{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 999)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize train/test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_list = pd.read_csv('Resources/Data/Rideshare_Layout.txt', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[';    \"Trip ID\" character(40) COLLATE pg_catalog.\"default\"',\n",
       " '    \"Trip Start Timestamp\" timestamp without time zone',\n",
       " '    \"Trip Seconds\" integer',\n",
       " '    \"Fare\" numeric',\n",
       " '    \"Trip Miles\" numeric',\n",
       " '    \"Pickup Community Area\" numeric',\n",
       " '    \"Dropoff Community Area\" numeric',\n",
       " '    \"Pickup Centroid Latitude\" character(60) COLLATE pg_catalog.\"default\"',\n",
       " '    \"Pickup Centroid Longitude\" character(60) COLLATE pg_catalog.\"default\"',\n",
       " '    \"Dropoff Centroid Longitude\" character(60) COLLATE pg_catalog.\"default\"',\n",
       " '    \"Dropoff Centroid Latitude\" character(60) COLLATE pg_catalog.\"default\"',\n",
       " '    \"Mon\" boolean',\n",
       " '    \"Tue\" boolean',\n",
       " '    \"Wed\" boolean',\n",
       " '    \"Thu\" boolean',\n",
       " '    \"Fri\" boolean',\n",
       " '    \"Sat\" boolean',\n",
       " '    \"Sun\" boolean',\n",
       " '    \"Time_0_0\" boolean',\n",
       " '    \"Time_0_15\" boolean',\n",
       " '    \"Time_0_30\" boolean',\n",
       " '    \"Time_0_45\" boolean',\n",
       " '    \"Time_1_0\" boolean',\n",
       " '    \"Time_1_15\" boolean',\n",
       " '    \"Time_1_30\" boolean',\n",
       " '    \"Time_1_45\" boolean',\n",
       " '    \"Time_2_0\" boolean',\n",
       " '    \"Time_2_15\" boolean',\n",
       " '    \"Time_2_30\" boolean',\n",
       " '    \"Time_2_45\" boolean',\n",
       " '    \"Time_3_0\" boolean',\n",
       " '    \"Time_3_15\" boolean',\n",
       " '    \"Time_3_30\" boolean',\n",
       " '    \"Time_3_45\" boolean',\n",
       " '    \"Time_4_0\" boolean',\n",
       " '    \"Time_4_15\" boolean',\n",
       " '    \"Time_4_30\" boolean',\n",
       " '    \"Time_4_45\" boolean',\n",
       " '    \"Time_5_0\" boolean',\n",
       " '    \"Time_5_15\" boolean',\n",
       " '    \"Time_5_30\" boolean',\n",
       " '    \"Time_5_45\" boolean',\n",
       " '    \"Time_6_0\" boolean',\n",
       " '    \"Time_6_15\" boolean',\n",
       " '    \"Time_6_30\" boolean',\n",
       " '    \"Time_6_45\" boolean',\n",
       " '    \"Time_7_0\" boolean',\n",
       " '    \"Time_7_15\" boolean',\n",
       " '    \"Time_7_30\" boolean',\n",
       " '    \"Time_7_45\" boolean',\n",
       " '    \"Time_8_0\" boolean',\n",
       " '    \"Time_8_15\" boolean',\n",
       " '    \"Time_8_30\" boolean',\n",
       " '    \"Time_8_45\" boolean',\n",
       " '    \"Time_9_0\" boolean',\n",
       " '    \"Time_9_15\" boolean',\n",
       " '    \"Time_9_30\" boolean',\n",
       " '    \"Time_9_45\" boolean',\n",
       " '    \"Time_10_0\" boolean',\n",
       " '    \"Time_10_15\" boolean',\n",
       " '    \"Time_10_30\" boolean',\n",
       " '    \"Time_10_45\" boolean',\n",
       " '    \"Time_11_0\" boolean',\n",
       " '    \"Time_11_15\" boolean',\n",
       " '    \"Time_11_30\" boolean',\n",
       " '    \"Time_11_45\" boolean',\n",
       " '    \"Time_12_0\" boolean',\n",
       " '    \"Time_12_15\" boolean',\n",
       " '    \"Time_12_30\" boolean',\n",
       " '    \"Time_12_45\" boolean',\n",
       " '    \"Time_13_0\" boolean',\n",
       " '    \"Time_13_15\" boolean',\n",
       " '    \"Time_13_30\" boolean',\n",
       " '    \"Time_13_45\" boolean',\n",
       " '    \"Time_14_0\" boolean',\n",
       " '    \"Time_14_15\" boolean',\n",
       " '    \"Time_14_30\" boolean',\n",
       " '    \"Time_14_45\" boolean',\n",
       " '    \"Time_15_0\" boolean',\n",
       " '    \"Time_15_15\" boolean',\n",
       " '    \"Time_15_30\" boolean',\n",
       " '    \"Time_15_45\" boolean',\n",
       " '    \"Time_16_0\" boolean',\n",
       " '    \"Time_16_15\" boolean',\n",
       " '    \"Time_16_30\" boolean',\n",
       " '    \"Time_16_45\" boolean',\n",
       " '    \"Time_17_0\" boolean',\n",
       " '    \"Time_17_15\" boolean',\n",
       " '    \"Time_17_30\" boolean',\n",
       " '    \"Time_17_45\" boolean',\n",
       " '    \"Time_18_0\" boolean',\n",
       " '    \"Time_18_15\" boolean',\n",
       " '    \"Time_18_30\" boolean',\n",
       " '    \"Time_18_45\" boolean',\n",
       " '    \"Time_19_0\" boolean',\n",
       " '    \"Time_19_15\" boolean',\n",
       " '    \"Time_19_30\" boolean',\n",
       " '    \"Time_19_45\" boolean',\n",
       " '    \"Time_20_0\" boolean',\n",
       " '    \"Time_20_15\" boolean',\n",
       " '    \"Time_20_30\" boolean',\n",
       " '    \"Time_20_45\" boolean',\n",
       " '    \"Time_21_0\" boolean',\n",
       " '    \"Time_21_15\" boolean',\n",
       " '    \"Time_21_30\" boolean',\n",
       " '    \"Time_21_45\" boolean',\n",
       " '    \"Time_22_0\" boolean',\n",
       " '    \"Time_22_15\" boolean',\n",
       " '    \"Time_22_30\" boolean',\n",
       " '    \"Time_22_45\" boolean',\n",
       " '    \"Time_23_0\" boolean',\n",
       " '    \"Time_23_15\" boolean',\n",
       " '    \"Time_23_30\" boolean',\n",
       " '    \"Time_23_45\" boolean',\n",
       " '    \"PCA_1\" boolean',\n",
       " '    \"PCA_2\" boolean',\n",
       " '    \"PCA_3\" boolean',\n",
       " '    \"PCA_4\" boolean',\n",
       " '    \"PCA_5\" boolean',\n",
       " '    \"PCA_6\" boolean',\n",
       " '    \"PCA_7\" boolean',\n",
       " '    \"PCA_8\" boolean',\n",
       " '    \"PCA_9\" boolean',\n",
       " '    \"PCA_10\" boolean',\n",
       " '    \"PCA_11\" boolean',\n",
       " '    \"PCA_12\" boolean',\n",
       " '    \"PCA_13\" boolean',\n",
       " '    \"PCA_14\" boolean',\n",
       " '    \"PCA_15\" boolean',\n",
       " '    \"PCA_16\" boolean',\n",
       " '    \"PCA_17\" boolean',\n",
       " '    \"PCA_18\" boolean',\n",
       " '    \"PCA_19\" boolean',\n",
       " '    \"PCA_20\" boolean',\n",
       " '    \"PCA_21\" boolean',\n",
       " '    \"PCA_22\" boolean',\n",
       " '    \"PCA_23\" boolean',\n",
       " '    \"PCA_24\" boolean',\n",
       " '    \"PCA_25\" boolean',\n",
       " '    \"PCA_26\" boolean',\n",
       " '    \"PCA_27\" boolean',\n",
       " '    \"PCA_28\" boolean',\n",
       " '    \"PCA_29\" boolean',\n",
       " '    \"PCA_30\" boolean',\n",
       " '    \"PCA_31\" boolean',\n",
       " '    \"PCA_32\" boolean',\n",
       " '    \"PCA_33\" boolean',\n",
       " '    \"PCA_34\" boolean',\n",
       " '    \"PCA_35\" boolean',\n",
       " '    \"PCA_36\" boolean',\n",
       " '    \"PCA_37\" boolean',\n",
       " '    \"PCA_38\" boolean',\n",
       " '    \"PCA_39\" boolean',\n",
       " '    \"PCA_40\" boolean',\n",
       " '    \"PCA_41\" boolean',\n",
       " '    \"PCA_42\" boolean',\n",
       " '    \"PCA_43\" boolean',\n",
       " '    \"PCA_44\" boolean',\n",
       " '    \"PCA_45\" boolean',\n",
       " '    \"PCA_46\" boolean',\n",
       " '    \"PCA_47\" boolean',\n",
       " '    \"PCA_48\" boolean',\n",
       " '    \"PCA_49\" boolean',\n",
       " '    \"PCA_50\" boolean',\n",
       " '    \"PCA_51\" boolean',\n",
       " '    \"PCA_52\" boolean',\n",
       " '    \"PCA_53\" boolean',\n",
       " '    \"PCA_54\" boolean',\n",
       " '    \"PCA_55\" boolean',\n",
       " '    \"PCA_56\" boolean',\n",
       " '    \"PCA_57\" boolean',\n",
       " '    \"PCA_58\" boolean',\n",
       " '    \"PCA_59\" boolean',\n",
       " '    \"PCA_60\" boolean',\n",
       " '    \"PCA_61\" boolean',\n",
       " '    \"PCA_62\" boolean',\n",
       " '    \"PCA_63\" boolean',\n",
       " '    \"PCA_64\" boolean',\n",
       " '    \"PCA_65\" boolean',\n",
       " '    \"PCA_66\" boolean',\n",
       " '    \"PCA_67\" boolean',\n",
       " '    \"PCA_68\" boolean',\n",
       " '    \"PCA_69\" boolean',\n",
       " '    \"PCA_70\" boolean',\n",
       " '    \"PCA_71\" boolean',\n",
       " '    \"PCA_72\" boolean',\n",
       " '    \"PCA_73\" boolean',\n",
       " '    \"PCA_74\" boolean',\n",
       " '    \"PCA_75\" boolean',\n",
       " '    \"PCA_76\" boolean',\n",
       " '    \"PCA_77\" boolean',\n",
       " '    \"DCA_1\" boolean',\n",
       " '    \"DCA_2\" boolean',\n",
       " '    \"DCA_3\" boolean',\n",
       " '    \"DCA_4\" boolean',\n",
       " '    \"DCA_5\" boolean',\n",
       " '    \"DCA_6\" boolean',\n",
       " '    \"DCA_7\" boolean',\n",
       " '    \"DCA_8\" boolean',\n",
       " '    \"DCA_9\" boolean',\n",
       " '    \"DCA_10\" boolean',\n",
       " '    \"DCA_11\" boolean',\n",
       " '    \"DCA_12\" boolean',\n",
       " '    \"DCA_13\" boolean',\n",
       " '    \"DCA_14\" boolean',\n",
       " '    \"DCA_15\" boolean',\n",
       " '    \"DCA_16\" boolean',\n",
       " '    \"DCA_17\" boolean',\n",
       " '    \"DCA_18\" boolean',\n",
       " '    \"DCA_19\" boolean',\n",
       " '    \"DCA_20\" boolean',\n",
       " '    \"DCA_21\" boolean',\n",
       " '    \"DCA_22\" boolean',\n",
       " '    \"DCA_23\" boolean',\n",
       " '    \"DCA_24\" boolean',\n",
       " '    \"DCA_25\" boolean',\n",
       " '    \"DCA_26\" boolean',\n",
       " '    \"DCA_27\" boolean',\n",
       " '    \"DCA_28\" boolean',\n",
       " '    \"DCA_29\" boolean',\n",
       " '    \"DCA_30\" boolean',\n",
       " '    \"DCA_31\" boolean',\n",
       " '    \"DCA_32\" boolean',\n",
       " '    \"DCA_33\" boolean',\n",
       " '    \"DCA_34\" boolean',\n",
       " '    \"DCA_35\" boolean',\n",
       " '    \"DCA_36\" boolean',\n",
       " '    \"DCA_37\" boolean',\n",
       " '    \"DCA_38\" boolean',\n",
       " '    \"DCA_39\" boolean',\n",
       " '    \"DCA_40\" boolean',\n",
       " '    \"DCA_41\" boolean',\n",
       " '    \"DCA_42\" boolean',\n",
       " '    \"DCA_43\" boolean',\n",
       " '    \"DCA_44\" boolean',\n",
       " '    \"DCA_45\" boolean',\n",
       " '    \"DCA_46\" boolean',\n",
       " '    \"DCA_47\" boolean',\n",
       " '    \"DCA_48\" boolean',\n",
       " '    \"DCA_49\" boolean',\n",
       " '    \"DCA_50\" boolean',\n",
       " '    \"DCA_51\" boolean',\n",
       " '    \"DCA_52\" boolean',\n",
       " '    \"DCA_53\" boolean',\n",
       " '    \"DCA_54\" boolean',\n",
       " '    \"DCA_55\" boolean',\n",
       " '    \"DCA_56\" boolean',\n",
       " '    \"DCA_57\" boolean',\n",
       " '    \"DCA_58\" boolean',\n",
       " '    \"DCA_59\" boolean',\n",
       " '    \"DCA_60\" boolean',\n",
       " '    \"DCA_61\" boolean',\n",
       " '    \"DCA_62\" boolean',\n",
       " '    \"DCA_63\" boolean',\n",
       " '    \"DCA_64\" boolean',\n",
       " '    \"DCA_65\" boolean',\n",
       " '    \"DCA_66\" boolean',\n",
       " '    \"DCA_67\" boolean',\n",
       " '    \"DCA_68\" boolean',\n",
       " '    \"DCA_69\" boolean',\n",
       " '    \"DCA_70\" boolean',\n",
       " '    \"DCA_71\" boolean',\n",
       " '    \"DCA_72\" boolean',\n",
       " '    \"DCA_73\" boolean',\n",
       " '    \"DCA_74\" boolean',\n",
       " '    \"DCA_75\" boolean',\n",
       " '    \"DCA_76\" boolean',\n",
       " '    \"DCA_77\" boolean',\n",
       " '    temp numeric',\n",
       " '    feels_like numeric',\n",
       " '    pressure numeric',\n",
       " '    humidity numeric',\n",
       " '    rain_1h numeric',\n",
       " '    snow_1h numeric']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_names = headers_list[0].to_list()\n",
    "header_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_df = pd.read_csv('Resources/Data/Rideshare_fixed.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be9de796ab2abcbae1d77ced9d9d21021e2284a4</td>\n",
       "      <td>2019-04-23 05:45:00</td>\n",
       "      <td>377.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>41.898306</td>\n",
       "      <td>-87.653614</td>\n",
       "      <td>-87.722611</td>\n",
       "      <td>41.950078</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>57.34</td>\n",
       "      <td>52.83</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90753342407656d346d0319811e6cfaa71431283</td>\n",
       "      <td>2019-04-11 17:30:00</td>\n",
       "      <td>959.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>41.914747</td>\n",
       "      <td>-87.654007</td>\n",
       "      <td>-87.631864</td>\n",
       "      <td>41.892042</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>57.00</td>\n",
       "      <td>53.96</td>\n",
       "      <td>1000.8</td>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4a813a48ec90afec16c42c360cd3ff584679bdaf</td>\n",
       "      <td>2019-04-13 05:45:00</td>\n",
       "      <td>758.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>41.922761</td>\n",
       "      <td>-87.699155</td>\n",
       "      <td>-87.625192</td>\n",
       "      <td>41.878866</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>37.08</td>\n",
       "      <td>29.53</td>\n",
       "      <td>1016.7</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c27a1dcc7a9c12b27a25b1f558ebd238b09eafd8</td>\n",
       "      <td>2019-04-03 14:15:00</td>\n",
       "      <td>604.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>41.745842</td>\n",
       "      <td>-87.591708</td>\n",
       "      <td>-87.581350</td>\n",
       "      <td>41.769690</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>56.68</td>\n",
       "      <td>42.28</td>\n",
       "      <td>1024.7</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dfb927c00257464d44ed91cbfc3f903436d8dad1</td>\n",
       "      <td>2019-04-03 19:45:00</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "      <td>41.986712</td>\n",
       "      <td>-87.663416</td>\n",
       "      <td>-87.633308</td>\n",
       "      <td>41.899602</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>56.03</td>\n",
       "      <td>48.92</td>\n",
       "      <td>1023.9</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0                    1       2    \\\n",
       "0  be9de796ab2abcbae1d77ced9d9d21021e2284a4  2019-04-23 05:45:00   377.0   \n",
       "1  90753342407656d346d0319811e6cfaa71431283  2019-04-11 17:30:00   959.0   \n",
       "2  4a813a48ec90afec16c42c360cd3ff584679bdaf  2019-04-13 05:45:00   758.0   \n",
       "3  c27a1dcc7a9c12b27a25b1f558ebd238b09eafd8  2019-04-03 14:15:00   604.0   \n",
       "4  dfb927c00257464d44ed91cbfc3f903436d8dad1  2019-04-03 19:45:00  1023.0   \n",
       "\n",
       "    3    4    5    6          7          8          9          10  11  12   \\\n",
       "0   7.5  3.9   24   16  41.898306 -87.653614 -87.722611  41.950078   f   t   \n",
       "1   7.5  2.5    7    8  41.914747 -87.654007 -87.631864  41.892042   f   f   \n",
       "2  10.0  5.3   22   32  41.922761 -87.699155 -87.625192  41.878866   f   f   \n",
       "3   7.5  2.0   45   43  41.745842 -87.591708 -87.581350  41.769690   f   f   \n",
       "4  12.5  7.7   77    8  41.986712 -87.663416 -87.633308  41.899602   f   f   \n",
       "\n",
       "  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31   \\\n",
       "0   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "1   f   t   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "2   f   f   f   t   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "3   t   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "4   t   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "\n",
       "  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50   \\\n",
       "0   f   f   f   f   f   f   f   f   f   t   f   f   f   f   f   f   f   f   f   \n",
       "1   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "2   f   f   f   f   f   f   f   f   f   t   f   f   f   f   f   f   f   f   f   \n",
       "3   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "4   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "\n",
       "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69   \\\n",
       "0   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "1   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "2   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "3   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "4   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "\n",
       "  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88   \\\n",
       "0   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "1   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   t   \n",
       "2   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "3   f   f   f   f   f   t   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "4   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "\n",
       "  89  90  91  92  93  94  95  96  97  98  99  100 101 102 103 104 105 106 107  \\\n",
       "0   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "1   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "2   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "3   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "4   f   f   f   f   f   f   f   f   t   f   f   f   f   f   f   f   f   f   f   \n",
       "\n",
       "  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126  \\\n",
       "0   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "1   f   f   f   f   f   f   f   f   f   f   f   f   t   f   f   f   f   f   f   \n",
       "2   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "3   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "4   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "\n",
       "  127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145  \\\n",
       "0   f   f   f   f   f   f   f   f   f   f   t   f   f   f   f   f   f   f   f   \n",
       "1   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "2   f   f   f   f   f   f   f   f   t   f   f   f   f   f   f   f   f   f   f   \n",
       "3   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "4   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "\n",
       "  146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164  \\\n",
       "0   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "1   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "2   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "3   f   f   f   f   f   f   f   f   f   f   f   f   t   f   f   f   f   f   f   \n",
       "4   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "\n",
       "  165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183  \\\n",
       "0   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "1   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "2   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "3   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "4   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "\n",
       "  184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202  \\\n",
       "0   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "1   f   f   f   f   f   f   f   f   f   f   f   f   f   f   t   f   f   f   f   \n",
       "2   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "3   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "4   f   f   f   f   f   f   t   f   f   f   f   f   f   f   t   f   f   f   f   \n",
       "\n",
       "  203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221  \\\n",
       "0   f   f   f   t   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "1   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "2   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "3   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "4   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "\n",
       "  222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240  \\\n",
       "0   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "1   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "2   t   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "3   f   f   f   f   f   f   f   f   f   f   f   t   f   f   f   f   f   f   f   \n",
       "4   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "\n",
       "  241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259  \\\n",
       "0   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "1   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "2   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "3   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "4   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   f   \n",
       "\n",
       "  260 261 262 263 264 265 266 267    268    269     270  271  272  273  \n",
       "0   f   f   f   f   f   f   f   f  57.34  52.83  1010.8   89  NaN  NaN  \n",
       "1   f   f   f   f   f   f   f   f  57.00  53.96  1000.8   79  NaN  NaN  \n",
       "2   f   f   f   f   f   f   f   f  37.08  29.53  1016.7   52  NaN  NaN  \n",
       "3   f   f   f   f   f   f   f   f  56.68  42.28  1024.7   27  NaN  NaN  \n",
       "4   f   f   f   f   f   f   f   f  56.03  48.92  1023.9   37  NaN  NaN  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = pd.read_csv('Extract_with_headers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = initial_df.columns.to_list()\n",
    "additional_cols = ['temp', 'feels_like', 'pressure', 'humidity', 'rain_1h', 'snow_1h']\n",
    "for element in additional_cols:\n",
    "    headers.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_df.columns = headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip ID</th>\n",
       "      <th>Trip Start Timestamp</th>\n",
       "      <th>Trip Seconds</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Trip Miles</th>\n",
       "      <th>Pickup Community Area</th>\n",
       "      <th>Dropoff Community Area</th>\n",
       "      <th>Pickup Centroid Latitude</th>\n",
       "      <th>Pickup Centroid Longitude</th>\n",
       "      <th>Dropoff Centroid Longitude</th>\n",
       "      <th>Dropoff Centroid Latitude</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>Thu</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>Time_0_0</th>\n",
       "      <th>Time_0_15</th>\n",
       "      <th>Time_0_30</th>\n",
       "      <th>Time_0_45</th>\n",
       "      <th>Time_1_0</th>\n",
       "      <th>Time_1_15</th>\n",
       "      <th>Time_1_30</th>\n",
       "      <th>Time_1_45</th>\n",
       "      <th>Time_2_0</th>\n",
       "      <th>Time_2_15</th>\n",
       "      <th>Time_2_30</th>\n",
       "      <th>Time_2_45</th>\n",
       "      <th>Time_3_0</th>\n",
       "      <th>Time_3_15</th>\n",
       "      <th>Time_3_30</th>\n",
       "      <th>Time_3_45</th>\n",
       "      <th>Time_4_0</th>\n",
       "      <th>Time_4_15</th>\n",
       "      <th>Time_4_30</th>\n",
       "      <th>Time_4_45</th>\n",
       "      <th>Time_5_0</th>\n",
       "      <th>Time_5_15</th>\n",
       "      <th>Time_5_30</th>\n",
       "      <th>Time_5_45</th>\n",
       "      <th>Time_6_0</th>\n",
       "      <th>Time_6_15</th>\n",
       "      <th>Time_6_30</th>\n",
       "      <th>Time_6_45</th>\n",
       "      <th>Time_7_0</th>\n",
       "      <th>Time_7_15</th>\n",
       "      <th>Time_7_30</th>\n",
       "      <th>Time_7_45</th>\n",
       "      <th>Time_8_0</th>\n",
       "      <th>Time_8_15</th>\n",
       "      <th>Time_8_30</th>\n",
       "      <th>Time_8_45</th>\n",
       "      <th>Time_9_0</th>\n",
       "      <th>Time_9_15</th>\n",
       "      <th>Time_9_30</th>\n",
       "      <th>Time_9_45</th>\n",
       "      <th>Time_10_0</th>\n",
       "      <th>Time_10_15</th>\n",
       "      <th>Time_10_30</th>\n",
       "      <th>Time_10_45</th>\n",
       "      <th>Time_11_0</th>\n",
       "      <th>Time_11_15</th>\n",
       "      <th>Time_11_30</th>\n",
       "      <th>Time_11_45</th>\n",
       "      <th>Time_12_0</th>\n",
       "      <th>Time_12_15</th>\n",
       "      <th>Time_12_30</th>\n",
       "      <th>Time_12_45</th>\n",
       "      <th>Time_13_0</th>\n",
       "      <th>Time_13_15</th>\n",
       "      <th>Time_13_30</th>\n",
       "      <th>Time_13_45</th>\n",
       "      <th>Time_14_0</th>\n",
       "      <th>Time_14_15</th>\n",
       "      <th>Time_14_30</th>\n",
       "      <th>Time_14_45</th>\n",
       "      <th>Time_15_0</th>\n",
       "      <th>Time_15_15</th>\n",
       "      <th>Time_15_30</th>\n",
       "      <th>Time_15_45</th>\n",
       "      <th>Time_16_0</th>\n",
       "      <th>Time_16_15</th>\n",
       "      <th>Time_16_30</th>\n",
       "      <th>Time_16_45</th>\n",
       "      <th>Time_17_0</th>\n",
       "      <th>Time_17_15</th>\n",
       "      <th>Time_17_30</th>\n",
       "      <th>Time_17_45</th>\n",
       "      <th>Time_18_0</th>\n",
       "      <th>Time_18_15</th>\n",
       "      <th>Time_18_30</th>\n",
       "      <th>Time_18_45</th>\n",
       "      <th>Time_19_0</th>\n",
       "      <th>Time_19_15</th>\n",
       "      <th>Time_19_30</th>\n",
       "      <th>Time_19_45</th>\n",
       "      <th>Time_20_0</th>\n",
       "      <th>Time_20_15</th>\n",
       "      <th>Time_20_30</th>\n",
       "      <th>Time_20_45</th>\n",
       "      <th>Time_21_0</th>\n",
       "      <th>Time_21_15</th>\n",
       "      <th>Time_21_30</th>\n",
       "      <th>Time_21_45</th>\n",
       "      <th>Time_22_0</th>\n",
       "      <th>Time_22_15</th>\n",
       "      <th>Time_22_30</th>\n",
       "      <th>Time_22_45</th>\n",
       "      <th>Time_23_0</th>\n",
       "      <th>Time_23_15</th>\n",
       "      <th>Time_23_30</th>\n",
       "      <th>Time_23_45</th>\n",
       "      <th>PCA_1</th>\n",
       "      <th>PCA_2</th>\n",
       "      <th>PCA_3</th>\n",
       "      <th>PCA_4</th>\n",
       "      <th>PCA_5</th>\n",
       "      <th>PCA_6</th>\n",
       "      <th>PCA_7</th>\n",
       "      <th>PCA_8</th>\n",
       "      <th>PCA_9</th>\n",
       "      <th>PCA_10</th>\n",
       "      <th>PCA_11</th>\n",
       "      <th>PCA_12</th>\n",
       "      <th>PCA_13</th>\n",
       "      <th>PCA_14</th>\n",
       "      <th>PCA_15</th>\n",
       "      <th>PCA_16</th>\n",
       "      <th>PCA_17</th>\n",
       "      <th>PCA_18</th>\n",
       "      <th>PCA_19</th>\n",
       "      <th>PCA_20</th>\n",
       "      <th>PCA_21</th>\n",
       "      <th>PCA_22</th>\n",
       "      <th>PCA_23</th>\n",
       "      <th>PCA_24</th>\n",
       "      <th>PCA_25</th>\n",
       "      <th>PCA_26</th>\n",
       "      <th>PCA_27</th>\n",
       "      <th>PCA_28</th>\n",
       "      <th>PCA_29</th>\n",
       "      <th>PCA_30</th>\n",
       "      <th>PCA_31</th>\n",
       "      <th>PCA_32</th>\n",
       "      <th>PCA_33</th>\n",
       "      <th>PCA_34</th>\n",
       "      <th>PCA_35</th>\n",
       "      <th>PCA_36</th>\n",
       "      <th>PCA_37</th>\n",
       "      <th>PCA_38</th>\n",
       "      <th>PCA_39</th>\n",
       "      <th>PCA_40</th>\n",
       "      <th>PCA_41</th>\n",
       "      <th>PCA_42</th>\n",
       "      <th>PCA_43</th>\n",
       "      <th>PCA_44</th>\n",
       "      <th>PCA_45</th>\n",
       "      <th>PCA_46</th>\n",
       "      <th>PCA_47</th>\n",
       "      <th>PCA_48</th>\n",
       "      <th>PCA_49</th>\n",
       "      <th>PCA_50</th>\n",
       "      <th>PCA_51</th>\n",
       "      <th>PCA_52</th>\n",
       "      <th>PCA_53</th>\n",
       "      <th>PCA_54</th>\n",
       "      <th>PCA_55</th>\n",
       "      <th>PCA_56</th>\n",
       "      <th>PCA_57</th>\n",
       "      <th>PCA_58</th>\n",
       "      <th>PCA_59</th>\n",
       "      <th>PCA_60</th>\n",
       "      <th>PCA_61</th>\n",
       "      <th>PCA_62</th>\n",
       "      <th>PCA_63</th>\n",
       "      <th>PCA_64</th>\n",
       "      <th>PCA_65</th>\n",
       "      <th>PCA_66</th>\n",
       "      <th>PCA_67</th>\n",
       "      <th>PCA_68</th>\n",
       "      <th>PCA_69</th>\n",
       "      <th>PCA_70</th>\n",
       "      <th>PCA_71</th>\n",
       "      <th>PCA_72</th>\n",
       "      <th>PCA_73</th>\n",
       "      <th>PCA_74</th>\n",
       "      <th>PCA_75</th>\n",
       "      <th>PCA_76</th>\n",
       "      <th>PCA_77</th>\n",
       "      <th>DCA_1</th>\n",
       "      <th>DCA_2</th>\n",
       "      <th>DCA_3</th>\n",
       "      <th>DCA_4</th>\n",
       "      <th>DCA_5</th>\n",
       "      <th>DCA_6</th>\n",
       "      <th>DCA_7</th>\n",
       "      <th>DCA_8</th>\n",
       "      <th>DCA_9</th>\n",
       "      <th>DCA_10</th>\n",
       "      <th>DCA_11</th>\n",
       "      <th>DCA_12</th>\n",
       "      <th>DCA_13</th>\n",
       "      <th>DCA_14</th>\n",
       "      <th>DCA_15</th>\n",
       "      <th>DCA_16</th>\n",
       "      <th>DCA_17</th>\n",
       "      <th>DCA_18</th>\n",
       "      <th>DCA_19</th>\n",
       "      <th>DCA_20</th>\n",
       "      <th>DCA_21</th>\n",
       "      <th>DCA_22</th>\n",
       "      <th>DCA_23</th>\n",
       "      <th>DCA_24</th>\n",
       "      <th>DCA_25</th>\n",
       "      <th>DCA_26</th>\n",
       "      <th>DCA_27</th>\n",
       "      <th>DCA_28</th>\n",
       "      <th>DCA_29</th>\n",
       "      <th>DCA_30</th>\n",
       "      <th>DCA_31</th>\n",
       "      <th>DCA_32</th>\n",
       "      <th>DCA_33</th>\n",
       "      <th>DCA_34</th>\n",
       "      <th>DCA_35</th>\n",
       "      <th>DCA_36</th>\n",
       "      <th>DCA_37</th>\n",
       "      <th>DCA_38</th>\n",
       "      <th>DCA_39</th>\n",
       "      <th>DCA_40</th>\n",
       "      <th>DCA_41</th>\n",
       "      <th>DCA_42</th>\n",
       "      <th>DCA_43</th>\n",
       "      <th>DCA_44</th>\n",
       "      <th>DCA_45</th>\n",
       "      <th>DCA_46</th>\n",
       "      <th>DCA_47</th>\n",
       "      <th>DCA_48</th>\n",
       "      <th>DCA_49</th>\n",
       "      <th>DCA_50</th>\n",
       "      <th>DCA_51</th>\n",
       "      <th>DCA_52</th>\n",
       "      <th>DCA_53</th>\n",
       "      <th>DCA_54</th>\n",
       "      <th>DCA_55</th>\n",
       "      <th>DCA_56</th>\n",
       "      <th>DCA_57</th>\n",
       "      <th>DCA_58</th>\n",
       "      <th>DCA_59</th>\n",
       "      <th>DCA_60</th>\n",
       "      <th>DCA_61</th>\n",
       "      <th>DCA_62</th>\n",
       "      <th>DCA_63</th>\n",
       "      <th>DCA_64</th>\n",
       "      <th>DCA_65</th>\n",
       "      <th>DCA_66</th>\n",
       "      <th>DCA_67</th>\n",
       "      <th>DCA_68</th>\n",
       "      <th>DCA_69</th>\n",
       "      <th>DCA_70</th>\n",
       "      <th>DCA_71</th>\n",
       "      <th>DCA_72</th>\n",
       "      <th>DCA_73</th>\n",
       "      <th>DCA_74</th>\n",
       "      <th>DCA_75</th>\n",
       "      <th>DCA_76</th>\n",
       "      <th>DCA_77</th>\n",
       "      <th>temp</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be9de796ab2abcbae1d77ced9d9d21021e2284a4</td>\n",
       "      <td>2019-04-23 05:45:00</td>\n",
       "      <td>377.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>41.898306</td>\n",
       "      <td>-87.653614</td>\n",
       "      <td>-87.722611</td>\n",
       "      <td>41.950078</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>57.34</td>\n",
       "      <td>52.83</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90753342407656d346d0319811e6cfaa71431283</td>\n",
       "      <td>2019-04-11 17:30:00</td>\n",
       "      <td>959.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>41.914747</td>\n",
       "      <td>-87.654007</td>\n",
       "      <td>-87.631864</td>\n",
       "      <td>41.892042</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>57.00</td>\n",
       "      <td>53.96</td>\n",
       "      <td>1000.8</td>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4a813a48ec90afec16c42c360cd3ff584679bdaf</td>\n",
       "      <td>2019-04-13 05:45:00</td>\n",
       "      <td>758.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>41.922761</td>\n",
       "      <td>-87.699155</td>\n",
       "      <td>-87.625192</td>\n",
       "      <td>41.878866</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>37.08</td>\n",
       "      <td>29.53</td>\n",
       "      <td>1016.7</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c27a1dcc7a9c12b27a25b1f558ebd238b09eafd8</td>\n",
       "      <td>2019-04-03 14:15:00</td>\n",
       "      <td>604.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>41.745842</td>\n",
       "      <td>-87.591708</td>\n",
       "      <td>-87.581350</td>\n",
       "      <td>41.769690</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>56.68</td>\n",
       "      <td>42.28</td>\n",
       "      <td>1024.7</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dfb927c00257464d44ed91cbfc3f903436d8dad1</td>\n",
       "      <td>2019-04-03 19:45:00</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "      <td>41.986712</td>\n",
       "      <td>-87.663416</td>\n",
       "      <td>-87.633308</td>\n",
       "      <td>41.899602</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>56.03</td>\n",
       "      <td>48.92</td>\n",
       "      <td>1023.9</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Trip ID Trip Start Timestamp  \\\n",
       "0  be9de796ab2abcbae1d77ced9d9d21021e2284a4  2019-04-23 05:45:00   \n",
       "1  90753342407656d346d0319811e6cfaa71431283  2019-04-11 17:30:00   \n",
       "2  4a813a48ec90afec16c42c360cd3ff584679bdaf  2019-04-13 05:45:00   \n",
       "3  c27a1dcc7a9c12b27a25b1f558ebd238b09eafd8  2019-04-03 14:15:00   \n",
       "4  dfb927c00257464d44ed91cbfc3f903436d8dad1  2019-04-03 19:45:00   \n",
       "\n",
       "   Trip Seconds  Fare  Trip Miles  Pickup Community Area  \\\n",
       "0         377.0   7.5         3.9                     24   \n",
       "1         959.0   7.5         2.5                      7   \n",
       "2         758.0  10.0         5.3                     22   \n",
       "3         604.0   7.5         2.0                     45   \n",
       "4        1023.0  12.5         7.7                     77   \n",
       "\n",
       "   Dropoff Community Area  Pickup Centroid Latitude  \\\n",
       "0                      16                 41.898306   \n",
       "1                       8                 41.914747   \n",
       "2                      32                 41.922761   \n",
       "3                      43                 41.745842   \n",
       "4                       8                 41.986712   \n",
       "\n",
       "   Pickup Centroid Longitude  Dropoff Centroid Longitude  \\\n",
       "0                 -87.653614                  -87.722611   \n",
       "1                 -87.654007                  -87.631864   \n",
       "2                 -87.699155                  -87.625192   \n",
       "3                 -87.591708                  -87.581350   \n",
       "4                 -87.663416                  -87.633308   \n",
       "\n",
       "   Dropoff Centroid Latitude Mon Tue Wed Thu Fri Sat Sun Time_0_0 Time_0_15  \\\n",
       "0                  41.950078   f   t   f   f   f   f   f        f         f   \n",
       "1                  41.892042   f   f   f   t   f   f   f        f         f   \n",
       "2                  41.878866   f   f   f   f   f   t   f        f         f   \n",
       "3                  41.769690   f   f   t   f   f   f   f        f         f   \n",
       "4                  41.899602   f   f   t   f   f   f   f        f         f   \n",
       "\n",
       "  Time_0_30 Time_0_45 Time_1_0 Time_1_15 Time_1_30 Time_1_45 Time_2_0  \\\n",
       "0         f         f        f         f         f         f        f   \n",
       "1         f         f        f         f         f         f        f   \n",
       "2         f         f        f         f         f         f        f   \n",
       "3         f         f        f         f         f         f        f   \n",
       "4         f         f        f         f         f         f        f   \n",
       "\n",
       "  Time_2_15 Time_2_30 Time_2_45 Time_3_0 Time_3_15 Time_3_30 Time_3_45  \\\n",
       "0         f         f         f        f         f         f         f   \n",
       "1         f         f         f        f         f         f         f   \n",
       "2         f         f         f        f         f         f         f   \n",
       "3         f         f         f        f         f         f         f   \n",
       "4         f         f         f        f         f         f         f   \n",
       "\n",
       "  Time_4_0 Time_4_15 Time_4_30 Time_4_45 Time_5_0 Time_5_15 Time_5_30  \\\n",
       "0        f         f         f         f        f         f         f   \n",
       "1        f         f         f         f        f         f         f   \n",
       "2        f         f         f         f        f         f         f   \n",
       "3        f         f         f         f        f         f         f   \n",
       "4        f         f         f         f        f         f         f   \n",
       "\n",
       "  Time_5_45 Time_6_0 Time_6_15 Time_6_30 Time_6_45 Time_7_0 Time_7_15  \\\n",
       "0         t        f         f         f         f        f         f   \n",
       "1         f        f         f         f         f        f         f   \n",
       "2         t        f         f         f         f        f         f   \n",
       "3         f        f         f         f         f        f         f   \n",
       "4         f        f         f         f         f        f         f   \n",
       "\n",
       "  Time_7_30 Time_7_45 Time_8_0 Time_8_15 Time_8_30 Time_8_45 Time_9_0  \\\n",
       "0         f         f        f         f         f         f        f   \n",
       "1         f         f        f         f         f         f        f   \n",
       "2         f         f        f         f         f         f        f   \n",
       "3         f         f        f         f         f         f        f   \n",
       "4         f         f        f         f         f         f        f   \n",
       "\n",
       "  Time_9_15 Time_9_30 Time_9_45 Time_10_0 Time_10_15 Time_10_30 Time_10_45  \\\n",
       "0         f         f         f         f          f          f          f   \n",
       "1         f         f         f         f          f          f          f   \n",
       "2         f         f         f         f          f          f          f   \n",
       "3         f         f         f         f          f          f          f   \n",
       "4         f         f         f         f          f          f          f   \n",
       "\n",
       "  Time_11_0 Time_11_15 Time_11_30 Time_11_45 Time_12_0 Time_12_15 Time_12_30  \\\n",
       "0         f          f          f          f         f          f          f   \n",
       "1         f          f          f          f         f          f          f   \n",
       "2         f          f          f          f         f          f          f   \n",
       "3         f          f          f          f         f          f          f   \n",
       "4         f          f          f          f         f          f          f   \n",
       "\n",
       "  Time_12_45 Time_13_0 Time_13_15 Time_13_30 Time_13_45 Time_14_0 Time_14_15  \\\n",
       "0          f         f          f          f          f         f          f   \n",
       "1          f         f          f          f          f         f          f   \n",
       "2          f         f          f          f          f         f          f   \n",
       "3          f         f          f          f          f         f          t   \n",
       "4          f         f          f          f          f         f          f   \n",
       "\n",
       "  Time_14_30 Time_14_45 Time_15_0 Time_15_15 Time_15_30 Time_15_45 Time_16_0  \\\n",
       "0          f          f         f          f          f          f         f   \n",
       "1          f          f         f          f          f          f         f   \n",
       "2          f          f         f          f          f          f         f   \n",
       "3          f          f         f          f          f          f         f   \n",
       "4          f          f         f          f          f          f         f   \n",
       "\n",
       "  Time_16_15 Time_16_30 Time_16_45 Time_17_0 Time_17_15 Time_17_30 Time_17_45  \\\n",
       "0          f          f          f         f          f          f          f   \n",
       "1          f          f          f         f          f          t          f   \n",
       "2          f          f          f         f          f          f          f   \n",
       "3          f          f          f         f          f          f          f   \n",
       "4          f          f          f         f          f          f          f   \n",
       "\n",
       "  Time_18_0 Time_18_15 Time_18_30 Time_18_45 Time_19_0 Time_19_15 Time_19_30  \\\n",
       "0         f          f          f          f         f          f          f   \n",
       "1         f          f          f          f         f          f          f   \n",
       "2         f          f          f          f         f          f          f   \n",
       "3         f          f          f          f         f          f          f   \n",
       "4         f          f          f          f         f          f          f   \n",
       "\n",
       "  Time_19_45 Time_20_0 Time_20_15 Time_20_30 Time_20_45 Time_21_0 Time_21_15  \\\n",
       "0          f         f          f          f          f         f          f   \n",
       "1          f         f          f          f          f         f          f   \n",
       "2          f         f          f          f          f         f          f   \n",
       "3          f         f          f          f          f         f          f   \n",
       "4          t         f          f          f          f         f          f   \n",
       "\n",
       "  Time_21_30 Time_21_45 Time_22_0 Time_22_15 Time_22_30 Time_22_45 Time_23_0  \\\n",
       "0          f          f         f          f          f          f         f   \n",
       "1          f          f         f          f          f          f         f   \n",
       "2          f          f         f          f          f          f         f   \n",
       "3          f          f         f          f          f          f         f   \n",
       "4          f          f         f          f          f          f         f   \n",
       "\n",
       "  Time_23_15 Time_23_30 Time_23_45 PCA_1 PCA_2 PCA_3 PCA_4 PCA_5 PCA_6 PCA_7  \\\n",
       "0          f          f          f     f     f     f     f     f     f     f   \n",
       "1          f          f          f     f     f     f     f     f     f     t   \n",
       "2          f          f          f     f     f     f     f     f     f     f   \n",
       "3          f          f          f     f     f     f     f     f     f     f   \n",
       "4          f          f          f     f     f     f     f     f     f     f   \n",
       "\n",
       "  PCA_8 PCA_9 PCA_10 PCA_11 PCA_12 PCA_13 PCA_14 PCA_15 PCA_16 PCA_17 PCA_18  \\\n",
       "0     f     f      f      f      f      f      f      f      f      f      f   \n",
       "1     f     f      f      f      f      f      f      f      f      f      f   \n",
       "2     f     f      f      f      f      f      f      f      f      f      f   \n",
       "3     f     f      f      f      f      f      f      f      f      f      f   \n",
       "4     f     f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_19 PCA_20 PCA_21 PCA_22 PCA_23 PCA_24 PCA_25 PCA_26 PCA_27 PCA_28  \\\n",
       "0      f      f      f      f      f      t      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      t      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_29 PCA_30 PCA_31 PCA_32 PCA_33 PCA_34 PCA_35 PCA_36 PCA_37 PCA_38  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_39 PCA_40 PCA_41 PCA_42 PCA_43 PCA_44 PCA_45 PCA_46 PCA_47 PCA_48  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      t      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_49 PCA_50 PCA_51 PCA_52 PCA_53 PCA_54 PCA_55 PCA_56 PCA_57 PCA_58  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_59 PCA_60 PCA_61 PCA_62 PCA_63 PCA_64 PCA_65 PCA_66 PCA_67 PCA_68  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_69 PCA_70 PCA_71 PCA_72 PCA_73 PCA_74 PCA_75 PCA_76 PCA_77 DCA_1 DCA_2  \\\n",
       "0      f      f      f      f      f      f      f      f      f     f     f   \n",
       "1      f      f      f      f      f      f      f      f      f     f     f   \n",
       "2      f      f      f      f      f      f      f      f      f     f     f   \n",
       "3      f      f      f      f      f      f      f      f      f     f     f   \n",
       "4      f      f      f      f      f      f      f      f      t     f     f   \n",
       "\n",
       "  DCA_3 DCA_4 DCA_5 DCA_6 DCA_7 DCA_8 DCA_9 DCA_10 DCA_11 DCA_12 DCA_13  \\\n",
       "0     f     f     f     f     f     f     f      f      f      f      f   \n",
       "1     f     f     f     f     f     t     f      f      f      f      f   \n",
       "2     f     f     f     f     f     f     f      f      f      f      f   \n",
       "3     f     f     f     f     f     f     f      f      f      f      f   \n",
       "4     f     f     f     f     f     t     f      f      f      f      f   \n",
       "\n",
       "  DCA_14 DCA_15 DCA_16 DCA_17 DCA_18 DCA_19 DCA_20 DCA_21 DCA_22 DCA_23  \\\n",
       "0      f      f      t      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_24 DCA_25 DCA_26 DCA_27 DCA_28 DCA_29 DCA_30 DCA_31 DCA_32 DCA_33  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      t      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_34 DCA_35 DCA_36 DCA_37 DCA_38 DCA_39 DCA_40 DCA_41 DCA_42 DCA_43  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      t   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_44 DCA_45 DCA_46 DCA_47 DCA_48 DCA_49 DCA_50 DCA_51 DCA_52 DCA_53  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_54 DCA_55 DCA_56 DCA_57 DCA_58 DCA_59 DCA_60 DCA_61 DCA_62 DCA_63  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_64 DCA_65 DCA_66 DCA_67 DCA_68 DCA_69 DCA_70 DCA_71 DCA_72 DCA_73  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_74 DCA_75 DCA_76 DCA_77   temp  feels_like  pressure  humidity  rain_1h  \\\n",
       "0      f      f      f      f  57.34       52.83    1010.8        89      NaN   \n",
       "1      f      f      f      f  57.00       53.96    1000.8        79      NaN   \n",
       "2      f      f      f      f  37.08       29.53    1016.7        52      NaN   \n",
       "3      f      f      f      f  56.68       42.28    1024.7        27      NaN   \n",
       "4      f      f      f      f  56.03       48.92    1023.9        37      NaN   \n",
       "\n",
       "   snow_1h  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace rain_1h and snow_1h NaN as zero\n",
    "values_df['rain_1h'] = values_df['rain_1h'].fillna(0)\n",
    "values_df['snow_1h'] = values_df['snow_1h'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip ID</th>\n",
       "      <th>Trip Start Timestamp</th>\n",
       "      <th>Trip Seconds</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Trip Miles</th>\n",
       "      <th>Pickup Community Area</th>\n",
       "      <th>Dropoff Community Area</th>\n",
       "      <th>Pickup Centroid Latitude</th>\n",
       "      <th>Pickup Centroid Longitude</th>\n",
       "      <th>Dropoff Centroid Longitude</th>\n",
       "      <th>Dropoff Centroid Latitude</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>Thu</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>Time_0_0</th>\n",
       "      <th>Time_0_15</th>\n",
       "      <th>Time_0_30</th>\n",
       "      <th>Time_0_45</th>\n",
       "      <th>Time_1_0</th>\n",
       "      <th>Time_1_15</th>\n",
       "      <th>Time_1_30</th>\n",
       "      <th>Time_1_45</th>\n",
       "      <th>Time_2_0</th>\n",
       "      <th>Time_2_15</th>\n",
       "      <th>Time_2_30</th>\n",
       "      <th>Time_2_45</th>\n",
       "      <th>Time_3_0</th>\n",
       "      <th>Time_3_15</th>\n",
       "      <th>Time_3_30</th>\n",
       "      <th>Time_3_45</th>\n",
       "      <th>Time_4_0</th>\n",
       "      <th>Time_4_15</th>\n",
       "      <th>Time_4_30</th>\n",
       "      <th>Time_4_45</th>\n",
       "      <th>Time_5_0</th>\n",
       "      <th>Time_5_15</th>\n",
       "      <th>Time_5_30</th>\n",
       "      <th>Time_5_45</th>\n",
       "      <th>Time_6_0</th>\n",
       "      <th>Time_6_15</th>\n",
       "      <th>Time_6_30</th>\n",
       "      <th>Time_6_45</th>\n",
       "      <th>Time_7_0</th>\n",
       "      <th>Time_7_15</th>\n",
       "      <th>Time_7_30</th>\n",
       "      <th>Time_7_45</th>\n",
       "      <th>Time_8_0</th>\n",
       "      <th>Time_8_15</th>\n",
       "      <th>Time_8_30</th>\n",
       "      <th>Time_8_45</th>\n",
       "      <th>Time_9_0</th>\n",
       "      <th>Time_9_15</th>\n",
       "      <th>Time_9_30</th>\n",
       "      <th>Time_9_45</th>\n",
       "      <th>Time_10_0</th>\n",
       "      <th>Time_10_15</th>\n",
       "      <th>Time_10_30</th>\n",
       "      <th>Time_10_45</th>\n",
       "      <th>Time_11_0</th>\n",
       "      <th>Time_11_15</th>\n",
       "      <th>Time_11_30</th>\n",
       "      <th>Time_11_45</th>\n",
       "      <th>Time_12_0</th>\n",
       "      <th>Time_12_15</th>\n",
       "      <th>Time_12_30</th>\n",
       "      <th>Time_12_45</th>\n",
       "      <th>Time_13_0</th>\n",
       "      <th>Time_13_15</th>\n",
       "      <th>Time_13_30</th>\n",
       "      <th>Time_13_45</th>\n",
       "      <th>Time_14_0</th>\n",
       "      <th>Time_14_15</th>\n",
       "      <th>Time_14_30</th>\n",
       "      <th>Time_14_45</th>\n",
       "      <th>Time_15_0</th>\n",
       "      <th>Time_15_15</th>\n",
       "      <th>Time_15_30</th>\n",
       "      <th>Time_15_45</th>\n",
       "      <th>Time_16_0</th>\n",
       "      <th>Time_16_15</th>\n",
       "      <th>Time_16_30</th>\n",
       "      <th>Time_16_45</th>\n",
       "      <th>Time_17_0</th>\n",
       "      <th>Time_17_15</th>\n",
       "      <th>Time_17_30</th>\n",
       "      <th>Time_17_45</th>\n",
       "      <th>Time_18_0</th>\n",
       "      <th>Time_18_15</th>\n",
       "      <th>Time_18_30</th>\n",
       "      <th>Time_18_45</th>\n",
       "      <th>Time_19_0</th>\n",
       "      <th>Time_19_15</th>\n",
       "      <th>Time_19_30</th>\n",
       "      <th>Time_19_45</th>\n",
       "      <th>Time_20_0</th>\n",
       "      <th>Time_20_15</th>\n",
       "      <th>Time_20_30</th>\n",
       "      <th>Time_20_45</th>\n",
       "      <th>Time_21_0</th>\n",
       "      <th>Time_21_15</th>\n",
       "      <th>Time_21_30</th>\n",
       "      <th>Time_21_45</th>\n",
       "      <th>Time_22_0</th>\n",
       "      <th>Time_22_15</th>\n",
       "      <th>Time_22_30</th>\n",
       "      <th>Time_22_45</th>\n",
       "      <th>Time_23_0</th>\n",
       "      <th>Time_23_15</th>\n",
       "      <th>Time_23_30</th>\n",
       "      <th>Time_23_45</th>\n",
       "      <th>PCA_1</th>\n",
       "      <th>PCA_2</th>\n",
       "      <th>PCA_3</th>\n",
       "      <th>PCA_4</th>\n",
       "      <th>PCA_5</th>\n",
       "      <th>PCA_6</th>\n",
       "      <th>PCA_7</th>\n",
       "      <th>PCA_8</th>\n",
       "      <th>PCA_9</th>\n",
       "      <th>PCA_10</th>\n",
       "      <th>PCA_11</th>\n",
       "      <th>PCA_12</th>\n",
       "      <th>PCA_13</th>\n",
       "      <th>PCA_14</th>\n",
       "      <th>PCA_15</th>\n",
       "      <th>PCA_16</th>\n",
       "      <th>PCA_17</th>\n",
       "      <th>PCA_18</th>\n",
       "      <th>PCA_19</th>\n",
       "      <th>PCA_20</th>\n",
       "      <th>PCA_21</th>\n",
       "      <th>PCA_22</th>\n",
       "      <th>PCA_23</th>\n",
       "      <th>PCA_24</th>\n",
       "      <th>PCA_25</th>\n",
       "      <th>PCA_26</th>\n",
       "      <th>PCA_27</th>\n",
       "      <th>PCA_28</th>\n",
       "      <th>PCA_29</th>\n",
       "      <th>PCA_30</th>\n",
       "      <th>PCA_31</th>\n",
       "      <th>PCA_32</th>\n",
       "      <th>PCA_33</th>\n",
       "      <th>PCA_34</th>\n",
       "      <th>PCA_35</th>\n",
       "      <th>PCA_36</th>\n",
       "      <th>PCA_37</th>\n",
       "      <th>PCA_38</th>\n",
       "      <th>PCA_39</th>\n",
       "      <th>PCA_40</th>\n",
       "      <th>PCA_41</th>\n",
       "      <th>PCA_42</th>\n",
       "      <th>PCA_43</th>\n",
       "      <th>PCA_44</th>\n",
       "      <th>PCA_45</th>\n",
       "      <th>PCA_46</th>\n",
       "      <th>PCA_47</th>\n",
       "      <th>PCA_48</th>\n",
       "      <th>PCA_49</th>\n",
       "      <th>PCA_50</th>\n",
       "      <th>PCA_51</th>\n",
       "      <th>PCA_52</th>\n",
       "      <th>PCA_53</th>\n",
       "      <th>PCA_54</th>\n",
       "      <th>PCA_55</th>\n",
       "      <th>PCA_56</th>\n",
       "      <th>PCA_57</th>\n",
       "      <th>PCA_58</th>\n",
       "      <th>PCA_59</th>\n",
       "      <th>PCA_60</th>\n",
       "      <th>PCA_61</th>\n",
       "      <th>PCA_62</th>\n",
       "      <th>PCA_63</th>\n",
       "      <th>PCA_64</th>\n",
       "      <th>PCA_65</th>\n",
       "      <th>PCA_66</th>\n",
       "      <th>PCA_67</th>\n",
       "      <th>PCA_68</th>\n",
       "      <th>PCA_69</th>\n",
       "      <th>PCA_70</th>\n",
       "      <th>PCA_71</th>\n",
       "      <th>PCA_72</th>\n",
       "      <th>PCA_73</th>\n",
       "      <th>PCA_74</th>\n",
       "      <th>PCA_75</th>\n",
       "      <th>PCA_76</th>\n",
       "      <th>PCA_77</th>\n",
       "      <th>DCA_1</th>\n",
       "      <th>DCA_2</th>\n",
       "      <th>DCA_3</th>\n",
       "      <th>DCA_4</th>\n",
       "      <th>DCA_5</th>\n",
       "      <th>DCA_6</th>\n",
       "      <th>DCA_7</th>\n",
       "      <th>DCA_8</th>\n",
       "      <th>DCA_9</th>\n",
       "      <th>DCA_10</th>\n",
       "      <th>DCA_11</th>\n",
       "      <th>DCA_12</th>\n",
       "      <th>DCA_13</th>\n",
       "      <th>DCA_14</th>\n",
       "      <th>DCA_15</th>\n",
       "      <th>DCA_16</th>\n",
       "      <th>DCA_17</th>\n",
       "      <th>DCA_18</th>\n",
       "      <th>DCA_19</th>\n",
       "      <th>DCA_20</th>\n",
       "      <th>DCA_21</th>\n",
       "      <th>DCA_22</th>\n",
       "      <th>DCA_23</th>\n",
       "      <th>DCA_24</th>\n",
       "      <th>DCA_25</th>\n",
       "      <th>DCA_26</th>\n",
       "      <th>DCA_27</th>\n",
       "      <th>DCA_28</th>\n",
       "      <th>DCA_29</th>\n",
       "      <th>DCA_30</th>\n",
       "      <th>DCA_31</th>\n",
       "      <th>DCA_32</th>\n",
       "      <th>DCA_33</th>\n",
       "      <th>DCA_34</th>\n",
       "      <th>DCA_35</th>\n",
       "      <th>DCA_36</th>\n",
       "      <th>DCA_37</th>\n",
       "      <th>DCA_38</th>\n",
       "      <th>DCA_39</th>\n",
       "      <th>DCA_40</th>\n",
       "      <th>DCA_41</th>\n",
       "      <th>DCA_42</th>\n",
       "      <th>DCA_43</th>\n",
       "      <th>DCA_44</th>\n",
       "      <th>DCA_45</th>\n",
       "      <th>DCA_46</th>\n",
       "      <th>DCA_47</th>\n",
       "      <th>DCA_48</th>\n",
       "      <th>DCA_49</th>\n",
       "      <th>DCA_50</th>\n",
       "      <th>DCA_51</th>\n",
       "      <th>DCA_52</th>\n",
       "      <th>DCA_53</th>\n",
       "      <th>DCA_54</th>\n",
       "      <th>DCA_55</th>\n",
       "      <th>DCA_56</th>\n",
       "      <th>DCA_57</th>\n",
       "      <th>DCA_58</th>\n",
       "      <th>DCA_59</th>\n",
       "      <th>DCA_60</th>\n",
       "      <th>DCA_61</th>\n",
       "      <th>DCA_62</th>\n",
       "      <th>DCA_63</th>\n",
       "      <th>DCA_64</th>\n",
       "      <th>DCA_65</th>\n",
       "      <th>DCA_66</th>\n",
       "      <th>DCA_67</th>\n",
       "      <th>DCA_68</th>\n",
       "      <th>DCA_69</th>\n",
       "      <th>DCA_70</th>\n",
       "      <th>DCA_71</th>\n",
       "      <th>DCA_72</th>\n",
       "      <th>DCA_73</th>\n",
       "      <th>DCA_74</th>\n",
       "      <th>DCA_75</th>\n",
       "      <th>DCA_76</th>\n",
       "      <th>DCA_77</th>\n",
       "      <th>temp</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be9de796ab2abcbae1d77ced9d9d21021e2284a4</td>\n",
       "      <td>2019-04-23 05:45:00</td>\n",
       "      <td>377.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>41.898306</td>\n",
       "      <td>-87.653614</td>\n",
       "      <td>-87.722611</td>\n",
       "      <td>41.950078</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>57.34</td>\n",
       "      <td>52.83</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90753342407656d346d0319811e6cfaa71431283</td>\n",
       "      <td>2019-04-11 17:30:00</td>\n",
       "      <td>959.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>41.914747</td>\n",
       "      <td>-87.654007</td>\n",
       "      <td>-87.631864</td>\n",
       "      <td>41.892042</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>57.00</td>\n",
       "      <td>53.96</td>\n",
       "      <td>1000.8</td>\n",
       "      <td>79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4a813a48ec90afec16c42c360cd3ff584679bdaf</td>\n",
       "      <td>2019-04-13 05:45:00</td>\n",
       "      <td>758.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>41.922761</td>\n",
       "      <td>-87.699155</td>\n",
       "      <td>-87.625192</td>\n",
       "      <td>41.878866</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>37.08</td>\n",
       "      <td>29.53</td>\n",
       "      <td>1016.7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c27a1dcc7a9c12b27a25b1f558ebd238b09eafd8</td>\n",
       "      <td>2019-04-03 14:15:00</td>\n",
       "      <td>604.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>41.745842</td>\n",
       "      <td>-87.591708</td>\n",
       "      <td>-87.581350</td>\n",
       "      <td>41.769690</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>56.68</td>\n",
       "      <td>42.28</td>\n",
       "      <td>1024.7</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dfb927c00257464d44ed91cbfc3f903436d8dad1</td>\n",
       "      <td>2019-04-03 19:45:00</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "      <td>41.986712</td>\n",
       "      <td>-87.663416</td>\n",
       "      <td>-87.633308</td>\n",
       "      <td>41.899602</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>56.03</td>\n",
       "      <td>48.92</td>\n",
       "      <td>1023.9</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Trip ID Trip Start Timestamp  \\\n",
       "0  be9de796ab2abcbae1d77ced9d9d21021e2284a4  2019-04-23 05:45:00   \n",
       "1  90753342407656d346d0319811e6cfaa71431283  2019-04-11 17:30:00   \n",
       "2  4a813a48ec90afec16c42c360cd3ff584679bdaf  2019-04-13 05:45:00   \n",
       "3  c27a1dcc7a9c12b27a25b1f558ebd238b09eafd8  2019-04-03 14:15:00   \n",
       "4  dfb927c00257464d44ed91cbfc3f903436d8dad1  2019-04-03 19:45:00   \n",
       "\n",
       "   Trip Seconds  Fare  Trip Miles  Pickup Community Area  \\\n",
       "0         377.0   7.5         3.9                     24   \n",
       "1         959.0   7.5         2.5                      7   \n",
       "2         758.0  10.0         5.3                     22   \n",
       "3         604.0   7.5         2.0                     45   \n",
       "4        1023.0  12.5         7.7                     77   \n",
       "\n",
       "   Dropoff Community Area  Pickup Centroid Latitude  \\\n",
       "0                      16                 41.898306   \n",
       "1                       8                 41.914747   \n",
       "2                      32                 41.922761   \n",
       "3                      43                 41.745842   \n",
       "4                       8                 41.986712   \n",
       "\n",
       "   Pickup Centroid Longitude  Dropoff Centroid Longitude  \\\n",
       "0                 -87.653614                  -87.722611   \n",
       "1                 -87.654007                  -87.631864   \n",
       "2                 -87.699155                  -87.625192   \n",
       "3                 -87.591708                  -87.581350   \n",
       "4                 -87.663416                  -87.633308   \n",
       "\n",
       "   Dropoff Centroid Latitude Mon Tue Wed Thu Fri Sat Sun Time_0_0 Time_0_15  \\\n",
       "0                  41.950078   f   t   f   f   f   f   f        f         f   \n",
       "1                  41.892042   f   f   f   t   f   f   f        f         f   \n",
       "2                  41.878866   f   f   f   f   f   t   f        f         f   \n",
       "3                  41.769690   f   f   t   f   f   f   f        f         f   \n",
       "4                  41.899602   f   f   t   f   f   f   f        f         f   \n",
       "\n",
       "  Time_0_30 Time_0_45 Time_1_0 Time_1_15 Time_1_30 Time_1_45 Time_2_0  \\\n",
       "0         f         f        f         f         f         f        f   \n",
       "1         f         f        f         f         f         f        f   \n",
       "2         f         f        f         f         f         f        f   \n",
       "3         f         f        f         f         f         f        f   \n",
       "4         f         f        f         f         f         f        f   \n",
       "\n",
       "  Time_2_15 Time_2_30 Time_2_45 Time_3_0 Time_3_15 Time_3_30 Time_3_45  \\\n",
       "0         f         f         f        f         f         f         f   \n",
       "1         f         f         f        f         f         f         f   \n",
       "2         f         f         f        f         f         f         f   \n",
       "3         f         f         f        f         f         f         f   \n",
       "4         f         f         f        f         f         f         f   \n",
       "\n",
       "  Time_4_0 Time_4_15 Time_4_30 Time_4_45 Time_5_0 Time_5_15 Time_5_30  \\\n",
       "0        f         f         f         f        f         f         f   \n",
       "1        f         f         f         f        f         f         f   \n",
       "2        f         f         f         f        f         f         f   \n",
       "3        f         f         f         f        f         f         f   \n",
       "4        f         f         f         f        f         f         f   \n",
       "\n",
       "  Time_5_45 Time_6_0 Time_6_15 Time_6_30 Time_6_45 Time_7_0 Time_7_15  \\\n",
       "0         t        f         f         f         f        f         f   \n",
       "1         f        f         f         f         f        f         f   \n",
       "2         t        f         f         f         f        f         f   \n",
       "3         f        f         f         f         f        f         f   \n",
       "4         f        f         f         f         f        f         f   \n",
       "\n",
       "  Time_7_30 Time_7_45 Time_8_0 Time_8_15 Time_8_30 Time_8_45 Time_9_0  \\\n",
       "0         f         f        f         f         f         f        f   \n",
       "1         f         f        f         f         f         f        f   \n",
       "2         f         f        f         f         f         f        f   \n",
       "3         f         f        f         f         f         f        f   \n",
       "4         f         f        f         f         f         f        f   \n",
       "\n",
       "  Time_9_15 Time_9_30 Time_9_45 Time_10_0 Time_10_15 Time_10_30 Time_10_45  \\\n",
       "0         f         f         f         f          f          f          f   \n",
       "1         f         f         f         f          f          f          f   \n",
       "2         f         f         f         f          f          f          f   \n",
       "3         f         f         f         f          f          f          f   \n",
       "4         f         f         f         f          f          f          f   \n",
       "\n",
       "  Time_11_0 Time_11_15 Time_11_30 Time_11_45 Time_12_0 Time_12_15 Time_12_30  \\\n",
       "0         f          f          f          f         f          f          f   \n",
       "1         f          f          f          f         f          f          f   \n",
       "2         f          f          f          f         f          f          f   \n",
       "3         f          f          f          f         f          f          f   \n",
       "4         f          f          f          f         f          f          f   \n",
       "\n",
       "  Time_12_45 Time_13_0 Time_13_15 Time_13_30 Time_13_45 Time_14_0 Time_14_15  \\\n",
       "0          f         f          f          f          f         f          f   \n",
       "1          f         f          f          f          f         f          f   \n",
       "2          f         f          f          f          f         f          f   \n",
       "3          f         f          f          f          f         f          t   \n",
       "4          f         f          f          f          f         f          f   \n",
       "\n",
       "  Time_14_30 Time_14_45 Time_15_0 Time_15_15 Time_15_30 Time_15_45 Time_16_0  \\\n",
       "0          f          f         f          f          f          f         f   \n",
       "1          f          f         f          f          f          f         f   \n",
       "2          f          f         f          f          f          f         f   \n",
       "3          f          f         f          f          f          f         f   \n",
       "4          f          f         f          f          f          f         f   \n",
       "\n",
       "  Time_16_15 Time_16_30 Time_16_45 Time_17_0 Time_17_15 Time_17_30 Time_17_45  \\\n",
       "0          f          f          f         f          f          f          f   \n",
       "1          f          f          f         f          f          t          f   \n",
       "2          f          f          f         f          f          f          f   \n",
       "3          f          f          f         f          f          f          f   \n",
       "4          f          f          f         f          f          f          f   \n",
       "\n",
       "  Time_18_0 Time_18_15 Time_18_30 Time_18_45 Time_19_0 Time_19_15 Time_19_30  \\\n",
       "0         f          f          f          f         f          f          f   \n",
       "1         f          f          f          f         f          f          f   \n",
       "2         f          f          f          f         f          f          f   \n",
       "3         f          f          f          f         f          f          f   \n",
       "4         f          f          f          f         f          f          f   \n",
       "\n",
       "  Time_19_45 Time_20_0 Time_20_15 Time_20_30 Time_20_45 Time_21_0 Time_21_15  \\\n",
       "0          f         f          f          f          f         f          f   \n",
       "1          f         f          f          f          f         f          f   \n",
       "2          f         f          f          f          f         f          f   \n",
       "3          f         f          f          f          f         f          f   \n",
       "4          t         f          f          f          f         f          f   \n",
       "\n",
       "  Time_21_30 Time_21_45 Time_22_0 Time_22_15 Time_22_30 Time_22_45 Time_23_0  \\\n",
       "0          f          f         f          f          f          f         f   \n",
       "1          f          f         f          f          f          f         f   \n",
       "2          f          f         f          f          f          f         f   \n",
       "3          f          f         f          f          f          f         f   \n",
       "4          f          f         f          f          f          f         f   \n",
       "\n",
       "  Time_23_15 Time_23_30 Time_23_45 PCA_1 PCA_2 PCA_3 PCA_4 PCA_5 PCA_6 PCA_7  \\\n",
       "0          f          f          f     f     f     f     f     f     f     f   \n",
       "1          f          f          f     f     f     f     f     f     f     t   \n",
       "2          f          f          f     f     f     f     f     f     f     f   \n",
       "3          f          f          f     f     f     f     f     f     f     f   \n",
       "4          f          f          f     f     f     f     f     f     f     f   \n",
       "\n",
       "  PCA_8 PCA_9 PCA_10 PCA_11 PCA_12 PCA_13 PCA_14 PCA_15 PCA_16 PCA_17 PCA_18  \\\n",
       "0     f     f      f      f      f      f      f      f      f      f      f   \n",
       "1     f     f      f      f      f      f      f      f      f      f      f   \n",
       "2     f     f      f      f      f      f      f      f      f      f      f   \n",
       "3     f     f      f      f      f      f      f      f      f      f      f   \n",
       "4     f     f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_19 PCA_20 PCA_21 PCA_22 PCA_23 PCA_24 PCA_25 PCA_26 PCA_27 PCA_28  \\\n",
       "0      f      f      f      f      f      t      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      t      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_29 PCA_30 PCA_31 PCA_32 PCA_33 PCA_34 PCA_35 PCA_36 PCA_37 PCA_38  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_39 PCA_40 PCA_41 PCA_42 PCA_43 PCA_44 PCA_45 PCA_46 PCA_47 PCA_48  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      t      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_49 PCA_50 PCA_51 PCA_52 PCA_53 PCA_54 PCA_55 PCA_56 PCA_57 PCA_58  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_59 PCA_60 PCA_61 PCA_62 PCA_63 PCA_64 PCA_65 PCA_66 PCA_67 PCA_68  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_69 PCA_70 PCA_71 PCA_72 PCA_73 PCA_74 PCA_75 PCA_76 PCA_77 DCA_1 DCA_2  \\\n",
       "0      f      f      f      f      f      f      f      f      f     f     f   \n",
       "1      f      f      f      f      f      f      f      f      f     f     f   \n",
       "2      f      f      f      f      f      f      f      f      f     f     f   \n",
       "3      f      f      f      f      f      f      f      f      f     f     f   \n",
       "4      f      f      f      f      f      f      f      f      t     f     f   \n",
       "\n",
       "  DCA_3 DCA_4 DCA_5 DCA_6 DCA_7 DCA_8 DCA_9 DCA_10 DCA_11 DCA_12 DCA_13  \\\n",
       "0     f     f     f     f     f     f     f      f      f      f      f   \n",
       "1     f     f     f     f     f     t     f      f      f      f      f   \n",
       "2     f     f     f     f     f     f     f      f      f      f      f   \n",
       "3     f     f     f     f     f     f     f      f      f      f      f   \n",
       "4     f     f     f     f     f     t     f      f      f      f      f   \n",
       "\n",
       "  DCA_14 DCA_15 DCA_16 DCA_17 DCA_18 DCA_19 DCA_20 DCA_21 DCA_22 DCA_23  \\\n",
       "0      f      f      t      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_24 DCA_25 DCA_26 DCA_27 DCA_28 DCA_29 DCA_30 DCA_31 DCA_32 DCA_33  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      t      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_34 DCA_35 DCA_36 DCA_37 DCA_38 DCA_39 DCA_40 DCA_41 DCA_42 DCA_43  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      t   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_44 DCA_45 DCA_46 DCA_47 DCA_48 DCA_49 DCA_50 DCA_51 DCA_52 DCA_53  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_54 DCA_55 DCA_56 DCA_57 DCA_58 DCA_59 DCA_60 DCA_61 DCA_62 DCA_63  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_64 DCA_65 DCA_66 DCA_67 DCA_68 DCA_69 DCA_70 DCA_71 DCA_72 DCA_73  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_74 DCA_75 DCA_76 DCA_77   temp  feels_like  pressure  humidity  rain_1h  \\\n",
       "0      f      f      f      f  57.34       52.83    1010.8        89      0.0   \n",
       "1      f      f      f      f  57.00       53.96    1000.8        79      0.0   \n",
       "2      f      f      f      f  37.08       29.53    1016.7        52      0.0   \n",
       "3      f      f      f      f  56.68       42.28    1024.7        27      0.0   \n",
       "4      f      f      f      f  56.03       48.92    1023.9        37      0.0   \n",
       "\n",
       "   snow_1h  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = pd.DataFrame(values_df['Trip Start Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps['parsed_time'] = timestamps['Trip Start Timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip Start Timestamp</th>\n",
       "      <th>parsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-23 05:45:00</td>\n",
       "      <td>2019-04-23 05:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-11 17:30:00</td>\n",
       "      <td>2019-04-11 17:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-13 05:45:00</td>\n",
       "      <td>2019-04-13 05:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-03 14:15:00</td>\n",
       "      <td>2019-04-03 14:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-03 19:45:00</td>\n",
       "      <td>2019-04-03 19:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Trip Start Timestamp          parsed_time\n",
       "0  2019-04-23 05:45:00  2019-04-23 05:45:00\n",
       "1  2019-04-11 17:30:00  2019-04-11 17:30:00\n",
       "2  2019-04-13 05:45:00  2019-04-13 05:45:00\n",
       "3  2019-04-03 14:15:00  2019-04-03 14:15:00\n",
       "4  2019-04-03 19:45:00  2019-04-03 19:45:00"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in timestamps.iterrows():\n",
    "    row['parsed_time'] = row['parsed_time'][5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "timestamps['parsed_time'] = timestamps['parsed_time'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip Start Timestamp</th>\n",
       "      <th>parsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-23 05:45:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-11 17:30:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-13 05:45:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-03 14:15:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-03 19:45:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Trip Start Timestamp  parsed_time\n",
       "0  2019-04-23 05:45:00            4\n",
       "1  2019-04-11 17:30:00            4\n",
       "2  2019-04-13 05:45:00            4\n",
       "3  2019-04-03 14:15:00            4\n",
       "4  2019-04-03 19:45:00            4"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps['January'] = 0\n",
    "timestamps['February'] = 0\n",
    "timestamps['March'] = 0\n",
    "timestamps['April'] = 0\n",
    "timestamps['May'] = 0\n",
    "timestamps['June'] = 0\n",
    "timestamps['July'] = 0\n",
    "timestamps['August'] = 0\n",
    "timestamps['September'] = 0\n",
    "timestamps['October'] = 0\n",
    "timestamps['November'] = 0\n",
    "timestamps['December'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trip Start Timestamp    object\n",
       "parsed_time              int64\n",
       "January                  int64\n",
       "February                 int64\n",
       "March                    int64\n",
       "April                    int64\n",
       "May                      int64\n",
       "June                     int64\n",
       "July                     int64\n",
       "August                   int64\n",
       "September                int64\n",
       "October                  int64\n",
       "November                 int64\n",
       "December                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamps.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(dataframe):\n",
    "    for index, row in dataframe.iterrows(): \n",
    "        if(int(row['parsed_time']) == 1):\n",
    "            dataframe.at[index, 'January'] = 1\n",
    "        elif(int(row['parsed_time']) == 2):\n",
    "            dataframe.at[index, 'February'] = 1\n",
    "        elif(int(row['parsed_time']) == 3):\n",
    "            dataframe.at[index, 'March'] = 1\n",
    "        elif(int(row['parsed_time']) == 4):\n",
    "            dataframe.at[index, 'April'] = 1\n",
    "        elif(int(row['parsed_time']) == 5):\n",
    "            dataframe.at[index, 'May'] = 1\n",
    "        elif(int(row['parsed_time']) == 6):\n",
    "            dataframe.at[index, 'June'] = 1\n",
    "        elif(int(row['parsed_time']) == 7):\n",
    "            dataframe.at[index, 'July'] = 1\n",
    "        elif(int(row['parsed_time']) == 8):\n",
    "            dataframe.at[index, 'August'] = 1\n",
    "        elif(int(row['parsed_time']) == 9):\n",
    "            dataframe.at[index, 'September'] = 1\n",
    "        elif(int(row['parsed_time']) == 10):\n",
    "            dataframe.at[index, 'October'] = 1\n",
    "        elif(int(row['parsed_time']) == 11):\n",
    "            dataframe.at[index, 'November'] = 1\n",
    "        elif(int(row['parsed_time']) == 12):\n",
    "            dataframe.at[index, 'December'] = 1\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df = one_hot(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: July, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_df['July'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_df['January'] = one_hot_df['January']\n",
    "values_df['February'] = one_hot_df['February']\n",
    "values_df['March'] = one_hot_df['March']\n",
    "values_df['April'] = one_hot_df['April']\n",
    "values_df['May'] = one_hot_df['May']\n",
    "values_df['June'] = one_hot_df['June']\n",
    "values_df['July'] = one_hot_df['July']\n",
    "values_df['August'] = one_hot_df['August']\n",
    "values_df['September'] = one_hot_df['September']\n",
    "values_df['October'] = one_hot_df['October']\n",
    "values_df['November'] = one_hot_df['November']\n",
    "values_df['December'] = one_hot_df['December']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip ID</th>\n",
       "      <th>Trip Start Timestamp</th>\n",
       "      <th>Trip Seconds</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Trip Miles</th>\n",
       "      <th>Pickup Community Area</th>\n",
       "      <th>Dropoff Community Area</th>\n",
       "      <th>Pickup Centroid Latitude</th>\n",
       "      <th>Pickup Centroid Longitude</th>\n",
       "      <th>Dropoff Centroid Longitude</th>\n",
       "      <th>Dropoff Centroid Latitude</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>Thu</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>Time_0_0</th>\n",
       "      <th>Time_0_15</th>\n",
       "      <th>Time_0_30</th>\n",
       "      <th>Time_0_45</th>\n",
       "      <th>Time_1_0</th>\n",
       "      <th>Time_1_15</th>\n",
       "      <th>Time_1_30</th>\n",
       "      <th>Time_1_45</th>\n",
       "      <th>Time_2_0</th>\n",
       "      <th>Time_2_15</th>\n",
       "      <th>Time_2_30</th>\n",
       "      <th>Time_2_45</th>\n",
       "      <th>Time_3_0</th>\n",
       "      <th>Time_3_15</th>\n",
       "      <th>Time_3_30</th>\n",
       "      <th>Time_3_45</th>\n",
       "      <th>Time_4_0</th>\n",
       "      <th>Time_4_15</th>\n",
       "      <th>Time_4_30</th>\n",
       "      <th>Time_4_45</th>\n",
       "      <th>Time_5_0</th>\n",
       "      <th>Time_5_15</th>\n",
       "      <th>Time_5_30</th>\n",
       "      <th>Time_5_45</th>\n",
       "      <th>Time_6_0</th>\n",
       "      <th>Time_6_15</th>\n",
       "      <th>Time_6_30</th>\n",
       "      <th>Time_6_45</th>\n",
       "      <th>Time_7_0</th>\n",
       "      <th>Time_7_15</th>\n",
       "      <th>Time_7_30</th>\n",
       "      <th>Time_7_45</th>\n",
       "      <th>Time_8_0</th>\n",
       "      <th>Time_8_15</th>\n",
       "      <th>Time_8_30</th>\n",
       "      <th>Time_8_45</th>\n",
       "      <th>Time_9_0</th>\n",
       "      <th>Time_9_15</th>\n",
       "      <th>Time_9_30</th>\n",
       "      <th>Time_9_45</th>\n",
       "      <th>Time_10_0</th>\n",
       "      <th>Time_10_15</th>\n",
       "      <th>Time_10_30</th>\n",
       "      <th>Time_10_45</th>\n",
       "      <th>Time_11_0</th>\n",
       "      <th>Time_11_15</th>\n",
       "      <th>Time_11_30</th>\n",
       "      <th>Time_11_45</th>\n",
       "      <th>Time_12_0</th>\n",
       "      <th>Time_12_15</th>\n",
       "      <th>Time_12_30</th>\n",
       "      <th>Time_12_45</th>\n",
       "      <th>Time_13_0</th>\n",
       "      <th>Time_13_15</th>\n",
       "      <th>Time_13_30</th>\n",
       "      <th>Time_13_45</th>\n",
       "      <th>Time_14_0</th>\n",
       "      <th>Time_14_15</th>\n",
       "      <th>Time_14_30</th>\n",
       "      <th>Time_14_45</th>\n",
       "      <th>Time_15_0</th>\n",
       "      <th>Time_15_15</th>\n",
       "      <th>Time_15_30</th>\n",
       "      <th>Time_15_45</th>\n",
       "      <th>Time_16_0</th>\n",
       "      <th>Time_16_15</th>\n",
       "      <th>Time_16_30</th>\n",
       "      <th>Time_16_45</th>\n",
       "      <th>Time_17_0</th>\n",
       "      <th>Time_17_15</th>\n",
       "      <th>Time_17_30</th>\n",
       "      <th>Time_17_45</th>\n",
       "      <th>Time_18_0</th>\n",
       "      <th>Time_18_15</th>\n",
       "      <th>Time_18_30</th>\n",
       "      <th>Time_18_45</th>\n",
       "      <th>Time_19_0</th>\n",
       "      <th>Time_19_15</th>\n",
       "      <th>Time_19_30</th>\n",
       "      <th>Time_19_45</th>\n",
       "      <th>Time_20_0</th>\n",
       "      <th>Time_20_15</th>\n",
       "      <th>Time_20_30</th>\n",
       "      <th>Time_20_45</th>\n",
       "      <th>Time_21_0</th>\n",
       "      <th>Time_21_15</th>\n",
       "      <th>Time_21_30</th>\n",
       "      <th>Time_21_45</th>\n",
       "      <th>Time_22_0</th>\n",
       "      <th>Time_22_15</th>\n",
       "      <th>Time_22_30</th>\n",
       "      <th>Time_22_45</th>\n",
       "      <th>Time_23_0</th>\n",
       "      <th>Time_23_15</th>\n",
       "      <th>Time_23_30</th>\n",
       "      <th>Time_23_45</th>\n",
       "      <th>PCA_1</th>\n",
       "      <th>PCA_2</th>\n",
       "      <th>PCA_3</th>\n",
       "      <th>PCA_4</th>\n",
       "      <th>PCA_5</th>\n",
       "      <th>PCA_6</th>\n",
       "      <th>PCA_7</th>\n",
       "      <th>PCA_8</th>\n",
       "      <th>PCA_9</th>\n",
       "      <th>PCA_10</th>\n",
       "      <th>PCA_11</th>\n",
       "      <th>PCA_12</th>\n",
       "      <th>PCA_13</th>\n",
       "      <th>PCA_14</th>\n",
       "      <th>PCA_15</th>\n",
       "      <th>PCA_16</th>\n",
       "      <th>PCA_17</th>\n",
       "      <th>PCA_18</th>\n",
       "      <th>PCA_19</th>\n",
       "      <th>PCA_20</th>\n",
       "      <th>PCA_21</th>\n",
       "      <th>PCA_22</th>\n",
       "      <th>PCA_23</th>\n",
       "      <th>PCA_24</th>\n",
       "      <th>PCA_25</th>\n",
       "      <th>PCA_26</th>\n",
       "      <th>PCA_27</th>\n",
       "      <th>PCA_28</th>\n",
       "      <th>PCA_29</th>\n",
       "      <th>PCA_30</th>\n",
       "      <th>PCA_31</th>\n",
       "      <th>PCA_32</th>\n",
       "      <th>PCA_33</th>\n",
       "      <th>PCA_34</th>\n",
       "      <th>PCA_35</th>\n",
       "      <th>PCA_36</th>\n",
       "      <th>PCA_37</th>\n",
       "      <th>PCA_38</th>\n",
       "      <th>PCA_39</th>\n",
       "      <th>PCA_40</th>\n",
       "      <th>PCA_41</th>\n",
       "      <th>PCA_42</th>\n",
       "      <th>PCA_43</th>\n",
       "      <th>PCA_44</th>\n",
       "      <th>PCA_45</th>\n",
       "      <th>PCA_46</th>\n",
       "      <th>PCA_47</th>\n",
       "      <th>PCA_48</th>\n",
       "      <th>PCA_49</th>\n",
       "      <th>PCA_50</th>\n",
       "      <th>PCA_51</th>\n",
       "      <th>PCA_52</th>\n",
       "      <th>PCA_53</th>\n",
       "      <th>PCA_54</th>\n",
       "      <th>PCA_55</th>\n",
       "      <th>PCA_56</th>\n",
       "      <th>PCA_57</th>\n",
       "      <th>PCA_58</th>\n",
       "      <th>PCA_59</th>\n",
       "      <th>PCA_60</th>\n",
       "      <th>PCA_61</th>\n",
       "      <th>PCA_62</th>\n",
       "      <th>PCA_63</th>\n",
       "      <th>PCA_64</th>\n",
       "      <th>PCA_65</th>\n",
       "      <th>PCA_66</th>\n",
       "      <th>PCA_67</th>\n",
       "      <th>PCA_68</th>\n",
       "      <th>PCA_69</th>\n",
       "      <th>PCA_70</th>\n",
       "      <th>PCA_71</th>\n",
       "      <th>PCA_72</th>\n",
       "      <th>PCA_73</th>\n",
       "      <th>PCA_74</th>\n",
       "      <th>PCA_75</th>\n",
       "      <th>PCA_76</th>\n",
       "      <th>PCA_77</th>\n",
       "      <th>DCA_1</th>\n",
       "      <th>DCA_2</th>\n",
       "      <th>DCA_3</th>\n",
       "      <th>DCA_4</th>\n",
       "      <th>DCA_5</th>\n",
       "      <th>DCA_6</th>\n",
       "      <th>DCA_7</th>\n",
       "      <th>DCA_8</th>\n",
       "      <th>DCA_9</th>\n",
       "      <th>DCA_10</th>\n",
       "      <th>DCA_11</th>\n",
       "      <th>DCA_12</th>\n",
       "      <th>DCA_13</th>\n",
       "      <th>DCA_14</th>\n",
       "      <th>DCA_15</th>\n",
       "      <th>DCA_16</th>\n",
       "      <th>DCA_17</th>\n",
       "      <th>DCA_18</th>\n",
       "      <th>DCA_19</th>\n",
       "      <th>DCA_20</th>\n",
       "      <th>DCA_21</th>\n",
       "      <th>DCA_22</th>\n",
       "      <th>DCA_23</th>\n",
       "      <th>DCA_24</th>\n",
       "      <th>DCA_25</th>\n",
       "      <th>DCA_26</th>\n",
       "      <th>DCA_27</th>\n",
       "      <th>DCA_28</th>\n",
       "      <th>DCA_29</th>\n",
       "      <th>DCA_30</th>\n",
       "      <th>DCA_31</th>\n",
       "      <th>DCA_32</th>\n",
       "      <th>DCA_33</th>\n",
       "      <th>DCA_34</th>\n",
       "      <th>DCA_35</th>\n",
       "      <th>DCA_36</th>\n",
       "      <th>DCA_37</th>\n",
       "      <th>DCA_38</th>\n",
       "      <th>DCA_39</th>\n",
       "      <th>DCA_40</th>\n",
       "      <th>DCA_41</th>\n",
       "      <th>DCA_42</th>\n",
       "      <th>DCA_43</th>\n",
       "      <th>DCA_44</th>\n",
       "      <th>DCA_45</th>\n",
       "      <th>DCA_46</th>\n",
       "      <th>DCA_47</th>\n",
       "      <th>DCA_48</th>\n",
       "      <th>DCA_49</th>\n",
       "      <th>DCA_50</th>\n",
       "      <th>DCA_51</th>\n",
       "      <th>DCA_52</th>\n",
       "      <th>DCA_53</th>\n",
       "      <th>DCA_54</th>\n",
       "      <th>DCA_55</th>\n",
       "      <th>DCA_56</th>\n",
       "      <th>DCA_57</th>\n",
       "      <th>DCA_58</th>\n",
       "      <th>DCA_59</th>\n",
       "      <th>DCA_60</th>\n",
       "      <th>DCA_61</th>\n",
       "      <th>DCA_62</th>\n",
       "      <th>DCA_63</th>\n",
       "      <th>DCA_64</th>\n",
       "      <th>DCA_65</th>\n",
       "      <th>DCA_66</th>\n",
       "      <th>DCA_67</th>\n",
       "      <th>DCA_68</th>\n",
       "      <th>DCA_69</th>\n",
       "      <th>DCA_70</th>\n",
       "      <th>DCA_71</th>\n",
       "      <th>DCA_72</th>\n",
       "      <th>DCA_73</th>\n",
       "      <th>DCA_74</th>\n",
       "      <th>DCA_75</th>\n",
       "      <th>DCA_76</th>\n",
       "      <th>DCA_77</th>\n",
       "      <th>temp</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>January</th>\n",
       "      <th>February</th>\n",
       "      <th>March</th>\n",
       "      <th>April</th>\n",
       "      <th>May</th>\n",
       "      <th>June</th>\n",
       "      <th>July</th>\n",
       "      <th>August</th>\n",
       "      <th>September</th>\n",
       "      <th>October</th>\n",
       "      <th>November</th>\n",
       "      <th>December</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be9de796ab2abcbae1d77ced9d9d21021e2284a4</td>\n",
       "      <td>2019-04-23 05:45:00</td>\n",
       "      <td>377.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>41.898306</td>\n",
       "      <td>-87.653614</td>\n",
       "      <td>-87.722611</td>\n",
       "      <td>41.950078</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>57.34</td>\n",
       "      <td>52.83</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90753342407656d346d0319811e6cfaa71431283</td>\n",
       "      <td>2019-04-11 17:30:00</td>\n",
       "      <td>959.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>41.914747</td>\n",
       "      <td>-87.654007</td>\n",
       "      <td>-87.631864</td>\n",
       "      <td>41.892042</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>57.00</td>\n",
       "      <td>53.96</td>\n",
       "      <td>1000.8</td>\n",
       "      <td>79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4a813a48ec90afec16c42c360cd3ff584679bdaf</td>\n",
       "      <td>2019-04-13 05:45:00</td>\n",
       "      <td>758.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>41.922761</td>\n",
       "      <td>-87.699155</td>\n",
       "      <td>-87.625192</td>\n",
       "      <td>41.878866</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>37.08</td>\n",
       "      <td>29.53</td>\n",
       "      <td>1016.7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c27a1dcc7a9c12b27a25b1f558ebd238b09eafd8</td>\n",
       "      <td>2019-04-03 14:15:00</td>\n",
       "      <td>604.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>41.745842</td>\n",
       "      <td>-87.591708</td>\n",
       "      <td>-87.581350</td>\n",
       "      <td>41.769690</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>56.68</td>\n",
       "      <td>42.28</td>\n",
       "      <td>1024.7</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dfb927c00257464d44ed91cbfc3f903436d8dad1</td>\n",
       "      <td>2019-04-03 19:45:00</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "      <td>41.986712</td>\n",
       "      <td>-87.663416</td>\n",
       "      <td>-87.633308</td>\n",
       "      <td>41.899602</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>56.03</td>\n",
       "      <td>48.92</td>\n",
       "      <td>1023.9</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Trip ID Trip Start Timestamp  \\\n",
       "0  be9de796ab2abcbae1d77ced9d9d21021e2284a4  2019-04-23 05:45:00   \n",
       "1  90753342407656d346d0319811e6cfaa71431283  2019-04-11 17:30:00   \n",
       "2  4a813a48ec90afec16c42c360cd3ff584679bdaf  2019-04-13 05:45:00   \n",
       "3  c27a1dcc7a9c12b27a25b1f558ebd238b09eafd8  2019-04-03 14:15:00   \n",
       "4  dfb927c00257464d44ed91cbfc3f903436d8dad1  2019-04-03 19:45:00   \n",
       "\n",
       "   Trip Seconds  Fare  Trip Miles  Pickup Community Area  \\\n",
       "0         377.0   7.5         3.9                     24   \n",
       "1         959.0   7.5         2.5                      7   \n",
       "2         758.0  10.0         5.3                     22   \n",
       "3         604.0   7.5         2.0                     45   \n",
       "4        1023.0  12.5         7.7                     77   \n",
       "\n",
       "   Dropoff Community Area  Pickup Centroid Latitude  \\\n",
       "0                      16                 41.898306   \n",
       "1                       8                 41.914747   \n",
       "2                      32                 41.922761   \n",
       "3                      43                 41.745842   \n",
       "4                       8                 41.986712   \n",
       "\n",
       "   Pickup Centroid Longitude  Dropoff Centroid Longitude  \\\n",
       "0                 -87.653614                  -87.722611   \n",
       "1                 -87.654007                  -87.631864   \n",
       "2                 -87.699155                  -87.625192   \n",
       "3                 -87.591708                  -87.581350   \n",
       "4                 -87.663416                  -87.633308   \n",
       "\n",
       "   Dropoff Centroid Latitude Mon Tue Wed Thu Fri Sat Sun Time_0_0 Time_0_15  \\\n",
       "0                  41.950078   f   t   f   f   f   f   f        f         f   \n",
       "1                  41.892042   f   f   f   t   f   f   f        f         f   \n",
       "2                  41.878866   f   f   f   f   f   t   f        f         f   \n",
       "3                  41.769690   f   f   t   f   f   f   f        f         f   \n",
       "4                  41.899602   f   f   t   f   f   f   f        f         f   \n",
       "\n",
       "  Time_0_30 Time_0_45 Time_1_0 Time_1_15 Time_1_30 Time_1_45 Time_2_0  \\\n",
       "0         f         f        f         f         f         f        f   \n",
       "1         f         f        f         f         f         f        f   \n",
       "2         f         f        f         f         f         f        f   \n",
       "3         f         f        f         f         f         f        f   \n",
       "4         f         f        f         f         f         f        f   \n",
       "\n",
       "  Time_2_15 Time_2_30 Time_2_45 Time_3_0 Time_3_15 Time_3_30 Time_3_45  \\\n",
       "0         f         f         f        f         f         f         f   \n",
       "1         f         f         f        f         f         f         f   \n",
       "2         f         f         f        f         f         f         f   \n",
       "3         f         f         f        f         f         f         f   \n",
       "4         f         f         f        f         f         f         f   \n",
       "\n",
       "  Time_4_0 Time_4_15 Time_4_30 Time_4_45 Time_5_0 Time_5_15 Time_5_30  \\\n",
       "0        f         f         f         f        f         f         f   \n",
       "1        f         f         f         f        f         f         f   \n",
       "2        f         f         f         f        f         f         f   \n",
       "3        f         f         f         f        f         f         f   \n",
       "4        f         f         f         f        f         f         f   \n",
       "\n",
       "  Time_5_45 Time_6_0 Time_6_15 Time_6_30 Time_6_45 Time_7_0 Time_7_15  \\\n",
       "0         t        f         f         f         f        f         f   \n",
       "1         f        f         f         f         f        f         f   \n",
       "2         t        f         f         f         f        f         f   \n",
       "3         f        f         f         f         f        f         f   \n",
       "4         f        f         f         f         f        f         f   \n",
       "\n",
       "  Time_7_30 Time_7_45 Time_8_0 Time_8_15 Time_8_30 Time_8_45 Time_9_0  \\\n",
       "0         f         f        f         f         f         f        f   \n",
       "1         f         f        f         f         f         f        f   \n",
       "2         f         f        f         f         f         f        f   \n",
       "3         f         f        f         f         f         f        f   \n",
       "4         f         f        f         f         f         f        f   \n",
       "\n",
       "  Time_9_15 Time_9_30 Time_9_45 Time_10_0 Time_10_15 Time_10_30 Time_10_45  \\\n",
       "0         f         f         f         f          f          f          f   \n",
       "1         f         f         f         f          f          f          f   \n",
       "2         f         f         f         f          f          f          f   \n",
       "3         f         f         f         f          f          f          f   \n",
       "4         f         f         f         f          f          f          f   \n",
       "\n",
       "  Time_11_0 Time_11_15 Time_11_30 Time_11_45 Time_12_0 Time_12_15 Time_12_30  \\\n",
       "0         f          f          f          f         f          f          f   \n",
       "1         f          f          f          f         f          f          f   \n",
       "2         f          f          f          f         f          f          f   \n",
       "3         f          f          f          f         f          f          f   \n",
       "4         f          f          f          f         f          f          f   \n",
       "\n",
       "  Time_12_45 Time_13_0 Time_13_15 Time_13_30 Time_13_45 Time_14_0 Time_14_15  \\\n",
       "0          f         f          f          f          f         f          f   \n",
       "1          f         f          f          f          f         f          f   \n",
       "2          f         f          f          f          f         f          f   \n",
       "3          f         f          f          f          f         f          t   \n",
       "4          f         f          f          f          f         f          f   \n",
       "\n",
       "  Time_14_30 Time_14_45 Time_15_0 Time_15_15 Time_15_30 Time_15_45 Time_16_0  \\\n",
       "0          f          f         f          f          f          f         f   \n",
       "1          f          f         f          f          f          f         f   \n",
       "2          f          f         f          f          f          f         f   \n",
       "3          f          f         f          f          f          f         f   \n",
       "4          f          f         f          f          f          f         f   \n",
       "\n",
       "  Time_16_15 Time_16_30 Time_16_45 Time_17_0 Time_17_15 Time_17_30 Time_17_45  \\\n",
       "0          f          f          f         f          f          f          f   \n",
       "1          f          f          f         f          f          t          f   \n",
       "2          f          f          f         f          f          f          f   \n",
       "3          f          f          f         f          f          f          f   \n",
       "4          f          f          f         f          f          f          f   \n",
       "\n",
       "  Time_18_0 Time_18_15 Time_18_30 Time_18_45 Time_19_0 Time_19_15 Time_19_30  \\\n",
       "0         f          f          f          f         f          f          f   \n",
       "1         f          f          f          f         f          f          f   \n",
       "2         f          f          f          f         f          f          f   \n",
       "3         f          f          f          f         f          f          f   \n",
       "4         f          f          f          f         f          f          f   \n",
       "\n",
       "  Time_19_45 Time_20_0 Time_20_15 Time_20_30 Time_20_45 Time_21_0 Time_21_15  \\\n",
       "0          f         f          f          f          f         f          f   \n",
       "1          f         f          f          f          f         f          f   \n",
       "2          f         f          f          f          f         f          f   \n",
       "3          f         f          f          f          f         f          f   \n",
       "4          t         f          f          f          f         f          f   \n",
       "\n",
       "  Time_21_30 Time_21_45 Time_22_0 Time_22_15 Time_22_30 Time_22_45 Time_23_0  \\\n",
       "0          f          f         f          f          f          f         f   \n",
       "1          f          f         f          f          f          f         f   \n",
       "2          f          f         f          f          f          f         f   \n",
       "3          f          f         f          f          f          f         f   \n",
       "4          f          f         f          f          f          f         f   \n",
       "\n",
       "  Time_23_15 Time_23_30 Time_23_45 PCA_1 PCA_2 PCA_3 PCA_4 PCA_5 PCA_6 PCA_7  \\\n",
       "0          f          f          f     f     f     f     f     f     f     f   \n",
       "1          f          f          f     f     f     f     f     f     f     t   \n",
       "2          f          f          f     f     f     f     f     f     f     f   \n",
       "3          f          f          f     f     f     f     f     f     f     f   \n",
       "4          f          f          f     f     f     f     f     f     f     f   \n",
       "\n",
       "  PCA_8 PCA_9 PCA_10 PCA_11 PCA_12 PCA_13 PCA_14 PCA_15 PCA_16 PCA_17 PCA_18  \\\n",
       "0     f     f      f      f      f      f      f      f      f      f      f   \n",
       "1     f     f      f      f      f      f      f      f      f      f      f   \n",
       "2     f     f      f      f      f      f      f      f      f      f      f   \n",
       "3     f     f      f      f      f      f      f      f      f      f      f   \n",
       "4     f     f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_19 PCA_20 PCA_21 PCA_22 PCA_23 PCA_24 PCA_25 PCA_26 PCA_27 PCA_28  \\\n",
       "0      f      f      f      f      f      t      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      t      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_29 PCA_30 PCA_31 PCA_32 PCA_33 PCA_34 PCA_35 PCA_36 PCA_37 PCA_38  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_39 PCA_40 PCA_41 PCA_42 PCA_43 PCA_44 PCA_45 PCA_46 PCA_47 PCA_48  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      t      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_49 PCA_50 PCA_51 PCA_52 PCA_53 PCA_54 PCA_55 PCA_56 PCA_57 PCA_58  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_59 PCA_60 PCA_61 PCA_62 PCA_63 PCA_64 PCA_65 PCA_66 PCA_67 PCA_68  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  PCA_69 PCA_70 PCA_71 PCA_72 PCA_73 PCA_74 PCA_75 PCA_76 PCA_77 DCA_1 DCA_2  \\\n",
       "0      f      f      f      f      f      f      f      f      f     f     f   \n",
       "1      f      f      f      f      f      f      f      f      f     f     f   \n",
       "2      f      f      f      f      f      f      f      f      f     f     f   \n",
       "3      f      f      f      f      f      f      f      f      f     f     f   \n",
       "4      f      f      f      f      f      f      f      f      t     f     f   \n",
       "\n",
       "  DCA_3 DCA_4 DCA_5 DCA_6 DCA_7 DCA_8 DCA_9 DCA_10 DCA_11 DCA_12 DCA_13  \\\n",
       "0     f     f     f     f     f     f     f      f      f      f      f   \n",
       "1     f     f     f     f     f     t     f      f      f      f      f   \n",
       "2     f     f     f     f     f     f     f      f      f      f      f   \n",
       "3     f     f     f     f     f     f     f      f      f      f      f   \n",
       "4     f     f     f     f     f     t     f      f      f      f      f   \n",
       "\n",
       "  DCA_14 DCA_15 DCA_16 DCA_17 DCA_18 DCA_19 DCA_20 DCA_21 DCA_22 DCA_23  \\\n",
       "0      f      f      t      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_24 DCA_25 DCA_26 DCA_27 DCA_28 DCA_29 DCA_30 DCA_31 DCA_32 DCA_33  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      t      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_34 DCA_35 DCA_36 DCA_37 DCA_38 DCA_39 DCA_40 DCA_41 DCA_42 DCA_43  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      t   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_44 DCA_45 DCA_46 DCA_47 DCA_48 DCA_49 DCA_50 DCA_51 DCA_52 DCA_53  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_54 DCA_55 DCA_56 DCA_57 DCA_58 DCA_59 DCA_60 DCA_61 DCA_62 DCA_63  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_64 DCA_65 DCA_66 DCA_67 DCA_68 DCA_69 DCA_70 DCA_71 DCA_72 DCA_73  \\\n",
       "0      f      f      f      f      f      f      f      f      f      f   \n",
       "1      f      f      f      f      f      f      f      f      f      f   \n",
       "2      f      f      f      f      f      f      f      f      f      f   \n",
       "3      f      f      f      f      f      f      f      f      f      f   \n",
       "4      f      f      f      f      f      f      f      f      f      f   \n",
       "\n",
       "  DCA_74 DCA_75 DCA_76 DCA_77   temp  feels_like  pressure  humidity  rain_1h  \\\n",
       "0      f      f      f      f  57.34       52.83    1010.8        89      0.0   \n",
       "1      f      f      f      f  57.00       53.96    1000.8        79      0.0   \n",
       "2      f      f      f      f  37.08       29.53    1016.7        52      0.0   \n",
       "3      f      f      f      f  56.68       42.28    1024.7        27      0.0   \n",
       "4      f      f      f      f  56.03       48.92    1023.9        37      0.0   \n",
       "\n",
       "   snow_1h  January  February  March  April  May  June  July  August  \\\n",
       "0      0.0        0         0      0      1    0     0     0       0   \n",
       "1      0.0        0         0      0      1    0     0     0       0   \n",
       "2      0.0        0         0      0      1    0     0     0       0   \n",
       "3      0.0        0         0      0      1    0     0     0       0   \n",
       "4      0.0        0         0      0      1    0     0     0       0   \n",
       "\n",
       "   September  October  November  December  \n",
       "0          0        0         0         0  \n",
       "1          0        0         0         0  \n",
       "2          0        0         0         0  \n",
       "3          0        0         0         0  \n",
       "4          0        0         0         0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f    1031278\n",
       "t     168722\n",
       "Name: Thu, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# values_df['Mon'].value_counts()\n",
    "# values_df['Tue'].value_counts()\n",
    "# values_df['Wed'].value_counts()\n",
    "values_df['Thu'].value_counts()\n",
    "# values_df['Fri'].value_counts()\n",
    "# values_df['Sat'].value_counts()\n",
    "# values_df['Sun'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't mess with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = values_df.drop(['Trip ID', 'Trip Start Timestamp'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_df = pd.read_csv('Extract_with_headers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initial_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = initial_df.drop(['Trip ID', 'Trip Start Timestamp', 'PCA_77', 'DCA_77'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop N/A values, then create X/y split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['Fare'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm X and y have same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1197590, 283)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1197590"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip Seconds\n",
      "Trip Miles\n",
      "Pickup Community Area\n",
      "Dropoff Community Area\n",
      "Pickup Centroid Latitude\n",
      "Pickup Centroid Longitude\n",
      "Dropoff Centroid Longitude\n",
      "Dropoff Centroid Latitude\n",
      "Mon\n",
      "Tue\n",
      "Wed\n",
      "Thu\n",
      "Fri\n",
      "Sat\n",
      "Sun\n",
      "Time_0_0\n",
      "Time_0_15\n",
      "Time_0_30\n",
      "Time_0_45\n",
      "Time_1_0\n",
      "Time_1_15\n",
      "Time_1_30\n",
      "Time_1_45\n",
      "Time_2_0\n",
      "Time_2_15\n",
      "Time_2_30\n",
      "Time_2_45\n",
      "Time_3_0\n",
      "Time_3_15\n",
      "Time_3_30\n",
      "Time_3_45\n",
      "Time_4_0\n",
      "Time_4_15\n",
      "Time_4_30\n",
      "Time_4_45\n",
      "Time_5_0\n",
      "Time_5_15\n",
      "Time_5_30\n",
      "Time_5_45\n",
      "Time_6_0\n",
      "Time_6_15\n",
      "Time_6_30\n",
      "Time_6_45\n",
      "Time_7_0\n",
      "Time_7_15\n",
      "Time_7_30\n",
      "Time_7_45\n",
      "Time_8_0\n",
      "Time_8_15\n",
      "Time_8_30\n",
      "Time_8_45\n",
      "Time_9_0\n",
      "Time_9_15\n",
      "Time_9_30\n",
      "Time_9_45\n",
      "Time_10_0\n",
      "Time_10_15\n",
      "Time_10_30\n",
      "Time_10_45\n",
      "Time_11_0\n",
      "Time_11_15\n",
      "Time_11_30\n",
      "Time_11_45\n",
      "Time_12_0\n",
      "Time_12_15\n",
      "Time_12_30\n",
      "Time_12_45\n",
      "Time_13_0\n",
      "Time_13_15\n",
      "Time_13_30\n",
      "Time_13_45\n",
      "Time_14_0\n",
      "Time_14_15\n",
      "Time_14_30\n",
      "Time_14_45\n",
      "Time_15_0\n",
      "Time_15_15\n",
      "Time_15_30\n",
      "Time_15_45\n",
      "Time_16_0\n",
      "Time_16_15\n",
      "Time_16_30\n",
      "Time_16_45\n",
      "Time_17_0\n",
      "Time_17_15\n",
      "Time_17_30\n",
      "Time_17_45\n",
      "Time_18_0\n",
      "Time_18_15\n",
      "Time_18_30\n",
      "Time_18_45\n",
      "Time_19_0\n",
      "Time_19_15\n",
      "Time_19_30\n",
      "Time_19_45\n",
      "Time_20_0\n",
      "Time_20_15\n",
      "Time_20_30\n",
      "Time_20_45\n",
      "Time_21_0\n",
      "Time_21_15\n",
      "Time_21_30\n",
      "Time_21_45\n",
      "Time_22_0\n",
      "Time_22_15\n",
      "Time_22_30\n",
      "Time_22_45\n",
      "Time_23_0\n",
      "Time_23_15\n",
      "Time_23_30\n",
      "Time_23_45\n",
      "PCA_1\n",
      "PCA_2\n",
      "PCA_3\n",
      "PCA_4\n",
      "PCA_5\n",
      "PCA_6\n",
      "PCA_7\n",
      "PCA_8\n",
      "PCA_9\n",
      "PCA_10\n",
      "PCA_11\n",
      "PCA_12\n",
      "PCA_13\n",
      "PCA_14\n",
      "PCA_15\n",
      "PCA_16\n",
      "PCA_17\n",
      "PCA_18\n",
      "PCA_19\n",
      "PCA_20\n",
      "PCA_21\n",
      "PCA_22\n",
      "PCA_23\n",
      "PCA_24\n",
      "PCA_25\n",
      "PCA_26\n",
      "PCA_27\n",
      "PCA_28\n",
      "PCA_29\n",
      "PCA_30\n",
      "PCA_31\n",
      "PCA_32\n",
      "PCA_33\n",
      "PCA_34\n",
      "PCA_35\n",
      "PCA_36\n",
      "PCA_37\n",
      "PCA_38\n",
      "PCA_39\n",
      "PCA_40\n",
      "PCA_41\n",
      "PCA_42\n",
      "PCA_43\n",
      "PCA_44\n",
      "PCA_45\n",
      "PCA_46\n",
      "PCA_47\n",
      "PCA_48\n",
      "PCA_49\n",
      "PCA_50\n",
      "PCA_51\n",
      "PCA_52\n",
      "PCA_53\n",
      "PCA_54\n",
      "PCA_55\n",
      "PCA_56\n",
      "PCA_57\n",
      "PCA_58\n",
      "PCA_59\n",
      "PCA_60\n",
      "PCA_61\n",
      "PCA_62\n",
      "PCA_63\n",
      "PCA_64\n",
      "PCA_65\n",
      "PCA_66\n",
      "PCA_67\n",
      "PCA_68\n",
      "PCA_69\n",
      "PCA_70\n",
      "PCA_71\n",
      "PCA_72\n",
      "PCA_73\n",
      "PCA_74\n",
      "PCA_75\n",
      "PCA_76\n",
      "PCA_77\n",
      "DCA_1\n",
      "DCA_2\n",
      "DCA_3\n",
      "DCA_4\n",
      "DCA_5\n",
      "DCA_6\n",
      "DCA_7\n",
      "DCA_8\n",
      "DCA_9\n",
      "DCA_10\n",
      "DCA_11\n",
      "DCA_12\n",
      "DCA_13\n",
      "DCA_14\n",
      "DCA_15\n",
      "DCA_16\n",
      "DCA_17\n",
      "DCA_18\n",
      "DCA_19\n",
      "DCA_20\n",
      "DCA_21\n",
      "DCA_22\n",
      "DCA_23\n",
      "DCA_24\n",
      "DCA_25\n",
      "DCA_26\n",
      "DCA_27\n",
      "DCA_28\n",
      "DCA_29\n",
      "DCA_30\n",
      "DCA_31\n",
      "DCA_32\n",
      "DCA_33\n",
      "DCA_34\n",
      "DCA_35\n",
      "DCA_36\n",
      "DCA_37\n",
      "DCA_38\n",
      "DCA_39\n",
      "DCA_40\n",
      "DCA_41\n",
      "DCA_42\n",
      "DCA_43\n",
      "DCA_44\n",
      "DCA_45\n",
      "DCA_46\n",
      "DCA_47\n",
      "DCA_48\n",
      "DCA_49\n",
      "DCA_50\n",
      "DCA_51\n",
      "DCA_52\n",
      "DCA_53\n",
      "DCA_54\n",
      "DCA_55\n",
      "DCA_56\n",
      "DCA_57\n",
      "DCA_58\n",
      "DCA_59\n",
      "DCA_60\n",
      "DCA_61\n",
      "DCA_62\n",
      "DCA_63\n",
      "DCA_64\n",
      "DCA_65\n",
      "DCA_66\n",
      "DCA_67\n",
      "DCA_68\n",
      "DCA_69\n",
      "DCA_70\n",
      "DCA_71\n",
      "DCA_72\n",
      "DCA_73\n",
      "DCA_74\n",
      "DCA_75\n",
      "DCA_76\n",
      "DCA_77\n",
      "temp\n",
      "feels_like\n",
      "pressure\n",
      "humidity\n",
      "rain_1h\n",
      "snow_1h\n",
      "January\n",
      "February\n",
      "March\n",
      "April\n",
      "May\n",
      "June\n",
      "July\n",
      "August\n",
      "September\n",
      "October\n",
      "November\n",
      "December\n"
     ]
    }
   ],
   "source": [
    "for column in range(len(X.columns)):\n",
    "    print(X.columns[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace 't', 'f' with 1,0 for Boolean analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in X.iterrows():\n",
    "#     print(f'Beginning analysis on index = {index}')\n",
    "#     for j in range(len(X.columns)):\n",
    "#         if(X.at[index, X.columns[j]]) == 'f':\n",
    "#             X.at[index, X.columns[j]] = 0\n",
    "#         elif(X.at[index, X.columns[j]]) == 't':\n",
    "#             X.at[index, X.columns[j]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.replace({'f': 0, 't':1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip Seconds</th>\n",
       "      <th>Trip Miles</th>\n",
       "      <th>Pickup Community Area</th>\n",
       "      <th>Dropoff Community Area</th>\n",
       "      <th>Pickup Centroid Latitude</th>\n",
       "      <th>Pickup Centroid Longitude</th>\n",
       "      <th>Dropoff Centroid Longitude</th>\n",
       "      <th>Dropoff Centroid Latitude</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>Thu</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>Time_0_0</th>\n",
       "      <th>Time_0_15</th>\n",
       "      <th>Time_0_30</th>\n",
       "      <th>Time_0_45</th>\n",
       "      <th>Time_1_0</th>\n",
       "      <th>Time_1_15</th>\n",
       "      <th>Time_1_30</th>\n",
       "      <th>Time_1_45</th>\n",
       "      <th>Time_2_0</th>\n",
       "      <th>Time_2_15</th>\n",
       "      <th>Time_2_30</th>\n",
       "      <th>Time_2_45</th>\n",
       "      <th>Time_3_0</th>\n",
       "      <th>Time_3_15</th>\n",
       "      <th>Time_3_30</th>\n",
       "      <th>Time_3_45</th>\n",
       "      <th>Time_4_0</th>\n",
       "      <th>Time_4_15</th>\n",
       "      <th>Time_4_30</th>\n",
       "      <th>Time_4_45</th>\n",
       "      <th>Time_5_0</th>\n",
       "      <th>Time_5_15</th>\n",
       "      <th>Time_5_30</th>\n",
       "      <th>Time_5_45</th>\n",
       "      <th>Time_6_0</th>\n",
       "      <th>Time_6_15</th>\n",
       "      <th>Time_6_30</th>\n",
       "      <th>Time_6_45</th>\n",
       "      <th>Time_7_0</th>\n",
       "      <th>Time_7_15</th>\n",
       "      <th>Time_7_30</th>\n",
       "      <th>Time_7_45</th>\n",
       "      <th>Time_8_0</th>\n",
       "      <th>Time_8_15</th>\n",
       "      <th>Time_8_30</th>\n",
       "      <th>Time_8_45</th>\n",
       "      <th>Time_9_0</th>\n",
       "      <th>Time_9_15</th>\n",
       "      <th>Time_9_30</th>\n",
       "      <th>Time_9_45</th>\n",
       "      <th>Time_10_0</th>\n",
       "      <th>Time_10_15</th>\n",
       "      <th>Time_10_30</th>\n",
       "      <th>Time_10_45</th>\n",
       "      <th>Time_11_0</th>\n",
       "      <th>Time_11_15</th>\n",
       "      <th>Time_11_30</th>\n",
       "      <th>Time_11_45</th>\n",
       "      <th>Time_12_0</th>\n",
       "      <th>Time_12_15</th>\n",
       "      <th>Time_12_30</th>\n",
       "      <th>Time_12_45</th>\n",
       "      <th>Time_13_0</th>\n",
       "      <th>Time_13_15</th>\n",
       "      <th>Time_13_30</th>\n",
       "      <th>Time_13_45</th>\n",
       "      <th>Time_14_0</th>\n",
       "      <th>Time_14_15</th>\n",
       "      <th>Time_14_30</th>\n",
       "      <th>Time_14_45</th>\n",
       "      <th>Time_15_0</th>\n",
       "      <th>Time_15_15</th>\n",
       "      <th>Time_15_30</th>\n",
       "      <th>Time_15_45</th>\n",
       "      <th>Time_16_0</th>\n",
       "      <th>Time_16_15</th>\n",
       "      <th>Time_16_30</th>\n",
       "      <th>Time_16_45</th>\n",
       "      <th>Time_17_0</th>\n",
       "      <th>Time_17_15</th>\n",
       "      <th>Time_17_30</th>\n",
       "      <th>Time_17_45</th>\n",
       "      <th>Time_18_0</th>\n",
       "      <th>Time_18_15</th>\n",
       "      <th>Time_18_30</th>\n",
       "      <th>Time_18_45</th>\n",
       "      <th>Time_19_0</th>\n",
       "      <th>Time_19_15</th>\n",
       "      <th>Time_19_30</th>\n",
       "      <th>Time_19_45</th>\n",
       "      <th>Time_20_0</th>\n",
       "      <th>Time_20_15</th>\n",
       "      <th>Time_20_30</th>\n",
       "      <th>Time_20_45</th>\n",
       "      <th>Time_21_0</th>\n",
       "      <th>Time_21_15</th>\n",
       "      <th>Time_21_30</th>\n",
       "      <th>Time_21_45</th>\n",
       "      <th>Time_22_0</th>\n",
       "      <th>Time_22_15</th>\n",
       "      <th>Time_22_30</th>\n",
       "      <th>Time_22_45</th>\n",
       "      <th>Time_23_0</th>\n",
       "      <th>Time_23_15</th>\n",
       "      <th>Time_23_30</th>\n",
       "      <th>Time_23_45</th>\n",
       "      <th>PCA_1</th>\n",
       "      <th>PCA_2</th>\n",
       "      <th>PCA_3</th>\n",
       "      <th>PCA_4</th>\n",
       "      <th>PCA_5</th>\n",
       "      <th>PCA_6</th>\n",
       "      <th>PCA_7</th>\n",
       "      <th>PCA_8</th>\n",
       "      <th>PCA_9</th>\n",
       "      <th>PCA_10</th>\n",
       "      <th>PCA_11</th>\n",
       "      <th>PCA_12</th>\n",
       "      <th>PCA_13</th>\n",
       "      <th>PCA_14</th>\n",
       "      <th>PCA_15</th>\n",
       "      <th>PCA_16</th>\n",
       "      <th>PCA_17</th>\n",
       "      <th>PCA_18</th>\n",
       "      <th>PCA_19</th>\n",
       "      <th>PCA_20</th>\n",
       "      <th>PCA_21</th>\n",
       "      <th>PCA_22</th>\n",
       "      <th>PCA_23</th>\n",
       "      <th>PCA_24</th>\n",
       "      <th>PCA_25</th>\n",
       "      <th>PCA_26</th>\n",
       "      <th>PCA_27</th>\n",
       "      <th>PCA_28</th>\n",
       "      <th>PCA_29</th>\n",
       "      <th>PCA_30</th>\n",
       "      <th>PCA_31</th>\n",
       "      <th>PCA_32</th>\n",
       "      <th>PCA_33</th>\n",
       "      <th>PCA_34</th>\n",
       "      <th>PCA_35</th>\n",
       "      <th>PCA_36</th>\n",
       "      <th>PCA_37</th>\n",
       "      <th>PCA_38</th>\n",
       "      <th>PCA_39</th>\n",
       "      <th>PCA_40</th>\n",
       "      <th>PCA_41</th>\n",
       "      <th>PCA_42</th>\n",
       "      <th>PCA_43</th>\n",
       "      <th>PCA_44</th>\n",
       "      <th>PCA_45</th>\n",
       "      <th>PCA_46</th>\n",
       "      <th>PCA_47</th>\n",
       "      <th>PCA_48</th>\n",
       "      <th>PCA_49</th>\n",
       "      <th>PCA_50</th>\n",
       "      <th>PCA_51</th>\n",
       "      <th>PCA_52</th>\n",
       "      <th>PCA_53</th>\n",
       "      <th>PCA_54</th>\n",
       "      <th>PCA_55</th>\n",
       "      <th>PCA_56</th>\n",
       "      <th>PCA_57</th>\n",
       "      <th>PCA_58</th>\n",
       "      <th>PCA_59</th>\n",
       "      <th>PCA_60</th>\n",
       "      <th>PCA_61</th>\n",
       "      <th>PCA_62</th>\n",
       "      <th>PCA_63</th>\n",
       "      <th>PCA_64</th>\n",
       "      <th>PCA_65</th>\n",
       "      <th>PCA_66</th>\n",
       "      <th>PCA_67</th>\n",
       "      <th>PCA_68</th>\n",
       "      <th>PCA_69</th>\n",
       "      <th>PCA_70</th>\n",
       "      <th>PCA_71</th>\n",
       "      <th>PCA_72</th>\n",
       "      <th>PCA_73</th>\n",
       "      <th>PCA_74</th>\n",
       "      <th>PCA_75</th>\n",
       "      <th>PCA_76</th>\n",
       "      <th>PCA_77</th>\n",
       "      <th>DCA_1</th>\n",
       "      <th>DCA_2</th>\n",
       "      <th>DCA_3</th>\n",
       "      <th>DCA_4</th>\n",
       "      <th>DCA_5</th>\n",
       "      <th>DCA_6</th>\n",
       "      <th>DCA_7</th>\n",
       "      <th>DCA_8</th>\n",
       "      <th>DCA_9</th>\n",
       "      <th>DCA_10</th>\n",
       "      <th>DCA_11</th>\n",
       "      <th>DCA_12</th>\n",
       "      <th>DCA_13</th>\n",
       "      <th>DCA_14</th>\n",
       "      <th>DCA_15</th>\n",
       "      <th>DCA_16</th>\n",
       "      <th>DCA_17</th>\n",
       "      <th>DCA_18</th>\n",
       "      <th>DCA_19</th>\n",
       "      <th>DCA_20</th>\n",
       "      <th>DCA_21</th>\n",
       "      <th>DCA_22</th>\n",
       "      <th>DCA_23</th>\n",
       "      <th>DCA_24</th>\n",
       "      <th>DCA_25</th>\n",
       "      <th>DCA_26</th>\n",
       "      <th>DCA_27</th>\n",
       "      <th>DCA_28</th>\n",
       "      <th>DCA_29</th>\n",
       "      <th>DCA_30</th>\n",
       "      <th>DCA_31</th>\n",
       "      <th>DCA_32</th>\n",
       "      <th>DCA_33</th>\n",
       "      <th>DCA_34</th>\n",
       "      <th>DCA_35</th>\n",
       "      <th>DCA_36</th>\n",
       "      <th>DCA_37</th>\n",
       "      <th>DCA_38</th>\n",
       "      <th>DCA_39</th>\n",
       "      <th>DCA_40</th>\n",
       "      <th>DCA_41</th>\n",
       "      <th>DCA_42</th>\n",
       "      <th>DCA_43</th>\n",
       "      <th>DCA_44</th>\n",
       "      <th>DCA_45</th>\n",
       "      <th>DCA_46</th>\n",
       "      <th>DCA_47</th>\n",
       "      <th>DCA_48</th>\n",
       "      <th>DCA_49</th>\n",
       "      <th>DCA_50</th>\n",
       "      <th>DCA_51</th>\n",
       "      <th>DCA_52</th>\n",
       "      <th>DCA_53</th>\n",
       "      <th>DCA_54</th>\n",
       "      <th>DCA_55</th>\n",
       "      <th>DCA_56</th>\n",
       "      <th>DCA_57</th>\n",
       "      <th>DCA_58</th>\n",
       "      <th>DCA_59</th>\n",
       "      <th>DCA_60</th>\n",
       "      <th>DCA_61</th>\n",
       "      <th>DCA_62</th>\n",
       "      <th>DCA_63</th>\n",
       "      <th>DCA_64</th>\n",
       "      <th>DCA_65</th>\n",
       "      <th>DCA_66</th>\n",
       "      <th>DCA_67</th>\n",
       "      <th>DCA_68</th>\n",
       "      <th>DCA_69</th>\n",
       "      <th>DCA_70</th>\n",
       "      <th>DCA_71</th>\n",
       "      <th>DCA_72</th>\n",
       "      <th>DCA_73</th>\n",
       "      <th>DCA_74</th>\n",
       "      <th>DCA_75</th>\n",
       "      <th>DCA_76</th>\n",
       "      <th>DCA_77</th>\n",
       "      <th>temp</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>January</th>\n",
       "      <th>February</th>\n",
       "      <th>March</th>\n",
       "      <th>April</th>\n",
       "      <th>May</th>\n",
       "      <th>June</th>\n",
       "      <th>July</th>\n",
       "      <th>August</th>\n",
       "      <th>September</th>\n",
       "      <th>October</th>\n",
       "      <th>November</th>\n",
       "      <th>December</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>377.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>41.898306</td>\n",
       "      <td>-87.653614</td>\n",
       "      <td>-87.722611</td>\n",
       "      <td>41.950078</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.34</td>\n",
       "      <td>52.83</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>959.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>41.914747</td>\n",
       "      <td>-87.654007</td>\n",
       "      <td>-87.631864</td>\n",
       "      <td>41.892042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.00</td>\n",
       "      <td>53.96</td>\n",
       "      <td>1000.8</td>\n",
       "      <td>79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>758.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>41.922761</td>\n",
       "      <td>-87.699155</td>\n",
       "      <td>-87.625192</td>\n",
       "      <td>41.878866</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.08</td>\n",
       "      <td>29.53</td>\n",
       "      <td>1016.7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>41.745842</td>\n",
       "      <td>-87.591708</td>\n",
       "      <td>-87.581350</td>\n",
       "      <td>41.769690</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.68</td>\n",
       "      <td>42.28</td>\n",
       "      <td>1024.7</td>\n",
       "      <td>27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1023.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "      <td>41.986712</td>\n",
       "      <td>-87.663416</td>\n",
       "      <td>-87.633308</td>\n",
       "      <td>41.899602</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.03</td>\n",
       "      <td>48.92</td>\n",
       "      <td>1023.9</td>\n",
       "      <td>37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>664.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>41.884987</td>\n",
       "      <td>-87.620993</td>\n",
       "      <td>-87.635891</td>\n",
       "      <td>41.929263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.09</td>\n",
       "      <td>45.86</td>\n",
       "      <td>999.1</td>\n",
       "      <td>73</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>787.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>41.885281</td>\n",
       "      <td>-87.657233</td>\n",
       "      <td>-87.649907</td>\n",
       "      <td>41.904935</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.67</td>\n",
       "      <td>35.56</td>\n",
       "      <td>1018.7</td>\n",
       "      <td>100</td>\n",
       "      <td>2.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>843.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>41.898332</td>\n",
       "      <td>-87.620763</td>\n",
       "      <td>-87.624135</td>\n",
       "      <td>41.849247</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.77</td>\n",
       "      <td>35.37</td>\n",
       "      <td>1023.9</td>\n",
       "      <td>100</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>527.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>41.880994</td>\n",
       "      <td>-87.632746</td>\n",
       "      <td>-87.679955</td>\n",
       "      <td>41.920452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.07</td>\n",
       "      <td>24.08</td>\n",
       "      <td>1012.5</td>\n",
       "      <td>93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>325.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>41.944227</td>\n",
       "      <td>-87.655998</td>\n",
       "      <td>-87.655998</td>\n",
       "      <td>41.944227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.88</td>\n",
       "      <td>48.33</td>\n",
       "      <td>1023.2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trip Seconds  Trip Miles  Pickup Community Area  Dropoff Community Area  \\\n",
       "0         377.0         3.9                     24                      16   \n",
       "1         959.0         2.5                      7                       8   \n",
       "2         758.0         5.3                     22                      32   \n",
       "3         604.0         2.0                     45                      43   \n",
       "4        1023.0         7.7                     77                       8   \n",
       "5         664.0         4.2                     32                       7   \n",
       "6         787.0         1.5                     28                       8   \n",
       "7         843.0         5.6                      8                      33   \n",
       "8         527.0         4.5                     32                      22   \n",
       "9         325.0         1.0                      6                       6   \n",
       "\n",
       "   Pickup Centroid Latitude  Pickup Centroid Longitude  \\\n",
       "0                 41.898306                 -87.653614   \n",
       "1                 41.914747                 -87.654007   \n",
       "2                 41.922761                 -87.699155   \n",
       "3                 41.745842                 -87.591708   \n",
       "4                 41.986712                 -87.663416   \n",
       "5                 41.884987                 -87.620993   \n",
       "6                 41.885281                 -87.657233   \n",
       "7                 41.898332                 -87.620763   \n",
       "8                 41.880994                 -87.632746   \n",
       "9                 41.944227                 -87.655998   \n",
       "\n",
       "   Dropoff Centroid Longitude  Dropoff Centroid Latitude  Mon  Tue  Wed  Thu  \\\n",
       "0                  -87.722611                  41.950078    0    1    0    0   \n",
       "1                  -87.631864                  41.892042    0    0    0    1   \n",
       "2                  -87.625192                  41.878866    0    0    0    0   \n",
       "3                  -87.581350                  41.769690    0    0    1    0   \n",
       "4                  -87.633308                  41.899602    0    0    1    0   \n",
       "5                  -87.635891                  41.929263    0    0    0    1   \n",
       "6                  -87.649907                  41.904935    0    1    0    0   \n",
       "7                  -87.624135                  41.849247    0    1    0    0   \n",
       "8                  -87.679955                  41.920452    0    0    0    1   \n",
       "9                  -87.655998                  41.944227    0    0    1    0   \n",
       "\n",
       "   Fri  Sat  Sun  Time_0_0  Time_0_15  Time_0_30  Time_0_45  Time_1_0  \\\n",
       "0    0    0    0         0          0          0          0         0   \n",
       "1    0    0    0         0          0          0          0         0   \n",
       "2    0    1    0         0          0          0          0         0   \n",
       "3    0    0    0         0          0          0          0         0   \n",
       "4    0    0    0         0          0          0          0         0   \n",
       "5    0    0    0         0          0          0          0         0   \n",
       "6    0    0    0         0          0          0          0         0   \n",
       "7    0    0    0         0          0          0          0         0   \n",
       "8    0    0    0         0          0          1          0         0   \n",
       "9    0    0    0         0          0          0          0         0   \n",
       "\n",
       "   Time_1_15  Time_1_30  Time_1_45  Time_2_0  Time_2_15  Time_2_30  Time_2_45  \\\n",
       "0          0          0          0         0          0          0          0   \n",
       "1          0          0          0         0          0          0          0   \n",
       "2          0          0          0         0          0          0          0   \n",
       "3          0          0          0         0          0          0          0   \n",
       "4          0          0          0         0          0          0          0   \n",
       "5          0          0          0         0          0          0          0   \n",
       "6          0          0          0         0          0          0          0   \n",
       "7          0          0          0         0          0          0          0   \n",
       "8          0          0          0         0          0          0          0   \n",
       "9          0          0          0         0          0          0          0   \n",
       "\n",
       "   Time_3_0  Time_3_15  Time_3_30  Time_3_45  Time_4_0  Time_4_15  Time_4_30  \\\n",
       "0         0          0          0          0         0          0          0   \n",
       "1         0          0          0          0         0          0          0   \n",
       "2         0          0          0          0         0          0          0   \n",
       "3         0          0          0          0         0          0          0   \n",
       "4         0          0          0          0         0          0          0   \n",
       "5         0          0          0          0         0          0          0   \n",
       "6         0          0          0          0         0          0          0   \n",
       "7         0          0          0          0         0          0          0   \n",
       "8         0          0          0          0         0          0          0   \n",
       "9         0          0          0          0         0          0          0   \n",
       "\n",
       "   Time_4_45  Time_5_0  Time_5_15  Time_5_30  Time_5_45  Time_6_0  Time_6_15  \\\n",
       "0          0         0          0          0          1         0          0   \n",
       "1          0         0          0          0          0         0          0   \n",
       "2          0         0          0          0          1         0          0   \n",
       "3          0         0          0          0          0         0          0   \n",
       "4          0         0          0          0          0         0          0   \n",
       "5          0         0          0          0          0         0          0   \n",
       "6          0         0          0          0          0         0          0   \n",
       "7          0         0          0          0          0         0          0   \n",
       "8          0         0          0          0          0         0          0   \n",
       "9          0         0          0          0          0         0          0   \n",
       "\n",
       "   Time_6_30  Time_6_45  Time_7_0  Time_7_15  Time_7_30  Time_7_45  Time_8_0  \\\n",
       "0          0          0         0          0          0          0         0   \n",
       "1          0          0         0          0          0          0         0   \n",
       "2          0          0         0          0          0          0         0   \n",
       "3          0          0         0          0          0          0         0   \n",
       "4          0          0         0          0          0          0         0   \n",
       "5          0          0         0          0          0          0         0   \n",
       "6          0          0         0          0          0          0         0   \n",
       "7          0          0         0          0          0          0         0   \n",
       "8          0          0         0          0          0          0         0   \n",
       "9          0          0         0          0          0          0         0   \n",
       "\n",
       "   Time_8_15  Time_8_30  Time_8_45  Time_9_0  Time_9_15  Time_9_30  Time_9_45  \\\n",
       "0          0          0          0         0          0          0          0   \n",
       "1          0          0          0         0          0          0          0   \n",
       "2          0          0          0         0          0          0          0   \n",
       "3          0          0          0         0          0          0          0   \n",
       "4          0          0          0         0          0          0          0   \n",
       "5          0          0          0         0          0          0          0   \n",
       "6          0          0          0         0          0          0          0   \n",
       "7          0          0          0         0          0          0          0   \n",
       "8          0          0          0         0          0          0          0   \n",
       "9          0          0          0         0          0          0          0   \n",
       "\n",
       "   Time_10_0  Time_10_15  Time_10_30  Time_10_45  Time_11_0  Time_11_15  \\\n",
       "0          0           0           0           0          0           0   \n",
       "1          0           0           0           0          0           0   \n",
       "2          0           0           0           0          0           0   \n",
       "3          0           0           0           0          0           0   \n",
       "4          0           0           0           0          0           0   \n",
       "5          0           0           0           0          0           0   \n",
       "6          0           0           0           0          0           0   \n",
       "7          0           0           0           0          0           0   \n",
       "8          0           0           0           0          0           0   \n",
       "9          0           0           0           0          0           0   \n",
       "\n",
       "   Time_11_30  Time_11_45  Time_12_0  Time_12_15  Time_12_30  Time_12_45  \\\n",
       "0           0           0          0           0           0           0   \n",
       "1           0           0          0           0           0           0   \n",
       "2           0           0          0           0           0           0   \n",
       "3           0           0          0           0           0           0   \n",
       "4           0           0          0           0           0           0   \n",
       "5           0           0          0           0           0           0   \n",
       "6           0           0          0           0           0           0   \n",
       "7           1           0          0           0           0           0   \n",
       "8           0           0          0           0           0           0   \n",
       "9           0           0          0           0           0           0   \n",
       "\n",
       "   Time_13_0  Time_13_15  Time_13_30  Time_13_45  Time_14_0  Time_14_15  \\\n",
       "0          0           0           0           0          0           0   \n",
       "1          0           0           0           0          0           0   \n",
       "2          0           0           0           0          0           0   \n",
       "3          0           0           0           0          0           1   \n",
       "4          0           0           0           0          0           0   \n",
       "5          0           0           0           0          0           0   \n",
       "6          0           0           0           0          0           0   \n",
       "7          0           0           0           0          0           0   \n",
       "8          0           0           0           0          0           0   \n",
       "9          0           0           0           0          0           0   \n",
       "\n",
       "   Time_14_30  Time_14_45  Time_15_0  Time_15_15  Time_15_30  Time_15_45  \\\n",
       "0           0           0          0           0           0           0   \n",
       "1           0           0          0           0           0           0   \n",
       "2           0           0          0           0           0           0   \n",
       "3           0           0          0           0           0           0   \n",
       "4           0           0          0           0           0           0   \n",
       "5           0           0          0           0           0           0   \n",
       "6           0           0          0           0           0           0   \n",
       "7           0           0          0           0           0           0   \n",
       "8           0           0          0           0           0           0   \n",
       "9           0           0          1           0           0           0   \n",
       "\n",
       "   Time_16_0  Time_16_15  Time_16_30  Time_16_45  Time_17_0  Time_17_15  \\\n",
       "0          0           0           0           0          0           0   \n",
       "1          0           0           0           0          0           0   \n",
       "2          0           0           0           0          0           0   \n",
       "3          0           0           0           0          0           0   \n",
       "4          0           0           0           0          0           0   \n",
       "5          0           0           0           0          0           0   \n",
       "6          0           0           0           0          0           0   \n",
       "7          0           0           0           0          0           0   \n",
       "8          0           0           0           0          0           0   \n",
       "9          0           0           0           0          0           0   \n",
       "\n",
       "   Time_17_30  Time_17_45  Time_18_0  Time_18_15  Time_18_30  Time_18_45  \\\n",
       "0           0           0          0           0           0           0   \n",
       "1           1           0          0           0           0           0   \n",
       "2           0           0          0           0           0           0   \n",
       "3           0           0          0           0           0           0   \n",
       "4           0           0          0           0           0           0   \n",
       "5           0           0          0           0           0           0   \n",
       "6           0           0          1           0           0           0   \n",
       "7           0           0          0           0           0           0   \n",
       "8           0           0          0           0           0           0   \n",
       "9           0           0          0           0           0           0   \n",
       "\n",
       "   Time_19_0  Time_19_15  Time_19_30  Time_19_45  Time_20_0  Time_20_15  \\\n",
       "0          0           0           0           0          0           0   \n",
       "1          0           0           0           0          0           0   \n",
       "2          0           0           0           0          0           0   \n",
       "3          0           0           0           0          0           0   \n",
       "4          0           0           0           1          0           0   \n",
       "5          0           0           0           0          0           0   \n",
       "6          0           0           0           0          0           0   \n",
       "7          0           0           0           0          0           0   \n",
       "8          0           0           0           0          0           0   \n",
       "9          0           0           0           0          0           0   \n",
       "\n",
       "   Time_20_30  Time_20_45  Time_21_0  Time_21_15  Time_21_30  Time_21_45  \\\n",
       "0           0           0          0           0           0           0   \n",
       "1           0           0          0           0           0           0   \n",
       "2           0           0          0           0           0           0   \n",
       "3           0           0          0           0           0           0   \n",
       "4           0           0          0           0           0           0   \n",
       "5           0           0          0           0           1           0   \n",
       "6           0           0          0           0           0           0   \n",
       "7           0           0          0           0           0           0   \n",
       "8           0           0          0           0           0           0   \n",
       "9           0           0          0           0           0           0   \n",
       "\n",
       "   Time_22_0  Time_22_15  Time_22_30  Time_22_45  Time_23_0  Time_23_15  \\\n",
       "0          0           0           0           0          0           0   \n",
       "1          0           0           0           0          0           0   \n",
       "2          0           0           0           0          0           0   \n",
       "3          0           0           0           0          0           0   \n",
       "4          0           0           0           0          0           0   \n",
       "5          0           0           0           0          0           0   \n",
       "6          0           0           0           0          0           0   \n",
       "7          0           0           0           0          0           0   \n",
       "8          0           0           0           0          0           0   \n",
       "9          0           0           0           0          0           0   \n",
       "\n",
       "   Time_23_30  Time_23_45  PCA_1  PCA_2  PCA_3  PCA_4  PCA_5  PCA_6  PCA_7  \\\n",
       "0           0           0      0      0      0      0      0      0      0   \n",
       "1           0           0      0      0      0      0      0      0      1   \n",
       "2           0           0      0      0      0      0      0      0      0   \n",
       "3           0           0      0      0      0      0      0      0      0   \n",
       "4           0           0      0      0      0      0      0      0      0   \n",
       "5           0           0      0      0      0      0      0      0      0   \n",
       "6           0           0      0      0      0      0      0      0      0   \n",
       "7           0           0      0      0      0      0      0      0      0   \n",
       "8           0           0      0      0      0      0      0      0      0   \n",
       "9           0           0      0      0      0      0      0      1      0   \n",
       "\n",
       "   PCA_8  PCA_9  PCA_10  PCA_11  PCA_12  PCA_13  PCA_14  PCA_15  PCA_16  \\\n",
       "0      0      0       0       0       0       0       0       0       0   \n",
       "1      0      0       0       0       0       0       0       0       0   \n",
       "2      0      0       0       0       0       0       0       0       0   \n",
       "3      0      0       0       0       0       0       0       0       0   \n",
       "4      0      0       0       0       0       0       0       0       0   \n",
       "5      0      0       0       0       0       0       0       0       0   \n",
       "6      0      0       0       0       0       0       0       0       0   \n",
       "7      1      0       0       0       0       0       0       0       0   \n",
       "8      0      0       0       0       0       0       0       0       0   \n",
       "9      0      0       0       0       0       0       0       0       0   \n",
       "\n",
       "   PCA_17  PCA_18  PCA_19  PCA_20  PCA_21  PCA_22  PCA_23  PCA_24  PCA_25  \\\n",
       "0       0       0       0       0       0       0       0       1       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       1       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "5       0       0       0       0       0       0       0       0       0   \n",
       "6       0       0       0       0       0       0       0       0       0   \n",
       "7       0       0       0       0       0       0       0       0       0   \n",
       "8       0       0       0       0       0       0       0       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   PCA_26  PCA_27  PCA_28  PCA_29  PCA_30  PCA_31  PCA_32  PCA_33  PCA_34  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "5       0       0       0       0       0       0       1       0       0   \n",
       "6       0       0       1       0       0       0       0       0       0   \n",
       "7       0       0       0       0       0       0       0       0       0   \n",
       "8       0       0       0       0       0       0       1       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   PCA_35  PCA_36  PCA_37  PCA_38  PCA_39  PCA_40  PCA_41  PCA_42  PCA_43  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "5       0       0       0       0       0       0       0       0       0   \n",
       "6       0       0       0       0       0       0       0       0       0   \n",
       "7       0       0       0       0       0       0       0       0       0   \n",
       "8       0       0       0       0       0       0       0       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   PCA_44  PCA_45  PCA_46  PCA_47  PCA_48  PCA_49  PCA_50  PCA_51  PCA_52  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       1       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "5       0       0       0       0       0       0       0       0       0   \n",
       "6       0       0       0       0       0       0       0       0       0   \n",
       "7       0       0       0       0       0       0       0       0       0   \n",
       "8       0       0       0       0       0       0       0       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   PCA_53  PCA_54  PCA_55  PCA_56  PCA_57  PCA_58  PCA_59  PCA_60  PCA_61  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "5       0       0       0       0       0       0       0       0       0   \n",
       "6       0       0       0       0       0       0       0       0       0   \n",
       "7       0       0       0       0       0       0       0       0       0   \n",
       "8       0       0       0       0       0       0       0       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   PCA_62  PCA_63  PCA_64  PCA_65  PCA_66  PCA_67  PCA_68  PCA_69  PCA_70  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "5       0       0       0       0       0       0       0       0       0   \n",
       "6       0       0       0       0       0       0       0       0       0   \n",
       "7       0       0       0       0       0       0       0       0       0   \n",
       "8       0       0       0       0       0       0       0       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   PCA_71  PCA_72  PCA_73  PCA_74  PCA_75  PCA_76  PCA_77  DCA_1  DCA_2  \\\n",
       "0       0       0       0       0       0       0       0      0      0   \n",
       "1       0       0       0       0       0       0       0      0      0   \n",
       "2       0       0       0       0       0       0       0      0      0   \n",
       "3       0       0       0       0       0       0       0      0      0   \n",
       "4       0       0       0       0       0       0       1      0      0   \n",
       "5       0       0       0       0       0       0       0      0      0   \n",
       "6       0       0       0       0       0       0       0      0      0   \n",
       "7       0       0       0       0       0       0       0      0      0   \n",
       "8       0       0       0       0       0       0       0      0      0   \n",
       "9       0       0       0       0       0       0       0      0      0   \n",
       "\n",
       "   DCA_3  DCA_4  DCA_5  DCA_6  DCA_7  DCA_8  DCA_9  DCA_10  DCA_11  DCA_12  \\\n",
       "0      0      0      0      0      0      0      0       0       0       0   \n",
       "1      0      0      0      0      0      1      0       0       0       0   \n",
       "2      0      0      0      0      0      0      0       0       0       0   \n",
       "3      0      0      0      0      0      0      0       0       0       0   \n",
       "4      0      0      0      0      0      1      0       0       0       0   \n",
       "5      0      0      0      0      1      0      0       0       0       0   \n",
       "6      0      0      0      0      0      1      0       0       0       0   \n",
       "7      0      0      0      0      0      0      0       0       0       0   \n",
       "8      0      0      0      0      0      0      0       0       0       0   \n",
       "9      0      0      0      1      0      0      0       0       0       0   \n",
       "\n",
       "   DCA_13  DCA_14  DCA_15  DCA_16  DCA_17  DCA_18  DCA_19  DCA_20  DCA_21  \\\n",
       "0       0       0       0       1       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "5       0       0       0       0       0       0       0       0       0   \n",
       "6       0       0       0       0       0       0       0       0       0   \n",
       "7       0       0       0       0       0       0       0       0       0   \n",
       "8       0       0       0       0       0       0       0       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   DCA_22  DCA_23  DCA_24  DCA_25  DCA_26  DCA_27  DCA_28  DCA_29  DCA_30  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "5       0       0       0       0       0       0       0       0       0   \n",
       "6       0       0       0       0       0       0       0       0       0   \n",
       "7       0       0       0       0       0       0       0       0       0   \n",
       "8       1       0       0       0       0       0       0       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   DCA_31  DCA_32  DCA_33  DCA_34  DCA_35  DCA_36  DCA_37  DCA_38  DCA_39  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       1       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "5       0       0       0       0       0       0       0       0       0   \n",
       "6       0       0       0       0       0       0       0       0       0   \n",
       "7       0       0       1       0       0       0       0       0       0   \n",
       "8       0       0       0       0       0       0       0       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   DCA_40  DCA_41  DCA_42  DCA_43  DCA_44  DCA_45  DCA_46  DCA_47  DCA_48  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       1       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "5       0       0       0       0       0       0       0       0       0   \n",
       "6       0       0       0       0       0       0       0       0       0   \n",
       "7       0       0       0       0       0       0       0       0       0   \n",
       "8       0       0       0       0       0       0       0       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   DCA_49  DCA_50  DCA_51  DCA_52  DCA_53  DCA_54  DCA_55  DCA_56  DCA_57  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "5       0       0       0       0       0       0       0       0       0   \n",
       "6       0       0       0       0       0       0       0       0       0   \n",
       "7       0       0       0       0       0       0       0       0       0   \n",
       "8       0       0       0       0       0       0       0       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   DCA_58  DCA_59  DCA_60  DCA_61  DCA_62  DCA_63  DCA_64  DCA_65  DCA_66  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "5       0       0       0       0       0       0       0       0       0   \n",
       "6       0       0       0       0       0       0       0       0       0   \n",
       "7       0       0       0       0       0       0       0       0       0   \n",
       "8       0       0       0       0       0       0       0       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   DCA_67  DCA_68  DCA_69  DCA_70  DCA_71  DCA_72  DCA_73  DCA_74  DCA_75  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "5       0       0       0       0       0       0       0       0       0   \n",
       "6       0       0       0       0       0       0       0       0       0   \n",
       "7       0       0       0       0       0       0       0       0       0   \n",
       "8       0       0       0       0       0       0       0       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   DCA_76  DCA_77   temp  feels_like  pressure  humidity  rain_1h  snow_1h  \\\n",
       "0       0       0  57.34       52.83    1010.8        89     0.00      0.0   \n",
       "1       0       0  57.00       53.96    1000.8        79     0.00      0.0   \n",
       "2       0       0  37.08       29.53    1016.7        52     0.00      0.0   \n",
       "3       0       0  56.68       42.28    1024.7        27     0.00      0.0   \n",
       "4       0       0  56.03       48.92    1023.9        37     0.00      0.0   \n",
       "5       0       0  55.09       45.86     999.1        73     0.91      0.0   \n",
       "6       0       0  46.67       35.56    1018.7       100     2.48      0.0   \n",
       "7       0       0  41.77       35.37    1023.9       100     0.77      0.0   \n",
       "8       0       0  38.07       24.08    1012.5        93     0.00      0.0   \n",
       "9       0       0  57.88       48.33    1023.2        29     0.00      0.0   \n",
       "\n",
       "   January  February  March  April  May  June  July  August  September  \\\n",
       "0        0         0      0      1    0     0     0       0          0   \n",
       "1        0         0      0      1    0     0     0       0          0   \n",
       "2        0         0      0      1    0     0     0       0          0   \n",
       "3        0         0      0      1    0     0     0       0          0   \n",
       "4        0         0      0      1    0     0     0       0          0   \n",
       "5        0         0      0      1    0     0     0       0          0   \n",
       "6        0         0      0      1    0     0     0       0          0   \n",
       "7        0         0      0      1    0     0     0       0          0   \n",
       "8        0         0      0      1    0     0     0       0          0   \n",
       "9        0         0      0      1    0     0     0       0          0   \n",
       "\n",
       "   October  November  December  \n",
       "0        0         0         0  \n",
       "1        0         0         0  \n",
       "2        0         0         0  \n",
       "3        0         0         0  \n",
       "4        0         0         0  \n",
       "5        0         0         0  \n",
       "6        0         0         0  \n",
       "7        0         0         0  \n",
       "8        0         0         0  \n",
       "9        0         0         0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('Resources/Model_data/cleaned_up_updated_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert timestamp to unix\n",
    "# def convert_to_timestamp(x):\n",
    "#     \"\"\"Convert date objects to integers\"\"\"\n",
    "# #     for element in x.iterrows():\n",
    "# #         element[]\n",
    "#     return time.mktime(x.to_datetime().timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X['Trip Start Timestamp'] = X['Trip Start Timestamp'].astype(convert_to_timestamp)\n",
    "# X['Trip Start Timestamp'] = X['Trip Start Timestamp'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = scaler.fit(X_train)\n",
    "# y_scaler = scaler.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "X_test_scaled = X_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_scaled.to_csv('Resources/Model_data/scaled_data/to_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "?{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train.astype(int)\n",
    "# y_train[a] = [int(y_train[a]) for a in y_train]\n",
    "y_train = [float(i) for i in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values = y_test.reset_index()['Fare'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "898192"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "# y_train_categorical = to_categorical(y_train)\n",
    "# y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "             learning_rate='invscaling', loss='squared_loss', max_iter=1000000,\n",
       "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
       "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = linear_model.SGDRegressor(max_iter=1000000, tol=1e-3)\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_predict = clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.728445608465966"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = clf.score(X_train_scaled, y_train)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S\n",
    "# pickle.dump(clf, open('initial_model.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Make This Better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame()\n",
    "coef_df['Feature'] = X.columns\n",
    "coef_df['Score'] = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trip Seconds</td>\n",
       "      <td>131.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trip Miles</td>\n",
       "      <td>126.669612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>rain_1h</td>\n",
       "      <td>4.473124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>PCA_76</td>\n",
       "      <td>4.348255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>DCA_76</td>\n",
       "      <td>3.961392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>temp</td>\n",
       "      <td>3.734499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>November</td>\n",
       "      <td>3.115328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>PCA_56</td>\n",
       "      <td>2.242217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>DCA_56</td>\n",
       "      <td>2.018558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>snow_1h</td>\n",
       "      <td>2.000567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature       Score\n",
       "0    Trip Seconds  131.718000\n",
       "1      Trip Miles  126.669612\n",
       "269       rain_1h    4.473124\n",
       "186        PCA_76    4.348255\n",
       "263        DCA_76    3.961392\n",
       "265          temp    3.734499\n",
       "281      November    3.115328\n",
       "166        PCA_56    2.242217\n",
       "243        DCA_56    2.018558\n",
       "270       snow_1h    2.000567"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_features = coef_df.sort_values(by = ['Score'], ascending = False).head(10)\n",
    "big_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_features = big_features['Feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip Seconds</th>\n",
       "      <th>Trip Miles</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>PCA_76</th>\n",
       "      <th>DCA_76</th>\n",
       "      <th>temp</th>\n",
       "      <th>November</th>\n",
       "      <th>PCA_56</th>\n",
       "      <th>DCA_56</th>\n",
       "      <th>snow_1h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>377.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>959.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>758.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1023.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trip Seconds  Trip Miles  rain_1h  PCA_76  DCA_76   temp  November  PCA_56  \\\n",
       "0         377.0         3.9      0.0       0       0  57.34         0       0   \n",
       "1         959.0         2.5      0.0       0       0  57.00         0       0   \n",
       "2         758.0         5.3      0.0       0       0  37.08         0       0   \n",
       "3         604.0         2.0      0.0       0       0  56.68         0       0   \n",
       "4        1023.0         7.7      0.0       0       0  56.03         0       0   \n",
       "\n",
       "   DCA_56  snow_1h  \n",
       "0       0      0.0  \n",
       "1       0      0.0  \n",
       "2       0      0.0  \n",
       "3       0      0.0  \n",
       "4       0      0.0  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_df = X[imp_features]\n",
    "imp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_X_train, imp_X_test, imp_y_train, imp_y_test = train_test_split(imp_df, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_X_scaler = scaler.fit(imp_X_train)\n",
    "# y_scaler = scaler.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_X_train_scaled = X_scaler.fit_transform(imp_X_train)\n",
    "imp_X_test_scaled = X_scaler.fit_transform(imp_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_y_train = [float(i) for i in imp_y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_true_values = imp_y_test.reset_index()['Fare'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "898192"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imp_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "             learning_rate='invscaling', loss='squared_loss', max_iter=1000000,\n",
       "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
       "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_clf = linear_model.SGDRegressor(max_iter=1000000, tol=1e-3)\n",
    "imp_clf.fit(imp_X_train_scaled, imp_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_scaled_predict = imp_clf.predict(imp_X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7226133321664392"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_score = imp_clf.score(imp_X_train_scaled, imp_y_train)\n",
    "imp_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7012407291508664"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_new_score = imp_clf.score(imp_X_test_scaled, imp_y_test)\n",
    "imp_new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_param_grid = {'alpha': [.01, .001, .0001, .00001],\n",
    "              'epsilon': [0.1, 0.01, 0.001, 0.0001],\n",
    "              'learning_rate' : ['optimal', 'invscaling', 'adaptive'],\n",
    "              'eta0':[.1, .01, .001],\n",
    "              'early_stopping' : [True],\n",
    "              'tol': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "              'max_iter' : [1000]}\n",
    "imp_grid = GridSearchCV(imp_clf, imp_param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxwellpatterson/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 576 candidates, totalling 1728 fits\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-9063135265723426950610944.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-424526533939443773267247104.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-18072414591934043567161344.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-4695978445461809086332928.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1918134769906297803374592.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-284847544282073668780032.000, total=   2.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-96713273776239769116737536.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-58813325686932946185879552.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-8072529030773539281567744.000, total=   2.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-5644044593631366022692864.000, total=   2.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-65500368993470992703553536.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-256241515838872301338624.000, total=   2.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-138112721576691171373936017408.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-87473267203402872509756866560.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-1640453506503509664595968.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-266857805946226354128158720.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-73834761846431951481112363008.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-12721538535386975977856827392.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-20159028464871754816928350208.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-401133234816079327706218496.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-1778283537412310540679643136.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-62214613878634835633003036672.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-35816166154601252377447104512.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-67583399926378761587305480192.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-298102326179310993408.000, total=   7.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-6954569912803155968.000, total=  10.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-64867020937318680.000, total=   9.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-25355632921619959808.000, total=  10.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-3191647067483207106560.000, total=   7.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-3165904730707047481344.000, total=   7.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-61957446368276553728.000, total=   8.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-16045371884001114112.000, total=   8.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-203673302858559946752.000, total=   6.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-196834857071944957952.000, total=   6.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1347924627898125516800.000, total=   7.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1229258684359746048.000, total=   9.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-47687885453975829348352.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-14485634493652246835757056.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-428778194402158393163776.000, total=   2.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-6740617317551340550881280.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-223547633259428056137728.000, total=   2.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-130976493239362440396800.000, total=   3.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-315347761432278165618688.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-12222736233185521868734464.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-474759595136133432868864.000, total=   2.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-2648837335662865107910656.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-1262638474692929697873920.000, total=   2.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-6494538292514831936258048.000, total=   2.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-290896058662564369038049280.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-33170601171631307487770050560.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-4732194353112648159537922048.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-73435140908619934814175232.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-632693966190173374713430016.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-173494628581975627631951872.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-22593800984103976962097152.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-1426975451665142680387584.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-79564468435325544971632640.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-225692617551691647025152000.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1025960288962365484613763072.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-856125988917986475385028608.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-506949645071337455616.000, total=   6.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-298687343130105152.000, total=   8.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-134384566290381668352.000, total=   7.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-48068996730572644352.000, total=   9.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-7777235125678205952.000, total=  10.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-222859797990029623296.000, total=   8.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-5134190382798371840.000, total=   7.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-95385391183044528.000, total=   9.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-3915665843953649664.000, total=   8.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-32139621393632862208.000, total=   7.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-2701056552571289600.000, total=   6.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-8403483889244181504.000, total=   8.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-4714107823745920942473216.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-2234358573756110094729216.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-10664479453437137470357504.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-26923450884446211666870272.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1823698640295576758910976.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-273567848517524355284992.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-33930181021440829030400.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-3084850810621908754628608.000, total=   2.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-3705300021583380993802240.000, total=   3.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-778141613028154791690240.000, total=   3.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-2382543759251415131750400.000, total=   1.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-1800605731126240646004736.000, total=   2.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-18271317726265460937195520.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-6008941152510877309599744.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-10102628355447451331592192.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-538236464808076618235904.000, total=   3.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-8473136687344089233883136.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-1900405512607141514444800.000, total=   2.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-1471704649938079785680896.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-423255418751825987239936.000, total=   1.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-4053297197736533289861120.000, total=   2.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-23470076669012746436608.000, total=   1.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1147198562949627973206016.000, total=   2.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-822825434061640841560064.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-6628284026989551616.000, total=   5.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-2161365823461857792.000, total=   4.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1487806901284305152.000, total=   5.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-5204016159669957632.000, total=   5.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-890208405026802176.000, total=   5.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-2411186359242176512.000, total=   4.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-384742120837233728.000, total=   7.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-1887410702077348096.000, total=   5.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-11362614111802603520.000, total=   4.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-647895567368206976.000, total=   4.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-149596341477504032.000, total=   4.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-319234059979582528.000, total=   4.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-654496574457197329645568.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-39440288637374278542557184.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-2654915394732265572401152.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-9284868230061426691014656.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-512439699665389579403264.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-17476334615850541503217664.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-199229813598540884082688.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-157327205281408374276096.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-23044695737543671817437184.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-374597855238988675153920.000, total=   2.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-2342254448297182001889280.000, total=   2.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-68236919961876133052416.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-137938559090924507301018599424.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-3147700465313931417683492864.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-196499595035618190213183963136.000, total=   3.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-5448932683058639461788155904.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-137444387034932893048023023616.000, total=   1.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-1800306000854922413727547392.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-59722622219766343469889486848.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-17051414376052999491151724544.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-67960954587314754595588145152.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-124397663705474379659283005440.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-275701120257419495320655495168.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-9130712786799683899192508416.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-205396121780943945728.000, total=   8.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1352296471282124587008.000, total=   6.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-21981515261738953474048.000, total=   7.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-35588465001464193024.000, total=   7.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-956565652972085760.000, total=   9.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-1606257664841809395712.000, total=   6.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-389533567726401880064.000, total=   7.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-14874892066542180352.000, total=   8.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-14595387782053890048.000, total=  12.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-10484159861270153003008.000, total=   7.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-54117492182279299072.000, total=   8.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-18724109910913744896.000, total=   8.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-16768367606223594013589504.000, total=   1.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-7625878983545972034895872.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-1118673235436118111944704.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-12124890144024715342118912.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-23078296666765399615864832.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1584338795693569497628672.000, total=   1.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-370037131259667309133824.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-108980205325584886975692800.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-74826496090387150536704.000, total=   2.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-2134090864531240464154624.000, total=   2.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-217625507022222733082624.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-1565402711529435409940480.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-59718032003820049471111168.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-146900150026994468316512256.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-127985786097539959717101568.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-38131772151899577468846080.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-3120104331618840027580071936.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-2282011932416502000517120.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-87406759370726862126841856.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-251417264477658529574944768.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-2211205448866731625673654272.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-899731571434556315127513088.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-16235755500975007295602688.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-5359285625665875984989028352.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-463348417060133339136.000, total=   6.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-45276340237137728.000, total=   6.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-11518639649000105984.000, total=   6.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-146874801972485685248.000, total=   6.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-7582786714455036928.000, total=   7.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-17042673321058461696.000, total=   5.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-7262898381410780160.000, total=   6.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-7703192083696538624.000, total=   6.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-73020277204377559040.000, total=   6.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-55030396939576885248.000, total=   7.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-57537982866884427776.000, total=   8.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-55681443649783341056.000, total=   6.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-3698950838622572922273792.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-2215379791914800708059136.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-22701194589012611825664.000, total=   3.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1238195185182516810088448.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-7920768410692608440926208.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-12202077107680063271206912.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-5252284171306803396608.000, total=   3.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-2797257196865673517596672.000, total=   3.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-58748992301341530054983680.000, total=   2.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-21598437962314468137369600.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-5631589816387817374220288.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-12092434654860589976780800.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-18679220538036840359264256.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-2716929372196696955551744.000, total=   2.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-289237163048149022932992.000, total=   2.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-862323321298407905034240.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-50995850617188780081152.000, total=   2.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-274668315789550642266112.000, total=   2.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-61147170251331506012160.000, total=   2.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-353164749373941470986240.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-13370201872469009859870720.000, total=   2.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-2558392979329272745295872.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-977647074540954356547584.000, total=   1.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1519405623696454588563456.000, total=   2.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-4667263503462033408.000, total=   5.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-14216778866180079616.000, total=   5.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-873621025837380736.000, total=   4.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-307863363745931657216.000, total=   5.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-996756087487508992.000, total=   5.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-8457049307562251264.000, total=   4.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-881102602482178944.000, total=   5.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-82929485251173968.000, total=   5.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-3626445148321078272.000, total=   5.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1253044721810720000.000, total=   5.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-3302564518121006080.000, total=   5.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1012084935761636480.000, total=   5.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-415727544152120021221376.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-258217505251393183678464.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-12008938003848551257341952.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-50735229674870537552134144.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-15997850412105164730138624.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-923896575220949446557696.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-283839879627912521973760.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-3193001370096777291628544.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-2274042740852601785417728.000, total=   2.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-143972955608213614493696.000, total=   2.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-6756690154905294256209920.000, total=   1.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-7138727796443790926938112.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-3720247806491668518606471168.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-5151589445248565607225360384.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-95271184580353484850297044992.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-427728779111836497061171167232.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-235879972324723141659737456640.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-6608407403550810033964974080.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-430094638054213918143597772800.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-7437004212357341088868990976.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-66651738329500549051582513152.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-8859913868197882315946328064.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-9551819675920330457218023424.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-497669208376696169673261056.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-13302170487452590080.000, total=   9.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-21579131261060415488.000, total=   7.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-5082199390446244864.000, total=   9.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-102914866277562580992.000, total=   6.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-14577813521557652242432.000, total=   6.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-29671910762042843136.000, total=   8.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-1385340938257718016.000, total=   9.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-211516854619313471488.000, total=   6.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-75660038359177527296.000, total=   8.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-138142713812187200.000, total=   8.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-22799506386553810944.000, total=   7.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-23575571735368292.000, total=   9.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-1531462510202749823483904.000, total=   2.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-12128631562577470445060096.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-3987919413293642315464704.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-44915676010512065232896.000, total=   2.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1719112037602411025530880.000, total=   2.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-11688054588392444046344192.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-37250396641819443068928.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-3521034258522775333371904.000, total=   2.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-38166306136486319671476224.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-13792063337153371018625024.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-118734461399476587737382912.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-3415698985859820529123328.000, total=   1.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-1558237080893933167413559296.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-94429852754483984403005440.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-34068481657926420539637760.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-4879270451389423309786447872.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-32121823015088583100858368.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-2070701226856645313733591040.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-124028588343614225065705472.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-632424424793988083642007552.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-2318292946068051822794244096.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-388583133078082728891514880.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-175475158351143304305836032.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-61207197255829846434512896.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-4591426101258144768.000, total=   6.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1249772114858159636480.000, total=   6.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-19200934730791387136.000, total=   8.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-4689342890494621696.000, total=   7.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-615261791714474880.000, total=   7.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-2484462500934278144.000, total=   7.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-51724183334034096128.000, total=   7.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-87029291526806175744.000, total=   7.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-56197740211759759360.000, total=   6.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-7994072159881315328.000, total=   6.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-39648698291216343040.000, total=  10.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-10145205301178738688.000, total=   6.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-90698234373888419607609344.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-13505771018518063002681344.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-7431107750510569963126784.000, total=   2.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-2563776648645389813022720.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-20253487242874739698434048.000, total=   2.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-105286464953431885873152.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-12941398638029370021642240.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-1540663893715349772697600.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-7623911673976817144823808.000, total=   1.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-1832460376002457455558656.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-22842158799502705931845632.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-30351356216076016996581376.000, total=   2.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-19250423189062175690850304.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-160868776658289691721728.000, total=   2.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-25068632671560317160914944.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-19370935513795263555698688.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-1006536749558731575918592.000, total=   2.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-752495872434435329622016.000, total=   2.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-7558682410118319938994176.000, total=   2.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-24077477427045579089772544.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-2327774323032239380627456.000, total=   2.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-2142040879767011702341632.000, total=   2.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1820155019982356499922944.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1770886760271295104942080.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-9364540598576486400.000, total=   4.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-2168323112918481408.000, total=   4.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-2595509586420900352.000, total=   5.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-10430582402247383040.000, total=   4.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-10550830100514129920.000, total=   4.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-27866778175622377472.000, total=   4.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-2058147476183314944.000, total=   4.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-7882114275240886272.000, total=   4.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-2600063411924319744.000, total=   5.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1821792117483938048.000, total=   4.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-2305340585444801536.000, total=   4.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-3587713156998882816.000, total=   5.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-1319880263575367608958976.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-26877216283481051773272064.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-2124621886878109887627264.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1243301763351913261170688.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-254546671545285452234752.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-7657720776955464823865344.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-1002387333804357169709056.000, total=   2.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-5334526191934283274256384.000, total=   2.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-267302985535252705837056.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-5724153080844084381220864.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-731518804200528153673728.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-115106099832696514543616.000, total=   2.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-36960318466446566108086403072.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-24129104543509943707431337984.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-143055368585780980855550771200.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-69756838878964148514328674304.000, total=   1.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-5463268895550038173676470272.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-8117535264447318392718753792.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-27811613318183727080782430208.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-64030214452753117436482420736.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-10864722567041255505699799040.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-191946966440285045108991066112.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-241404600279561172705869824.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1820042313751219317441036288.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-666843966092272599040.000, total=   7.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1930681858183642368.000, total=   8.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-310461829937374756864.000, total=   7.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-563217056494395392000.000, total=   6.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-11071447454199187456.000, total=   8.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-278787910172181920.000, total=   9.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-94645557038708867072.000, total=   9.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-40792664314804060160.000, total=   8.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-913835280400031285248.000, total=   7.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-287321041595720204288.000, total=  10.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-181996168242846040064.000, total=   8.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-11017468137175982080.000, total=  11.1s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-11049100527570203627749376.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-2590747836948162889646080.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-1745233855290346808803328.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-12016503377370934786654208.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-2159319859191323562082304.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-9549716000897686789160960.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-891096129784135460847616.000, total=   2.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-3900873943576408355766272.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-29404392142119785417670656.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-5256729308572880193191936.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-19843213001984823269523456.000, total=   2.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-13716002961268060981297152.000, total=   1.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-48465076219996534550298624.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-211157816098642673709088768.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-826294888455187214849015808.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-49089148275126753113931776.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-781809772324509838229897216.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-454374830651399103414534144.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-1051837279739205720559583232.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-3511083279118060620672401408.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-229297211372329017236520960.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-229294678858776254053613568.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-33363405221654482175131648.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-22144121041397904794714112.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-39196296070500114432.000, total=   9.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-224446202148261536.000, total=   6.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-410590532524640064.000, total=   7.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-19083348595452948480.000, total=   6.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-8672953299199692800.000, total=   7.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-12476060996585486336.000, total=   9.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-64635184571778192.000, total=   7.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-817305172974952704.000, total=   6.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-13472431307396132864.000, total=   6.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-90402913046504767488.000, total=   6.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-9692244076028596224.000, total=   6.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-2613269135209447424.000, total=   6.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-2476838628299393114046464.000, total=   1.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-442826859595917334413312.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-341736129075316703363072.000, total=   2.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1780012482891967685984256.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-90711259896865010820841472.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-4807333724103369983787008.000, total=   1.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-49360650469969993574383616.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-11099696877366467702554624.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-201436681331243581702144.000, total=   2.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-3160952326488576292290560.000, total=   2.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-133139772004049398792192.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-1369926651773640008269824.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-214496030099288092405923840.000, total=   1.5s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-79541774001359321724616704.000, total=   1.4s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-439137594704124564209664.000, total=   2.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-636137778696519052951552.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-697343668826830352154624.000, total=   1.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-610847801183838857592832.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-53559175079322484482244608.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-5137870506003952060858368.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-7286787533544970021502976.000, total=   2.0s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1315933790706359517315072.000, total=   1.6s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-14560191483250576677928960.000, total=   1.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1034844468476669247619072.000, total=   1.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-3067680827533346816.000, total=   5.3s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-303901399578387456.000, total=   5.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-573284671373094464.000, total=   4.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-368484780376099968.000, total=   5.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-6327784137459549184.000, total=   4.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-578232029563935744.000, total=   4.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-878493538959821440.000, total=   5.2s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-3536352889991078912.000, total=   4.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-27671672331167379456.000, total=   4.9s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-11895226386914621440.000, total=   4.8s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-880443975701243776.000, total=   4.7s\n",
      "[CV] alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.01, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-2216520863768755456.000, total=   4.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-3486335543949511712833536.000, total=   2.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-192452009871060673587314688.000, total=   3.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-10225878254024675114608492544.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-171538410544311433930211328.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-15347141099027656960114688.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-575759902471712394969088000.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-464224073072147061033402368.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-112605539109950101926182912.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-170463879201095186447859712.000, total=   1.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-179734405627759757080133632.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-130313071547231848970059776.000, total=   2.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-129795462447393976126275584.000, total=   1.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-923055947709317163839133843456.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-51183044409812498372320296960.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-190306007223304793253813944320.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-207661169651722982449479680.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-4789636715358465879995056128.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-5785964704447837675035033600.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-7010289969442927987598032896.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-163593835525967864845373014016.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-20680657010583568224532561920.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-87325458233150857514152099840.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-16440178155706868782625456128.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-618625131507395853616995631104.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-40970776147335847936.000, total=   8.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-474089949715995820032.000, total=  11.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-183159491276391088128.000, total=   7.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-1299406555796440350720.000, total=   7.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-52601525913307529216.000, total=   8.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-592846579947089952768.000, total=   8.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-194154425099747229696.000, total=   7.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-26151327960772509696.000, total=  10.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-86914874575509798912.000, total=   9.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1354373758517309603840.000, total=  10.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1171522070159776546816.000, total=   7.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-2368579922240911441920.000, total=   8.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-38501752888753685769748480.000, total=   2.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-912849273379254432451002368.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-238734042367174514525077504.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-318261934562450024899280896.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-110226441520253026091139072.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-504612399605095543754194944.000, total=   2.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-368948662941271053729529856.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-3760648708924238603116085248.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-44885684391353358946926592.000, total=   2.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-70964005561595146295836672.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-25641668081258011245412352.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-715962455197055239457865728.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-1126032265485697689845760000.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-257584525106730758616121344.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-5866897250333403589378048.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-97759455542899106635579392.000, total=   2.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-672222260213858912769671168.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-16192768474645100673105920.000, total=   1.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-3265302694425957784814092288.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-92227284328534469670600704.000, total=   1.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-913821971487098382567079936.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1289171718729745271019798528.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-91575051533622243342942208.000, total=   2.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-61961179153283783099154432.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-456156869919054626816.000, total=   5.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-40870771666703556608.000, total=   5.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-84683179533961674752.000, total=   6.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-56939577297413087232.000, total=   5.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-195404915270542688256.000, total=   5.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-1211303175846046466048.000, total=   6.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-4993359319984031744.000, total=   5.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-1195557664169653436416.000, total=   6.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-52040497714215116800.000, total=   6.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-15051669569789306880.000, total=   6.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-661615418923822481408.000, total=   5.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-182923318196095614976.000, total=   5.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-318523544640077397665775616.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-244295591187827439219769344.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-13705571300159123109997182976.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1732862844111144112485302272.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-3911745822576207834535428096.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-294976504702282707410878464.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-197291433636406508149276672.000, total=   2.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-373459068274351334483820544.000, total=   2.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-477668086913262054040141824.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-20138830129220008282161152.000, total=   2.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-181017833201214157104349184.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-982444070248943633957912576.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-13177764661620727521214464.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-10399326100519219464503296.000, total=   2.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-1296806720054793898819584.000, total=   1.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-1414912555989217029652480.000, total=   2.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-18244166407590588186624.000, total=   2.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-4169250037517434507755520.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-2164029211142763262771200.000, total=   2.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-1972643832642098721456128.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-27793645516861830424690688.000, total=   2.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-10014908652784192996769792.000, total=   1.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1472093612701691324399616.000, total=   1.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-8739353552289009208655872.000, total=   2.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-4799201328024181760.000, total=   6.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-2063074780976908800.000, total=   5.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-3544964181370904576.000, total=   6.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-424385796348667428864.000, total=   6.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-6037940639397980160.000, total=   7.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-2018946200886837248.000, total=   6.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-300388547685027264.000, total=   8.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-3400508489643652096.000, total=   7.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-2939288971373396992.000, total=   8.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-4143521229563695616.000, total=  10.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-3013969443141791744.000, total=   6.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-3748440745131530752.000, total=   7.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-510297393850903518961991680.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-966830729340647063328653312.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-255383555675345024159055872.000, total=   2.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-54561335996641384868085760.000, total=   2.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-450943862137564634078511104.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-19350748680765019151925248.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-426843455097803206316523520.000, total=   1.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-619944901537463388310863872.000, total=   2.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-594335864849422748041084928.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-490989081295243219409305600.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-1277276597898311559108624384.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-208468824366514742533029888.000, total=   2.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-473465457233864277815721984.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-12969983992371776476122447872.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-36128136032969154678870769664.000, total=   2.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-85331632022635531850481664.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-67813612923923786177242464256.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-91612562232488661528508104704.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-1796150725566986436634214400.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-91149884134361082626987524096.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-14603844503100349785802014720.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-334907614300303119978856448.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-3947254632430756660728823808.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-209486374451638743223293181952.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-211977579536820011008.000, total=  10.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-490284201849004294144.000, total=  14.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1804851139526854705152.000, total=   8.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-34737905304133276008448.000, total=   8.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-1230098497600375750656.000, total=   9.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-2837844352416219136000.000, total=   8.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-622908212214469099520.000, total=   8.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-596386190886659817472.000, total=   8.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-1955837285541259509760.000, total=   7.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-92806053007429353472.000, total=   9.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-8217187708018499584.000, total=  10.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1444638589090547456.000, total=   9.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-3374702703513588396457984.000, total=   2.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-269191321232524271647981568.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-1096879096800465540612096.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-65754251473277742011645952.000, total=   2.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-59265837308943964699623424.000, total=   2.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-316195306647630450345902080.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-66974677623749243333246976.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-886571811309868189214572544.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-548915120757180478556995584.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-436930689754710835172737024.000, total=   1.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-204490915006702864664887296.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-462255710923511068251652096.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-11143272428876967419314176.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-20059427253865513438637195264.000, total=   1.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-52345338086992394768613376.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-4509198725434445356643385344.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-48474578124125043070861312.000, total=   2.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-191025880788476017812439040.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-2896604588060366851784310784.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-199054903498201394898272256.000, total=   2.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-66020145781810342624493568.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-170263299022346916131241984.000, total=   2.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-21103473330968929740259328.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-613298325692505841555472384.000, total=   2.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-15819639054673762304.000, total=   5.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1195547722385482317824.000, total=   5.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-414987277995293474816.000, total=   6.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-24585909122287140864.000, total=   5.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-448653957941191872.000, total=   6.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-86047303731130728448.000, total=   5.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-74022724721669144576.000, total=   6.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-17672873887310551040.000, total=   5.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-15853651534569611264.000, total=   5.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-695658708265353347072.000, total=   5.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-134753736028420816896.000, total=   5.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-211476880355620945920.000, total=   5.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-104716641089670197536620544.000, total=   2.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-43839504973118779523334144.000, total=   2.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-276253568486236193961279488.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-427996554227304744909537280.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-7706239631781964368427614208.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-70007038350804716940689408.000, total=   1.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-647740014689598314458906624.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-2893292016840077114039336960.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-273826014744159106902261760.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-6474140684689699684483072.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-3301927471741187217256611840.000, total=   1.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-170728741890350459138342912.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-571855298042185153249280.000, total=   2.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-4457347380352552208957440.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-21828521057361298601279488.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-7970534986898299919794176.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-2255126009519505527537664.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-25232829723910116900601856.000, total=   2.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-41530080545884570893942784.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-2360071542893945164922880.000, total=   2.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-2878632195523006005510144.000, total=   3.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-312672581137294468055040.000, total=   2.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-8013814325891137965916160.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-357795200915947414093824.000, total=   2.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1834588112410189824.000, total=   5.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1410810796223619840.000, total=   6.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-495678201427928384.000, total=   6.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-3988812726373991424.000, total=   5.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-5732340074936507392.000, total=   5.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-8453429848813063168.000, total=   6.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-1681456256408067072.000, total=   6.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-8295845897543753728.000, total=   5.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-343696706933917056.000, total=   6.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-29946737462841446400.000, total=   5.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-2696984386559093248.000, total=   6.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1213951403611357440.000, total=   8.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-1352361390433923240034304.000, total=   1.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-49595477873621202374754304.000, total=   1.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-125197410214037178273497088.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-807603753309600650461446144.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-818487403298204838703136768.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-898738135178492141461569536.000, total=   2.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-50416208171572719798714368.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-1820582621946182490226950144.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-27144223310236207942729728.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-33759596665100096195526656.000, total=   2.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-402290952756730547742441472.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-922343707760204699872002048.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-11999222959334513096785920.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-8828446740461144498046500864.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-19647387549115540544560300032.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-2025689106800398981232852992.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-267375589757314582251078418432.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-5458984465625743932925149184.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-554447529378187759338435641344.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-83928910569673116812643926016.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-422445363436320463096119296.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-40506923138084771838071668736.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-125227672483053338613648457728.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-3001589791075144473920929792.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-5300093967419916288.000, total=   7.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-107781616426214342656.000, total=   7.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-14344921832499577880576.000, total=   7.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-842953723506044305408.000, total=   8.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-13781255526451060736.000, total=  10.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-4050283846479495680.000, total=   7.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-46066333293126647808.000, total=   7.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-2193592727488221440.000, total=   9.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-7046880814246606848.000, total=  10.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-231792620501334228992.000, total=  10.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1290112337238845816832.000, total=   8.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1335629977223556235264.000, total=   8.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-204141437448127590539722752.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-13182766158377157804198723584.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-163274250559870121461940224.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-380321208783280336290185216.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-133037115068085582444888064.000, total=   2.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-2179641675298577028900454400.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-141759873180319535215935488.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-842184651196066886057984.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-239855718962891452611297280.000, total=   2.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-1506785954729035674828144640.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-42773329563500277200322560.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-498084185202432029780606976.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-134664563930084991244959744.000, total=   2.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-292408313224656484510466048.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-94288187893087292518039552.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-138768388705000179781074944.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-443171706807628377884721152.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-34059076531557267002097664.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-111615136380457275954823168.000, total=   1.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-959194005781114624980025344.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-72593636403294294488645632.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-76035418615081310609211392.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-564067883142571291922399232.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-417182412542744774039306240.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-486986688377070288896.000, total=   5.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-21284663723034578944.000, total=   5.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-409764496539039956992.000, total=   5.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-5834725125231636480.000, total=   6.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-49229557009303314432.000, total=   5.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-5259925347561424896.000, total=   5.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-226053254230377398272.000, total=   5.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-7844461001558594560.000, total=   5.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-89829623959899766784.000, total=   5.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-13164828804807745536.000, total=   6.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-7123961185574457344.000, total=   5.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-4645914816236048384.000, total=   5.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-16857825855167462488670208.000, total=   2.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-1708372431814678276586078208.000, total=   1.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-31559664149310308412817408.000, total=   2.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-32035767435809068461064192.000, total=   2.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-271128869030086709941895168.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1456958420013586418579275776.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-10178642049753283978854400000.000, total=   1.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-498981916246518528890372096.000, total=   2.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-1846167621450598658800091136.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-237520276091802165465579520.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-1815198680800775146223697920.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-393470097433782877991993344.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-1517406563826791350272000.000, total=   1.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-716151865260239883337728.000, total=   2.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-2781666907521904736731136.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-11556077091992786620645376.000, total=   2.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-2367704562002946210922496.000, total=   2.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-337142798636964170956800.000, total=   2.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-3075892381187702020636672.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-1701526749610430995365888.000, total=   2.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-57207449592210103730176.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-33002330859694276443373568.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-6124021104978529792032768.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-4575127532345186446213120.000, total=   2.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1753013025036252416.000, total=   6.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-2136030572412433408.000, total=   4.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-2927520054473846272.000, total=   5.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-24486010664263012352.000, total=   6.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-2022954475884801280.000, total=   6.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-830005357339701760.000, total=   6.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-5514956690866000896.000, total=   6.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-1212324948706560512.000, total=   8.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-14698475110433116160.000, total=   9.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-814012427886910080.000, total=   8.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-18237387087557416960.000, total=   6.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1836306951697045760.000, total=   7.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-238359270634723970434203648.000, total=   1.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-833321494546308561289347072.000, total=   1.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-379523674821264980930723840.000, total=   2.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-883903655499671135596838912.000, total=   2.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-94189265572904971416895488.000, total=   2.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-82539011632623868557918208.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-119451336069330647392452608.000, total=   2.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-2252868029981640523413192704.000, total=   5.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-129143345149607669259042816.000, total=   2.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-898451609100680462266793984.000, total=   2.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-40947849254886028911575040.000, total=   1.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-48041447735879131669200896.000, total=   2.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-4455010415557865520328867840.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-5156239173378174681033474048.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-17370546380973648129185284096.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-14213661353305399605476720640.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-6587967522178622205783441408.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-39098019714374569529461178368.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-21929413051713902631553335296.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-43613392064842099307430543360.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-274173148158889681876145930240.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-26076572247335687293908287488.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-13052024806266104309352497152.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-58285932234203894611785547776.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-664512735659158011904.000, total=   8.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-8858102165762130944.000, total=   8.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-3461212171365613830144.000, total=  10.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-37168851703314046976.000, total=   9.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-132117031673589956608.000, total=  14.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-1180482847601628282880.000, total=   9.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-170076002787897212928.000, total=   8.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-1532243659148055805952.000, total=   7.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-3887353040702278144.000, total=   9.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-41829155807606759424.000, total=   9.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-200555007952996139008.000, total=  12.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-25852144464585121792.000, total=  10.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-51874223758165717737799680.000, total=   2.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-109384236392379545771048960.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-943228502184044397038927872.000, total=   2.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-2721371319876130054567100416.000, total=   2.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1960403770153853340958588928.000, total=   2.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-2863815553354527010742861824.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-714182397693836075728896.000, total=   2.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-357926301795677770254123008.000, total=   1.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-773596964887101152086196224.000, total=   1.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-3967302818428826803331137536.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-447410829397472664340135936.000, total=   2.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-306750421139414058839048192.000, total=   1.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-2691243286048491302989856768.000, total=   2.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-725063552592077890422571008.000, total=   2.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-276184825466014053240406016.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-37699596696846023390134272.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-56563388586820103808483328.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-3500542906528090964117946368.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-1244563636093653141340291072.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-19681552634462356755185664.000, total=   2.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-157594236672750617920274432.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-678189184129750145666383872.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-394504796296433744092332032.000, total=   1.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-274036617556308731113766912.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1088843867379532562432.000, total=   5.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-7317891813432003584.000, total=   5.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-192597538909271687168.000, total=   6.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-39176667498446094336.000, total=   5.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-3454202240007061504.000, total=   5.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-186924003532798590976.000, total=   5.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-18141692126073589760.000, total=   7.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-504552833608370356224.000, total=   6.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-4669731865660510208.000, total=   6.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-75827266951579123712.000, total=   6.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-58882563821055475712.000, total=   5.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-612967261172607877120.000, total=   5.7s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-758092939396889442254848.000, total=   2.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-148300311314393537427013632.000, total=   2.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-2699131054715868971265949696.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-2171016100326670128767827968.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-208106009451798940513992704.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-2167703370451508659811778560.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-177565062045802960624025600.000, total=   2.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-683924876237101930672816128.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-8849338053956784659969867776.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-344556707777140697707053056.000, total=   1.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-123333982250237632142376960.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-788078346919281272400379904.000, total=   1.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-36442975443109750681632768.000, total=   1.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-1542104511003118673068032.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-14475941667356729302581248.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-688425256195581913595904.000, total=   2.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-1618395919517662289330176.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-4818343602227321864454144.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-5591848070707658643996672.000, total=   2.1s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-690985692977286864699392.000, total=   1.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-2314807593736757376450560.000, total=   1.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-4891974687160933866799104.000, total=   1.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1007916261530915276062720.000, total=   1.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-225176880556402280497152.000, total=   2.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-970052479267239936.000, total=  10.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-722990710422555520.000, total=   6.8s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-3738256524255320576.000, total=   6.3s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-2030712289731922432.000, total=   7.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-4902611639285157888.000, total=   8.4s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-1796412941441459456.000, total=   8.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-4231821792969783808.000, total=   9.0s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-2305301112905038592.000, total=   5.9s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-3549358352254362112.000, total=   7.2s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-3181410603928990720.000, total=   7.6s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1060843529403033984.000, total=   5.5s\n",
      "[CV] alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-3100715908784603648.000, total=   6.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-91885574384951009077763244032.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-41569764712042718114284044288.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-21298458665985038471921664.000, total=   2.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-2791577307424559772964225024.000, total=   2.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-833762450692635406730551885824.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-419054118996497994124099584.000, total=   2.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-27945321726187842539402297344.000, total=   2.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-13576505733002467868965601280.000, total=   2.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-103780568196253735286191685632.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-34013301395053180070202966016.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-872880239033066840191863357440.000, total=   2.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-27526392685705305505985986560.000, total=   2.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-8313558613690823240889401344.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-523081363884023961044415152128.000, total=   3.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-43070769976263109263132459008.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-1182792244478786902415869214720.000, total=   2.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-92019269870528685889225228288.000, total=   2.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-52409357676285860538520436736.000, total=   2.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-2518771837225752700831924224.000, total=   2.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-2457822114847383408408002560.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-5931267940634846559752683520.000, total=   2.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-31460650982116442779288600576.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-89526674124444810286584561664.000, total=   2.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-14348115088610761116636676096.000, total=   2.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1904573007781625331712.000, total=   7.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-5849442825138510757888.000, total=   6.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-15310957656987888779264.000, total=   8.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-2219237075501700087808.000, total=   9.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-17589872129823362514944.000, total=   6.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-2023524725130961092608.000, total=   9.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-2600110993372961308672.000, total=   6.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-311303776735769985024.000, total=   7.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-626148557960431927296.000, total=   8.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-5850038782307254403072.000, total=   8.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-8700172351067751710720.000, total=   8.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-6078689232594764038144.000, total=   7.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-8321915528241422370506539008.000, total=   1.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-74927728628662805964024446976.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-155749101021861696135732658176.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-27201627243336537247605325824.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-43752170074379259389935616000.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1484977400680135776127680512.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-98336690105128671216574398464.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-27394741767534593384598470656.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-115939951610808702773852372992.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-286103566223576160997998592.000, total=   2.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-4173750849358926732777750528.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-6765382049216345213073620992.000, total=   3.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-129898771046860128201474048.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-79116652278821254357581824.000, total=   2.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-222723889885598008557436928.000, total=   3.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-7089075025063089071456256.000, total=   3.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-73568162036184993012645888.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-326881348720201051095957504.000, total=   2.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-200999711876744819129712640.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-659450379622021767102464000.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-575045419369600903574192128.000, total=   2.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-341938268011552927706513408.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-328886037200925038475214848.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-662420194018748990685708288.000, total=   2.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-2498739474751864438784.000, total=   9.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-85877310400902742016.000, total=   9.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-7203379280289415036928.000, total=   7.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-69241290732249890816.000, total=   8.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-221453585527273291776.000, total=   7.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-430415773046580248576.000, total=   8.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-226813942439372390400.000, total=   6.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-460527351737070649344.000, total=   8.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-549773436340529201152.000, total=   7.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-262116763771358969856.000, total=   7.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-98002124688768286720.000, total=   7.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-168852012479455199232.000, total=  10.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-34856415674877221799649607680.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-236724005611654469079082729472.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-17175853423616927569759174656.000, total=   2.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-12924919510711709729237762048.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-19052746808752685609841065984.000, total=   1.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-2366853242085384392131215360.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-31070458754750533795005333504.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-25283560373544718686884986880.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-65276086510410221153689796608.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-63230631675415453879446274048.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-6666749669340938716976250880.000, total=   2.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-542357809212453794390999040.000, total=   2.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-44537375581532318991384576.000, total=   3.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-46335098040834146726576128.000, total=   2.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-5411088484405692384411648.000, total=   2.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-100882415972632674921611264.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-230589224256620462080000.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-58960502208502173794304.000, total=   2.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-4061252155414883191488512.000, total=   2.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-36951046682581140395524096.000, total=   2.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-29411583311800938222583808.000, total=   3.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-8137389549977514620747776.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-15065004991602778701824.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1497267295482547969982464.000, total=   2.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-53228646739051102208.000, total=   7.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-11739569183796549632.000, total=   6.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-13874955411110076416.000, total=   7.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-9227558420282247168.000, total=   6.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-66441673857694900224.000, total=   6.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-66883716528880738304.000, total=   7.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-14171084690346319872.000, total=   8.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-365436942502413205504.000, total=   7.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-24889697372640649216.000, total=   8.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-123201328853404860416.000, total=   7.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-9121148797192120320.000, total=   9.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-31348483687222349824.000, total=   7.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-11356261476027947553738719232.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-3708326017318728837562892288.000, total=   2.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-52098139343448982841974587392.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-151519104764973003777341652992.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-71020170213851817681103093760.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-2033392094717329289024372736.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-57280569260591505672379564032.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-20430771725206574470401097728.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-3989093074675892827342241792.000, total=   3.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-12671581430059191618827714560.000, total=   4.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-289756815964295962195874807808.000, total=   3.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-12196300628463328282942636032.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-42403632928740666427689664512.000, total=   2.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-10518442593518493408551763968.000, total=   3.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-12490418291259619993448349696.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-194134176772723144021893971968.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-51690680805133149608817459200.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-87059829373795275679048138752.000, total=   2.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-77005724754678623307334418432.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-18329149444080445299598819328.000, total=   2.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-16079343460344344977514430464.000, total=   2.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-147496365447266725917924261888.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-5631328734848592596531412992.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-31378570322265819262335582208.000, total=   2.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-410238761559644241920.000, total=   9.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1423977282684289286144.000, total=   6.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-30111606179247557705728.000, total=   6.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-653199849478542721024.000, total=   8.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-15339408387900203597824.000, total=   6.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-5051447285528284626944.000, total=   7.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-25532125852319065571328.000, total=   7.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-298906698887232159744.000, total=   7.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-112082447555528943992832.000, total=   6.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-592645353180112617472.000, total=   6.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-512581013300949286912.000, total=   7.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-578847807693395460096.000, total=   8.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-33221409526597365489821810688.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-5168098896625726933686026240.000, total=   1.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-9254361846329832992713736192.000, total=   2.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-21162771019366922827845337088.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-73035166223114240734137417728.000, total=   1.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-763659647643047479592121008128.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-301726521672837651058705563648.000, total=   1.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-4051032427978481585134501888.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-4105200984404519072439468032.000, total=   1.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-42966364000433225155787882496.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-59148297733274523451397242880.000, total=   2.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-12722504655875606794182066176.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-42917721235313306858684416.000, total=   2.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-147985723478013888000163840.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-31798550074520817532665856.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-60329200204884346987872256.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-193391691412009056311705600.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-932171212425499246910767104.000, total=   2.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-387404939795515677803020288.000, total=   2.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-1521767504909829511929921536.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-4765704700959547604336640.000, total=   2.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-213217316056099405583876096.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-219230972889562020029923328.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-62335723813737392815210496.000, total=   2.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-2400695479525063000064.000, total=   7.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-136302414834275729408.000, total=   7.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-349226824555108499456.000, total=   9.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-295548296742436864000.000, total=   7.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-171275688275114721280.000, total=  10.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-190103266457131352064.000, total=   7.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-365201329498908786688.000, total=   8.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-179043894691528245248.000, total=   7.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-90794972950644637696.000, total=   9.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-170294839897478234112.000, total=   6.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-6799962040319666552832.000, total=   6.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-350244868301606748160.000, total=   9.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-332570411917678699629707788288.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-175780019908509653814294347776.000, total=   2.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-48501115483495170218070638592.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-11551197932574253597732110336.000, total=   2.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-10125861841836019063533338624.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-2385975606300989134529888256.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-19894596978396851828890271744.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-1025813730144342370534031360.000, total=   2.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-38331316057499478958165458944.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-40639183822740160481247363072.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-977400516017461289658875904.000, total=   1.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-29215759910128609065217032192.000, total=   2.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-153662182683732162379776.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-6067924987326224238903296.000, total=   2.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-22761312626690959056306176.000, total=   3.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-2938689216579407129346048.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-14410652714119379713785856.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-3927720908595684018487296.000, total=   3.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-2107451096621561786925056.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-6032674113525367732961280.000, total=   3.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-2385097695713830738329600.000, total=   3.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-52280989699815821348438016.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-86544279274047458508800.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-2605661294328675806740480.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-16016840703880087552.000, total=   6.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-77165590375073284096.000, total=   6.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-25749321742294216704.000, total=   5.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-16806922732468221952.000, total=   8.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-137268089295558459392.000, total=   7.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-9371071755444785152.000, total=   7.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-18980617533082836992.000, total=   5.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-34867729572193759232.000, total=   7.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-18971702131403759616.000, total=   8.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-43141664881802780672.000, total=   5.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-266339861853196845056.000, total=   7.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-16178354439474036736.000, total=   7.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-61683965026511724123223228416.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-448400650654683186779247345664.000, total=   1.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-134248188727052517531835170816.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-33842010991236838527816695808.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1383176112889981119678644224.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-13933993496744499404666306560.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-251129026124923866211665575936.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-342908436335890949337920831488.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-25589269611905412222228103168.000, total=   1.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-159640041721227259631640772608.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-904527808462412542258446336.000, total=   2.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-99217407765066030709781561344.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-27566406773599049024951812096.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-18854998057695335132440821760.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-188629615163643969029537792.000, total=   2.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-19959244559608098554965393408.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-81348268789892371178080698368.000, total=   4.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-94574118262291862895810576384.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-481393761485333126962164531200.000, total=   2.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-52482353720684280069310382080.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-20203671624639822603818631168.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-13565484185683881419222286336.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-101021246948252935015513456640.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1621930229278018988549341184.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-9919635991279645491200.000, total=   7.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-6093529928582499926016.000, total=   6.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-5305499533692647768064.000, total=   6.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-27106464722167728701440.000, total=   7.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-11988698501332005289984.000, total=   6.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-564629547114441080832.000, total=   7.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-4872951149417925181440.000, total=   7.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-36560892853386850861056.000, total=   8.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-244303229469220601856.000, total=   8.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-49499897685079553474560.000, total=   8.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-18967552659545844088832.000, total=   7.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-9213502902699066130432.000, total=   7.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-1265953880518904747141365760.000, total=   2.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-426697896216345241746984140800.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-11350429553650596239722414080.000, total=   2.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-12360956882970267440295968768.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-23946777527776350883557670912.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-10529605214916218401687863296.000, total=   2.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-158329976609498484774669385728.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-889166547923603368966094848.000, total=   2.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-52210233479705030447889121280.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-117268232613999134891332075520.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-113094040861752528537309413376.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-109370709191677759390220288.000, total=   2.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-312767943452679348915535872.000, total=   2.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-74487975587083007131910144.000, total=   3.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-1671170766712330657141358592.000, total=   2.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-1104930772317488939536482304.000, total=   2.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-9737584411359231157993472.000, total=   3.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-1378949315855647998021206016.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-12593882469234402893234176.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-493462819579647036762357760.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-54377326060941617498423296.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1316730867767421198607056896.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1109272794070596771857301504.000, total=   2.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1903875357956633355211505664.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-128054238278386810880.000, total=   8.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-81000937654317121536.000, total=   8.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-275592131887394652160.000, total=   9.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-402456944931832266752.000, total=   7.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-230832638522406338560.000, total=   7.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-1391197606822215680000.000, total=   7.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-156669927238507659264.000, total=   7.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-516573186599084883968.000, total=   6.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-101151325835269668864.000, total=   9.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-449430789499762835456.000, total=   8.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-217937622389605924864.000, total=   7.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-70343282687547703296.000, total=   9.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-28277622726473863088071245824.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-8077925855332873459621429248.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-36846295282241599243577982976.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-52389968639082199397410275328.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-31996268866144600314097958912.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-55316246116384635605686943744.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-54155408478796249249301397504.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-12535759558978988986052116480.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-10278686257319200305102979072.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-20484194528538298342375948288.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-15391144488306558930855657472.000, total=   2.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-134463493502987154735314763776.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-2987404049630857535684608.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-1101742830789222696222720.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-10913636994237447639400448.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-13567697987997255805698048.000, total=   2.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-5203601731519449812434944.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-121646792455481783746560.000, total=   2.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-293883928190912695369728.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-6682914803974723065610240.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-6502101879859403028430848.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-665386008587475817070592.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1910899490730254400487424.000, total=   2.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1628824415355068819177472.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-12557937545803632640.000, total=   7.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-17040301109228795904.000, total=   7.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-2137675405405995264.000, total=   7.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-21018980658333319168.000, total=   8.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-51725301447520788480.000, total=   7.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-36120630617184456704.000, total=   8.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-19245197481048809472.000, total=   6.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-67584699640497627136.000, total=   5.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-15252179276310050816.000, total=   7.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-16053757638439878656.000, total=   8.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-23361435705912283136.000, total=   9.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-18959103219044429824.000, total=   8.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-91825774609646313745573478400.000, total=   2.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-42049805363434312121154797568.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-966536385868841954242046459904.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-162574562264301203508875493376.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-87090949587263675324226863104.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-100204987963153222619317141504.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-10064262755291390227284754432.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-3704223677080181163618729984.000, total=   2.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-25543128943254417438385635328.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-95291619187539435365335040.000, total=   2.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-51301856137765546732598329344.000, total=   2.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-25274589673682059132189802496.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-50830572734561250466332672.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-62206002668397937119786434560.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-1346996625642217207008067584.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-20321709920769863352418566144.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-1173356347971430342084001792.000, total=   2.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-16091549725650307912273231872.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-9112378390179363373403078656.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-90679632525987362972998041600.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-1675660456089166611132448768.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-15833101243846126548090355712.000, total=   2.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-393606200136926252741005672448.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-352908529594758450467471097856.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1479953192034853715968.000, total=   7.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-29476213049769079078912.000, total=   8.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-327637897343076597760.000, total=   7.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-3739192766021859540992.000, total=   6.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-1451779381155571957760.000, total=   6.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-4748248448149538996224.000, total=   7.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-9809911314160432447488.000, total=   7.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-1512384198160902258688.000, total=   8.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-1057436930994819039232.000, total=  10.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-34335491184608287916032.000, total=   7.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1005051589890365194240.000, total=   8.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-2772004004099408789504.000, total=   7.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-311686169776193348060418408448.000, total=   1.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-4154178648673772225855225856.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-3195105259113884515221635072.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-21727679334872952819670843392.000, total=   2.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-3719334741930968272571727872.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1606154465154986493349986304.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-6703825221535893461162524672.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-165534759351448261094151290880.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-4418548251191308794732740608.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-311923935307054414954303062016.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-192579545070340881040824860672.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-906164308430108205571190554624.000, total=   1.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-2127078170393029280387825664.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-1430239835627816367071166464.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-66726054829627873725251584.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-3615403010643548457167486976.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-72567641037439979428511744.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-1205141778830346520568528896.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-1288502694301400204578914304.000, total=   2.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-7578825004410621787530854400.000, total=   2.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-61536259417084214686777344.000, total=   2.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-5473159241763664405819555840.000, total=   1.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-468777092490175979515281408.000, total=   2.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-95604422565977570636988416.000, total=   1.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-59858630687484420096.000, total=   8.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-65169335046483099648.000, total=  10.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-72733192154711883776.000, total=   8.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-126100335846547406848.000, total=   7.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-66274928676327079936.000, total=   9.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-82741912459321556992.000, total=   7.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-519568653778807357440.000, total=   7.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-363166360434767167488.000, total=   7.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-1001472021241388990464.000, total=   8.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-859468726121909059584.000, total=   7.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-3576499978068794277888.000, total=   6.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-381187087347866206208.000, total=   6.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-161250116080326620742386974720.000, total=   2.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-12391701470470434349083787264.000, total=   1.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-86249617835910442391070310400.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-20604040784099010449118330880.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-135163315952783778362949632.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-6360288084305314427957149696.000, total=   2.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-15442428233570677127339048960.000, total=   1.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-371386079244937403635335168.000, total=   2.3s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-517751932111284003441509138432.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-71669931944503463127537418240.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-48964195200285340511198248960.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-131698325976459129437693149184.000, total=   2.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-10993387603022189942538240.000, total=   3.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-9043648826434939871297536.000, total=   2.1s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-814399938257404018294784.000, total=   1.6s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-114398466983065131417600.000, total=   1.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-723549091483502824652800.000, total=   2.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-17324581387129452704563200.000, total=   2.2s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-3512866157126695881015296.000, total=   1.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-68992368027721919365120.000, total=   2.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-35538585954534884783423488.000, total=   2.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-3894528218492853855191040.000, total=   3.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1575938656624921307774976.000, total=   2.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-2060950103132003530440704.000, total=   2.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-12233805604045017088.000, total=   8.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-60591163608453038080.000, total=   6.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-43926064398402854912.000, total=   5.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-357367220506442858496.000, total=   5.4s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-59449455084765216768.000, total=   8.8s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-35681512894312448000.000, total=   7.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-7695867283954707456.000, total=   6.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-26565810705372270592.000, total=  11.0s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-144465250003386449920.000, total=  13.5s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-20331044478737772544.000, total=   7.9s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-16667461835932352512.000, total=   7.7s\n",
      "[CV] alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=0.0001, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-605584303680360677376.000, total=   8.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-39976979984394089728179175424.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-17888276539252725052631678976.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-755648172739817378397781229568.000, total=   1.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-2345090966726336763272397586432.000, total=   1.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1299145669063057460536140627968.000, total=   2.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-7539084236564495829359600336896.000, total=   1.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-174399808289777705352305836032.000, total=   3.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-690829274914871713848417583104.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-9624039658443479922127470067712.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-5121600349761495798262819454976.000, total=   1.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-2811541739790442021760817692672.000, total=   2.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-8494662708930671842038168682496.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-42201757447245219276305465344.000, total=   3.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-19732456464735489640831647744.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-3950194433992744259773530112.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-1078419394536302194076942336.000, total=   1.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-35121668538645898744811225088.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-3774286581653272681416491008.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-311920522026371929945545900032.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-7656353121241220374239117312.000, total=   2.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-177297063799671519900157870080.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-6680064526480111395821060096.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-244754287367457807698562646016.000, total=   2.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-194989672513134362959628206080.000, total=   1.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-11955619112933163794432.000, total=   7.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-6228607771705426837504.000, total=   9.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-20919206148911067561984.000, total=  14.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-14110333653469670408192.000, total=   8.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-14411009234201766526976.000, total=   8.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-13703982136926092132352.000, total=   9.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-48976153562983987937280.000, total=   8.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-13330671301593007128576.000, total=   9.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-5381229026596678008832.000, total=  11.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-13726044887684231462912.000, total=   8.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-67724841925027729244160.000, total=  11.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-18021501348676288643072.000, total=   7.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-3280089109672370174982059196416.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-115512175601537532932334288896.000, total=   2.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-2652999142615523693422897528832.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-4806394453074340536108997148672.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-585637569751744804453718425600.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-8048903770822290580086198370304.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-623712480069447938228617216000.000, total=   1.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-583192461318655241409303412736.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-17115600770913014081740009897984.000, total=   1.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-14544476977727249502918680772608.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-18113033782320957310706846269440.000, total=   1.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-64687124418308956893598835539968.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-975339151395587628984172544.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-1070796110424410899567607808.000, total=   1.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-144059493913691954087985152.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-1884657031199138742206988288.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-353459251423812708527505408.000, total=   1.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-617778248042696812059951104.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-12144280391115682549258518528.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-52622159907935184582868992.000, total=   1.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-88553155069782637485752320.000, total=   2.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-38631369021816961067122688.000, total=   2.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-279118580392302457447776256.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-115788823852878217219145728.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-3645634458578118508544.000, total=   8.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-5926067978258732810240.000, total=   8.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1512379801526408577024.000, total=   6.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-6836453469005523451904.000, total=   7.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-494811279746377252864.000, total=   7.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-2253589339986403000320.000, total=   9.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-1865792770064280190976.000, total=   7.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-2495315952905645195264.000, total=   8.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-1076072771163745943552.000, total=   8.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-3238928965644572950528.000, total=   6.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-4209916592733501784064.000, total=   7.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1833672052794259406848.000, total=   8.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-12879469846460653736447979814912.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-1572452743742594141375176900608.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-7342134897900188789369858949120.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-8081365541537968929883564277760.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-383514835588562667078426820608.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-19350975057372262151274903896064.000, total=   1.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-3040604902032407169435791523840.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-672424345540507609257859874816.000, total=   2.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-93268774591964574089517268467712.000, total=   1.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-9203818291793775930568760885248.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-9926150659533693830116575019008.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-18068607387409596646424928321536.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-516239477671915241340928.000, total=   2.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-8879217488812264524873728.000, total=   2.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-31670502080679378432294912.000, total=   2.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-54230311401023878153109504.000, total=   2.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-2212720580592440918933504.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-15668137453943726717009920.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-737002490348913389731840.000, total=   2.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-8208623186843662597226496.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-307908444119397929320448.000, total=   2.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-3410460806614768735485952.000, total=   2.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-2084233498599881527263232.000, total=   1.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-410737766082576767778816.000, total=   3.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-34284812875190575104.000, total=   8.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-13501582688249722880.000, total=   7.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-74044864773741199360.000, total=   7.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-112538361034042294272.000, total=   5.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-234612750839589371904.000, total=   8.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-25983080468514476032.000, total=   6.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-25308028451357339648.000, total=   6.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-129594229004093095936.000, total=   6.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-36619694371608838144.000, total=   6.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-8370570251095766016.000, total=   7.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-74201001321335144448.000, total=   7.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.1, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-69014181463873470464.000, total=   7.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-13522030970707423735477625159680.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-17312489834083362289562058489856.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-450227855010417387100895707136.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-6332974420146097709562642563072.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-516769625892842478090074456064.000, total=   2.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-21313810131754371898871994384384.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-33796322497124048968251785347072.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-1092157917890513458857334800384.000, total=   2.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-234618252523508241412281860096.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-28669348657373560447038121836544.000, total=   1.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-14938904451482251169195861475328.000, total=   2.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-189904935825980822928022831104.000, total=   2.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-13702137779940579104134266880.000, total=   2.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-55237687541059350825604743168.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-59118700144269598410405838848.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-120666275099484733129395011584.000, total=   3.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-380713154853854863820404555776.000, total=   1.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-5595347397679957450778738688.000, total=   3.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-65896722057339013276828172288.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-32907633838479769837900922880.000, total=   1.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-77850538623968924433171611648.000, total=   1.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-513160066067872804863976931328.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-487822465944013561638688915456.000, total=   2.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-136092846572816643497553559552.000, total=   2.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-16416556788921921437696.000, total=   8.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-18776518165799433666560.000, total=  10.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-22056290248850233360384.000, total=  11.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-44845619931379100811264.000, total=   8.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-11545029448381109370880.000, total=  10.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-4806050932644684759040.000, total=  10.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-5220840765061245960192.000, total=   8.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-33680545544692960329728.000, total=   8.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-12291154913898291789824.000, total=   9.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-18306360560484807081984.000, total=   9.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-16530757601765070209024.000, total=   9.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-42517167121262392115200.000, total=  10.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-22618083710973027881624535040.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-1014835044907283435580328771584.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-739689918352480312916411678720.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-3500152154233297307571591315456.000, total=   2.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1460477558447125261739161026560.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-748961914182338110626958671872.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-176168460216580703825994711040.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-10127777338491365142944362266624.000, total=   2.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-377085432417800025398805790720.000, total=   2.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-198828292309915302784420349476864.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-14317922565636163174015969525760.000, total=   2.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-9046622499123481090705047158784.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-2241719620465514514145607680.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-219128022810234652154920960.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-1654154214805024188382838784.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-796462531487646065979555840.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-41463090629054073080381440.000, total=   3.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-333752231941487254982098944.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-2430616722786238860571443200.000, total=   2.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-285459661938372728630280192.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-4283125922617987334334840832.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1319234903978921137520246784.000, total=   2.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-2944173623403621753643073536.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-14990802566776586141433856.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1272018034656641548288.000, total=  10.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1908993091647772819456.000, total=   7.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-3069716021903186984960.000, total=   9.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-1448094976939903942656.000, total=   9.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-7648282823946784473088.000, total=   8.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-2013935849846019981312.000, total=   9.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-6776591954497592360960.000, total=   7.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-474779554297036079104.000, total=   8.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-3597823277047374413824.000, total=   9.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-21687449043738581532672.000, total=   6.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1507639563763320356864.000, total=   8.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-5158264665619155648512.000, total=   7.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-7553641769987397994617017204736.000, total=   1.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-8200715827210571895384974557184.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-1422166809101598574591197839360.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-585876295691626160595828473856.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-5478521714366076836478181179392.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-711405428322887857972464058368.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-7740150888114363270878738776064.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-1711726252330944679130054000640.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-1175393759026051804319044337664.000, total=   2.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-1560330682602328145869441859584.000, total=   1.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-6842858681479866013009502535680.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-7209971580468774002115666247680.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-11452867215059767558930432.000, total=   2.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-279576916388316253782016.000, total=   2.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-1361578856220018153095168.000, total=   3.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-16789059831913687057170432.000, total=   1.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-617001090622813798137856.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-5683493098874945883078656.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-28092942445982826014703616.000, total=   3.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-63643852033791231201902592.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-26161700471109339578368.000, total=   2.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-383060220177438530863104.000, total=   2.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-29343627002855506871058432.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1052542274785417789177856.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-28982126451722911744.000, total=   8.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-69861346349907558400.000, total=   9.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-70360264594651660288.000, total=   6.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-17870521872356589568.000, total=   6.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-23649780373985161216.000, total=   8.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-124881543967086067712.000, total=   9.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-50197540834150506496.000, total=   5.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-92922940637563437056.000, total=   8.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-1045949036523288002560.000, total=   6.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-9965122620804909056.000, total=   8.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-681766969664638812160.000, total=   7.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.01, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-13814097117446514688.000, total=   6.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-3628963705273730528117881044992.000, total=   2.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-410093446870301607980487933952.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-3334153953969396309238061465600.000, total=   1.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-45560451470279007453462443065344.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-14518153859907159212005718491136.000, total=   2.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-11024610230092093918813062430720.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-5375708944331702486866476400640.000, total=   2.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-4394296136925550423860326694912.000, total=   1.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-299927329601112811353090818048.000, total=   2.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-2912213364525098597275926528.000, total=   1.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-2778975893909935630413115424768.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-1480766610880371922792335015936.000, total=   1.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-61379460505808508000388775936.000, total=   2.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-44156642720677995406663090176.000, total=   2.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-1904468204339324673706688512.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-20042948076325554601272016896.000, total=   2.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-2832681706794863249888116736.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-42463828598309851819996610560.000, total=   1.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-11545677896045874299464056832.000, total=   2.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-33087505461751650938364362752.000, total=   2.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-62084941249904570646478716928.000, total=   2.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-86346135383200384064128286720.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-27547602135992557500610117632.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-3631997804796479332788731904.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-6223810281814290857984.000, total=   9.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-25105357508546035449856.000, total=   8.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-2255768819342931394560.000, total=  10.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-24645228441098313007104.000, total=   7.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-42873589838819142664192.000, total=   8.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-12273591587200059834368.000, total=  10.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-3708448175829920776192.000, total=   8.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-10877267548961905836032.000, total=  10.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-25490619685090136948736.000, total=  10.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-9713414840707675324416.000, total=   8.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-22961631494936094310400.000, total=   7.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-4985797427969272053760.000, total=  10.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-4411792875743365126550152282112.000, total=   2.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-636579601671386769506288271360.000, total=   1.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-3603462265993026389664117817344.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1171786454738752480456799682560.000, total=   2.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-32377700469987901086178312454144.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1462001650013625815315320406016.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-6262431936330925853727290032128.000, total=   2.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-217448364607215050400429244416.000, total=   2.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-260874435471333920695444832256.000, total=   2.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-25827013264765700569657642057728.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-3804276266356381369288657731584.000, total=   2.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-141582940914078824259639050240.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-209508014040421099582259200.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-48034328525200230763724800.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-359046014087971247015067648.000, total=   2.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-2448887636705413409670168576.000, total=   2.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-65941868830983027857293312.000, total=   2.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-4166417466959476863235260416.000, total=   3.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-19462871091079603736805376.000, total=   2.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-3407857654124584161081556992.000, total=   2.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-1418586327175141309378723840.000, total=   1.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-370635111257043246419804160.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-1122868317184213308779003904.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-10509444484128242239799296.000, total=   2.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1029179624876944654336.000, total=   7.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-5653261003207360905216.000, total=   8.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-43357007864724577058816.000, total=   7.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-3221999433030699581440.000, total=   6.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-2941823621341650616320.000, total=   7.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-2332791348134619381760.000, total=   7.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-622158772299049074688.000, total=  10.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-7632575099612679897088.000, total=   8.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-3593919276521548677120.000, total=   6.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-6463859229080382603264.000, total=   7.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-1783626094055857586176.000, total=   7.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-19020844048965125013504.000, total=   8.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-343886426332661276771744743424.000, total=   2.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-1559958695396028932275553959936.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-2165526789550126755928409636864.000, total=   2.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-458713249009800056806018383872.000, total=   2.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-31579361025700716248507625766912.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-5179910077124543659688427782144.000, total=   1.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-142549430863826387028758495232.000, total=   2.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-1142278707548712664095560564736.000, total=   1.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-10545993290724711919719391690752.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-7107224914908342875605199486976.000, total=   2.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-719466766302326597154645213184.000, total=   2.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-4683313278610183392327127531520.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-65248394108266562453504.000, total=   3.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-6942650315857923024093184.000, total=   2.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-23654100729076021725233152.000, total=   3.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-498942073948238017200128.000, total=   2.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-18517262797772418839478272.000, total=   2.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-1024712547531024081354752.000, total=   1.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-2710827566534263318773760.000, total=   1.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-4653490535758563662364672.000, total=   2.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-3993984662054316583944192.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-719771073770889416802304.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-201924715530540550193152.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-5173824940459795939328.000, total=   1.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-93769569067121180672.000, total=   7.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-35519010155041214464.000, total=   6.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-159654965540557848576.000, total=   6.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-48092657765291327488.000, total=   6.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-11199213641651163136.000, total=   8.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-78924127240805285888.000, total=   7.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-35835665336412409856.000, total=   5.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-128599711184467345408.000, total=   7.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-30413951460958732288.000, total=   5.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-19292280176479944704.000, total=   6.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-100348568313317310464.000, total=   8.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-43866229546402668544.000, total=   5.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-1784430795177049865849048924160.000, total=   2.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-968721243574125211064188534784.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-260366198749017402783400198144.000, total=   2.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-325871268095642675947482644480.000, total=   3.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-13296812493951776668089875169280.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1795769860486827150885160747008.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-11651103166309271345494340141056.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-14941133421815059313713349656576.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.01, score=-798786923655893421889299677184.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-70824476716959983671092778631168.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-373383576354678264652982386688.000, total=   1.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, tol=0.1, score=-16979926297544100940190090002432.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-61588913406681626928436215808.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-3370620656312924593318789120.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-12258436060767074899051151360.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-11854874262384425839190081536.000, total=   2.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-33585423750657108667172651008.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-147922566998249414695791362048.000, total=   1.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-39623117932396086907837087744.000, total=   1.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-75507419781633686592167084032.000, total=   2.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-290526832492727795776743276544.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-30779839940930840619762319360.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-7710854929660005227891261440.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-893831971594174630824582840320.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-9117804888257113096192.000, total=   8.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-18158044813038758920192.000, total=  11.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-68145345921932939231232.000, total=  10.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-4899683322098914164736.000, total=   8.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-13678453294932317700096.000, total=   9.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-5355999713295724445696.000, total=  11.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-22025220914959997730816.000, total=   8.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-95110512613722920321024.000, total=   8.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-24796037522796356567040.000, total=   8.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-10302861817295843360768.000, total=   9.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-23033182117356896256000.000, total=   7.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-7068114474471893499904.000, total=   8.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-8100244501310307604443359608832.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-1140995137890855479102339547136.000, total=   2.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-230305747864708071697963548672.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-61341503268027918355055452880896.000, total=   1.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-1749474063495308046687023398912.000, total=   1.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.001, score=-580178461424071971734592421888.000, total=   2.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-708283950377777963866334953472.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-934526340875420891607780556800.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.01, score=-3813318713109549614041996984320.000, total=   2.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-1611200167075554510497225113600.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-1326709428551395598691345629184.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, tol=0.1, score=-453137386186854811110293372928.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-100430117539155223282450432.000, total=   2.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-484687475012404293270503424.000, total=   2.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-68895911847256796380004352.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-360239679945430439569653760.000, total=   1.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-1281257817991880089496715264.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-72681703935447299432382464.000, total=   2.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-96711442419597840624910336.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-14120385571998406266585088.000, total=   2.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-44513388093662591679725568.000, total=   1.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-18868793894040632094097408.000, total=   3.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-843907890262212216470110208.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-44471966557735992380358656.000, total=   2.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-1214960585266667454464.000, total=  10.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-2437164518770794823680.000, total=   7.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-3753847769683253002240.000, total=   8.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-3086506539601580523520.000, total=   9.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-2665344728711183204352.000, total=   9.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-4656821833085313613824.000, total=   7.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-517689489760355352576.000, total=   7.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-4225089254689902428160.000, total=   6.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-1923610351018493083648.000, total=   7.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-3793256906284934365184.000, total=   8.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-2653432190515401457664.000, total=   6.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-3798786849163074600960.000, total=   9.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-14102900624679604230784286720.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-1251033264727889425186187902976.000, total=   2.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.0001, score=-76405206815769049904946610176.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-244429328049341286020385079296.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-113765901264368222416851173376.000, total=   4.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.001, score=-6235005127814092481631094833152.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-41619298938358382541379314122752.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-2603504741807266471925778481152.000, total=   1.2s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.01, score=-35521084780136576663857135616.000, total=   1.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-1436730273814222661536519815168.000, total=   1.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-437908927559588858180826824704.000, total=   2.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=optimal, max_iter=1000, tol=0.1, score=-31786861912637167913545309880320.000, total=   1.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-10378820656850259991855104.000, total=   2.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-7190822095433879701684224.000, total=   2.5s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.0001, score=-8178629403024315950039040.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-224035736942941256548352.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-1526483476609841324097536.000, total=   1.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.001, score=-10008355155687404635947008.000, total=   1.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-15506270071430539504517120.000, total=   1.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-307595873881415802159104.000, total=   2.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.01, score=-174480558058841242175799296.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-10358555381554919455588352.000, total=   3.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-2736335569043372340412416.000, total=   1.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=invscaling, max_iter=1000, tol=0.1, score=-2667367438100683951177728.000, total=   2.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-60140157760035651584.000, total=   6.4s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-208921544930863185920.000, total=   6.7s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.0001, score=-95053344010100146176.000, total=   7.0s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-10322318983887609856.000, total=   7.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-115438050304269484032.000, total=   9.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.001, score=-56005777531930755072.000, total=   6.1s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-47104132755423059968.000, total=   7.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-9640221385435844608.000, total=   9.8s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.01, score=-90817994064162455552.000, total=   7.9s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-82987389726879465472.000, total=   7.6s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-18502384230603878400.000, total=   6.3s\n",
      "[CV] alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1 \n",
      "[CV]  alpha=1e-05, early_stopping=True, epsilon=0.0001, eta0=0.001, learning_rate=adaptive, max_iter=1000, tol=0.1, score=-58864061049209602048.000, total=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1728 out of 1728 | elapsed: 107.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SGDRegressor(alpha=0.0001, average=False,\n",
       "                                    early_stopping=False, epsilon=0.1,\n",
       "                                    eta0=0.01, fit_intercept=True,\n",
       "                                    l1_ratio=0.15, learning_rate='invscaling',\n",
       "                                    loss='squared_loss', max_iter=1000000,\n",
       "                                    n_iter_no_change=5, penalty='l2',\n",
       "                                    power_t=0.25, random_state=None,\n",
       "                                    shuffle=True, tol=0.001,\n",
       "                                    validation_fraction...\n",
       "                                    warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'alpha': [0.01, 0.001, 0.0001, 1e-05],\n",
       "                         'early_stopping': [True],\n",
       "                         'epsilon': [0.1, 0.01, 0.001, 0.0001],\n",
       "                         'eta0': [0.1, 0.01, 0.001],\n",
       "                         'learning_rate': ['optimal', 'invscaling', 'adaptive'],\n",
       "                         'max_iter': [1000],\n",
       "                         'tol': [0.0001, 0.001, 0.01, 0.1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_grid.fit(imp_X_train, imp_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -3.7224229650670874e+17\n",
      "Best Params: {'alpha': 0.01, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.001, 'learning_rate': 'adaptive', 'max_iter': 1000, 'tol': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# List the best score\n",
    "print(f'Best Score: {imp_grid.best_score_}')\n",
    "print(f'Best Params: {imp_grid.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01,\n",
       " 'early_stopping': True,\n",
       " 'epsilon': 0.1,\n",
       " 'eta0': 0.001,\n",
       " 'learning_rate': 'adaptive',\n",
       " 'max_iter': 1000,\n",
       " 'tol': 0.1}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(grid.best_params_)\n",
    "imp_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.01, average=False, early_stopping=True, epsilon=0.1,\n",
       "             eta0=0.001, fit_intercept=True, l1_ratio=0.15,\n",
       "             learning_rate='adaptive', loss='squared_loss', max_iter=1000,\n",
       "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
       "             shuffle=True, tol=0.1, validation_fraction=0.1, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_clf_test = linear_model.SGDRegressor(alpha = imp_grid.best_params_['alpha'], \\\n",
    "                        early_stopping = imp_grid.best_params_['early_stopping'], \\\n",
    "                        epsilon = imp_grid.best_params_['epsilon'], eta0 = imp_grid.best_params_['eta0'], \\\n",
    "                        learning_rate = imp_grid.best_params_['learning_rate'], \\\n",
    "                        tol = imp_grid.best_params_['tol'], \n",
    "                        max_iter = imp_grid.best_params_['max_iter'])\n",
    "imp_clf_test.fit(imp_X_train_scaled, imp_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method RegressorMixin.score of SGDRegressor(alpha=0.01, average=False, early_stopping=True, epsilon=0.1,\n",
       "             eta0=0.001, fit_intercept=True, l1_ratio=0.15,\n",
       "             learning_rate='adaptive', loss='squared_loss', max_iter=1000,\n",
       "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
       "             shuffle=True, tol=0.1, validation_fraction=0.1, verbose=0,\n",
       "             warm_start=False)>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_clf_test.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38987923129130586"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_test_score = imp_clf_test.score(imp_X_train_scaled, imp_y_train)\n",
    "imp_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39968806715558475"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_test_new_score = imp_clf_test.score(imp_X_test_scaled, imp_y_test)\n",
    "imp_test_new_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7066700029062856"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_score = clf.score(X_test_scaled, true_values)\n",
    "new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns = ['Prediction', 'Actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['Prediction'] = scaled_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['Actual'] = true_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxwellpatterson/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "percent_change = []\n",
    "for i in range(len(scaled_predict)):\n",
    "    percent_change.append(100 *(scaled_predict[i] - true_values[i]) / true_values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['Percent Change'] = percent_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-100, -20, -10, -5, 0, 5, 10, 20, 100]\n",
    "labels = ['-100% to -20%','-20% to -10%','-10% to -5%', '-5% to 0%', '0% to 5%', '5% to 10%', '10% to 20%', '20% to 100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['binned'] = pd.cut(results_df['Percent Change'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20% to 100       115352\n",
       "10% to 20%        57066\n",
       "5% to 10%         29634\n",
       "0% to 5%          25742\n",
       "-100% to -20%     24480\n",
       "-5% to 0%         18149\n",
       "-20% to -10%      11594\n",
       "-10% to -5%       10787\n",
       "Name: binned, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['binned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Percent Change</th>\n",
       "      <th>binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.821305</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.106525</td>\n",
       "      <td>0% to 5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.419028</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.190282</td>\n",
       "      <td>10% to 20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.213657</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.273143</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.289945</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-11.400364</td>\n",
       "      <td>-20% to -10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.652687</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-13.473132</td>\n",
       "      <td>-20% to -10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.566725</td>\n",
       "      <td>12.5</td>\n",
       "      <td>16.533800</td>\n",
       "      <td>10% to 20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.275509</td>\n",
       "      <td>7.5</td>\n",
       "      <td>23.673447</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.046781</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.935617</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.019268</td>\n",
       "      <td>27.5</td>\n",
       "      <td>30.979156</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.425715</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.257155</td>\n",
       "      <td>0% to 5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.491948</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.838957</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.161056</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-26.711548</td>\n",
       "      <td>-100% to -20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.016888</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-39.831119</td>\n",
       "      <td>-100% to -20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12.094715</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.947151</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.926293</td>\n",
       "      <td>12.5</td>\n",
       "      <td>11.410344</td>\n",
       "      <td>10% to 20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.661426</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.614258</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.885087</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.701749</td>\n",
       "      <td>10% to 20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.023686</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.473726</td>\n",
       "      <td>0% to 5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.783943</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-48.107049</td>\n",
       "      <td>-100% to -20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.417774</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-11.644517</td>\n",
       "      <td>-20% to -10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.707694</td>\n",
       "      <td>2.5</td>\n",
       "      <td>128.307759</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.363144</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.262880</td>\n",
       "      <td>5% to 10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.620260</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.135067</td>\n",
       "      <td>0% to 5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15.044934</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-39.820264</td>\n",
       "      <td>-100% to -20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19.844921</td>\n",
       "      <td>10.0</td>\n",
       "      <td>98.449208</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.198504</td>\n",
       "      <td>5.0</td>\n",
       "      <td>43.970074</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16.575273</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.501818</td>\n",
       "      <td>10% to 20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.162972</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-42.696220</td>\n",
       "      <td>-100% to -20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12.763888</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.638884</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9.732073</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-2.679274</td>\n",
       "      <td>-5% to 0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299368</th>\n",
       "      <td>8.424313</td>\n",
       "      <td>5.0</td>\n",
       "      <td>68.486266</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299369</th>\n",
       "      <td>7.528184</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.375782</td>\n",
       "      <td>0% to 5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299370</th>\n",
       "      <td>17.743042</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.286945</td>\n",
       "      <td>10% to 20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299371</th>\n",
       "      <td>14.660012</td>\n",
       "      <td>12.5</td>\n",
       "      <td>17.280100</td>\n",
       "      <td>10% to 20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299372</th>\n",
       "      <td>8.446634</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-32.426926</td>\n",
       "      <td>-100% to -20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299373</th>\n",
       "      <td>13.269696</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-33.651519</td>\n",
       "      <td>-100% to -20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299374</th>\n",
       "      <td>5.412510</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.250194</td>\n",
       "      <td>5% to 10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299375</th>\n",
       "      <td>5.698793</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.975864</td>\n",
       "      <td>10% to 20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299376</th>\n",
       "      <td>15.441256</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.941708</td>\n",
       "      <td>0% to 5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299377</th>\n",
       "      <td>14.413523</td>\n",
       "      <td>10.0</td>\n",
       "      <td>44.135233</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299378</th>\n",
       "      <td>12.972142</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.721424</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299379</th>\n",
       "      <td>27.947241</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39.736206</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299380</th>\n",
       "      <td>7.914447</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.525960</td>\n",
       "      <td>5% to 10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299381</th>\n",
       "      <td>5.745043</td>\n",
       "      <td>2.5</td>\n",
       "      <td>129.801728</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299382</th>\n",
       "      <td>10.703921</td>\n",
       "      <td>7.5</td>\n",
       "      <td>42.718949</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299383</th>\n",
       "      <td>10.911840</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.118400</td>\n",
       "      <td>5% to 10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299384</th>\n",
       "      <td>20.608835</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.764769</td>\n",
       "      <td>10% to 20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299385</th>\n",
       "      <td>8.564816</td>\n",
       "      <td>7.5</td>\n",
       "      <td>14.197540</td>\n",
       "      <td>10% to 20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299386</th>\n",
       "      <td>3.745252</td>\n",
       "      <td>2.5</td>\n",
       "      <td>49.810100</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299387</th>\n",
       "      <td>8.142596</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.851920</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299388</th>\n",
       "      <td>23.435781</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-41.410547</td>\n",
       "      <td>-100% to -20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299389</th>\n",
       "      <td>5.317642</td>\n",
       "      <td>2.5</td>\n",
       "      <td>112.705682</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299390</th>\n",
       "      <td>8.851191</td>\n",
       "      <td>7.5</td>\n",
       "      <td>18.015875</td>\n",
       "      <td>10% to 20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299391</th>\n",
       "      <td>8.901859</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-10.981409</td>\n",
       "      <td>-20% to -10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299392</th>\n",
       "      <td>10.120160</td>\n",
       "      <td>5.0</td>\n",
       "      <td>102.403200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299393</th>\n",
       "      <td>5.306030</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.120603</td>\n",
       "      <td>5% to 10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299394</th>\n",
       "      <td>19.127471</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.516473</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299395</th>\n",
       "      <td>4.882836</td>\n",
       "      <td>2.5</td>\n",
       "      <td>95.313456</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299396</th>\n",
       "      <td>11.112588</td>\n",
       "      <td>7.5</td>\n",
       "      <td>48.167840</td>\n",
       "      <td>20% to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299397</th>\n",
       "      <td>14.288219</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-4.745206</td>\n",
       "      <td>-5% to 0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299398 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Prediction  Actual  Percent Change         binned\n",
       "0        20.821305    20.0        4.106525       0% to 5%\n",
       "1        11.419028    10.0       14.190282     10% to 20%\n",
       "2         6.213657     5.0       24.273143     20% to 100\n",
       "3        13.289945    15.0      -11.400364   -20% to -10%\n",
       "4         8.652687    10.0      -13.473132   -20% to -10%\n",
       "5        14.566725    12.5       16.533800     10% to 20%\n",
       "6         9.275509     7.5       23.673447     20% to 100\n",
       "7         6.046781     5.0       20.935617     20% to 100\n",
       "8        36.019268    27.5       30.979156     20% to 100\n",
       "9        10.425715    10.0        4.257155       0% to 5%\n",
       "10        6.491948     5.0       29.838957     20% to 100\n",
       "11        9.161056    12.5      -26.711548  -100% to -20%\n",
       "12        6.016888    10.0      -39.831119  -100% to -20%\n",
       "13       12.094715    10.0       20.947151     20% to 100\n",
       "14       13.926293    12.5       11.410344     10% to 20%\n",
       "15       12.661426    10.0       26.614258     20% to 100\n",
       "16        5.885087     5.0       17.701749     10% to 20%\n",
       "17        5.023686     5.0        0.473726       0% to 5%\n",
       "18        7.783943    15.0      -48.107049  -100% to -20%\n",
       "19        4.417774     5.0      -11.644517   -20% to -10%\n",
       "20        5.707694     2.5      128.307759            NaN\n",
       "21        5.363144     5.0        7.262880      5% to 10%\n",
       "22       15.620260    15.0        4.135067       0% to 5%\n",
       "23       15.044934    25.0      -39.820264  -100% to -20%\n",
       "24       19.844921    10.0       98.449208     20% to 100\n",
       "25        7.198504     5.0       43.970074     20% to 100\n",
       "26       16.575273    15.0       10.501818     10% to 20%\n",
       "27        7.162972    12.5      -42.696220  -100% to -20%\n",
       "28       12.763888    10.0       27.638884     20% to 100\n",
       "29        9.732073    10.0       -2.679274      -5% to 0%\n",
       "...            ...     ...             ...            ...\n",
       "299368    8.424313     5.0       68.486266     20% to 100\n",
       "299369    7.528184     7.5        0.375782       0% to 5%\n",
       "299370   17.743042    15.0       18.286945     10% to 20%\n",
       "299371   14.660012    12.5       17.280100     10% to 20%\n",
       "299372    8.446634    12.5      -32.426926  -100% to -20%\n",
       "299373   13.269696    20.0      -33.651519  -100% to -20%\n",
       "299374    5.412510     5.0        8.250194      5% to 10%\n",
       "299375    5.698793     5.0       13.975864     10% to 20%\n",
       "299376   15.441256    15.0        2.941708       0% to 5%\n",
       "299377   14.413523    10.0       44.135233     20% to 100\n",
       "299378   12.972142    10.0       29.721424     20% to 100\n",
       "299379   27.947241    20.0       39.736206     20% to 100\n",
       "299380    7.914447     7.5        5.525960      5% to 10%\n",
       "299381    5.745043     2.5      129.801728            NaN\n",
       "299382   10.703921     7.5       42.718949     20% to 100\n",
       "299383   10.911840    10.0        9.118400      5% to 10%\n",
       "299384   20.608835    17.5       17.764769     10% to 20%\n",
       "299385    8.564816     7.5       14.197540     10% to 20%\n",
       "299386    3.745252     2.5       49.810100     20% to 100\n",
       "299387    8.142596     5.0       62.851920     20% to 100\n",
       "299388   23.435781    40.0      -41.410547  -100% to -20%\n",
       "299389    5.317642     2.5      112.705682            NaN\n",
       "299390    8.851191     7.5       18.015875     10% to 20%\n",
       "299391    8.901859    10.0      -10.981409   -20% to -10%\n",
       "299392   10.120160     5.0      102.403200            NaN\n",
       "299393    5.306030     5.0        6.120603      5% to 10%\n",
       "299394   19.127471    15.0       27.516473     20% to 100\n",
       "299395    4.882836     2.5       95.313456     20% to 100\n",
       "299396   11.112588     7.5       48.167840     20% to 100\n",
       "299397   14.288219    15.0       -4.745206      -5% to 0%\n",
       "\n",
       "[299398 rows x 4 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x18a725a58>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(results_df['Prediction'], results_df['Actual'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x13a0d23c8>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X['Trip Seconds'], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clf = linear_model.SGDRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'alpha': [.01, .001, .0001, .00001],\n",
    "#               'epsilon': [0.1, 0.01, 0.001, 0.0001],\n",
    "#               'learning_rate' : ['optimal', 'invscaling', 'adaptive'],\n",
    "#               'eta0':[.1, .01, .001],\n",
    "#               'early_stopping' : [True],\n",
    "#               'tol': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "              'max_iter' : [1000, 10000, 100000]}\n",
    "grid = GridSearchCV(test_clf, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'average', 'early_stopping', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter_no_change', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxwellpatterson/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] alpha=0.01, max_iter=1000 .......................................\n",
      "[CV]  alpha=0.01, max_iter=1000, score=-31893278059770681088802816.000, total= 7.6min\n",
      "[CV] alpha=0.01, max_iter=1000 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  7.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, max_iter=1000, score=-156157594216551658188439552.000, total= 3.4min\n",
      "[CV] alpha=0.01, max_iter=1000 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 11.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, max_iter=1000, score=-465342701870478845062152192.000, total= 4.6min\n",
      "[CV] alpha=0.01, max_iter=10000 ......................................\n",
      "[CV]  alpha=0.01, max_iter=10000, score=-1199010896811540512505856.000, total= 6.1min\n",
      "[CV] alpha=0.01, max_iter=10000 ......................................\n",
      "[CV]  alpha=0.01, max_iter=10000, score=-164793525105497831284670464.000, total= 3.9min\n",
      "[CV] alpha=0.01, max_iter=10000 ......................................\n",
      "[CV]  alpha=0.01, max_iter=10000, score=-48574168776107689089433600.000, total= 3.4min\n",
      "[CV] alpha=0.01, max_iter=100000 .....................................\n",
      "[CV]  alpha=0.01, max_iter=100000, score=-18862714017205143763681280.000, total= 5.1min\n",
      "[CV] alpha=0.01, max_iter=100000 .....................................\n",
      "[CV]  alpha=0.01, max_iter=100000, score=-350725786489393821501095936.000, total= 4.7min\n",
      "[CV] alpha=0.01, max_iter=100000 .....................................\n",
      "[CV]  alpha=0.01, max_iter=100000, score=-74592577823282628736843776.000, total= 4.7min\n",
      "[CV] alpha=0.001, max_iter=1000 ......................................\n",
      "[CV]  alpha=0.001, max_iter=1000, score=-51429531466053767439319040.000, total= 6.3min\n",
      "[CV] alpha=0.001, max_iter=1000 ......................................\n",
      "[CV]  alpha=0.001, max_iter=1000, score=-295820980707826972422569984.000, total= 3.0min\n",
      "[CV] alpha=0.001, max_iter=1000 ......................................\n",
      "[CV]  alpha=0.001, max_iter=1000, score=-131349533455052672352649216.000, total= 5.2min\n",
      "[CV] alpha=0.001, max_iter=10000 .....................................\n",
      "[CV]  alpha=0.001, max_iter=10000, score=-732033893794760776044511232.000, total= 5.0min\n",
      "[CV] alpha=0.001, max_iter=10000 .....................................\n",
      "[CV]  alpha=0.001, max_iter=10000, score=-393803155154376673164525568.000, total= 3.8min\n",
      "[CV] alpha=0.001, max_iter=10000 .....................................\n",
      "[CV]  alpha=0.001, max_iter=10000, score=-367395220820655566802124800.000, total= 5.5min\n",
      "[CV] alpha=0.001, max_iter=100000 ....................................\n",
      "[CV]  alpha=0.001, max_iter=100000, score=-14182354602866206742413312.000, total= 5.2min\n",
      "[CV] alpha=0.001, max_iter=100000 ....................................\n",
      "[CV]  alpha=0.001, max_iter=100000, score=-447317659778296209049911296.000, total= 3.9min\n",
      "[CV] alpha=0.001, max_iter=100000 ....................................\n",
      "[CV]  alpha=0.001, max_iter=100000, score=-98860809935557506895970304.000, total= 4.4min\n",
      "[CV] alpha=0.0001, max_iter=1000 .....................................\n",
      "[CV]  alpha=0.0001, max_iter=1000, score=-298920783805251828561477632.000, total= 4.6min\n",
      "[CV] alpha=0.0001, max_iter=1000 .....................................\n",
      "[CV]  alpha=0.0001, max_iter=1000, score=-104573927143197233989550080.000, total= 4.8min\n",
      "[CV] alpha=0.0001, max_iter=1000 .....................................\n",
      "[CV]  alpha=0.0001, max_iter=1000, score=-250397845882417622468788224.000, total= 5.3min\n",
      "[CV] alpha=0.0001, max_iter=10000 ....................................\n",
      "[CV]  alpha=0.0001, max_iter=10000, score=-42318996547220794438057984.000, total= 6.6min\n",
      "[CV] alpha=0.0001, max_iter=10000 ....................................\n",
      "[CV]  alpha=0.0001, max_iter=10000, score=-5968932559281181182394368.000, total= 4.6min\n",
      "[CV] alpha=0.0001, max_iter=10000 ....................................\n",
      "[CV]  alpha=0.0001, max_iter=10000, score=-430742585498590791015071744.000, total= 3.4min\n",
      "[CV] alpha=0.0001, max_iter=100000 ...................................\n",
      "[CV]  alpha=0.0001, max_iter=100000, score=-404396192107939382941450240.000, total= 4.0min\n",
      "[CV] alpha=0.0001, max_iter=100000 ...................................\n",
      "[CV]  alpha=0.0001, max_iter=100000, score=-296680153011177804661784576.000, total= 3.0min\n",
      "[CV] alpha=0.0001, max_iter=100000 ...................................\n",
      "[CV]  alpha=0.0001, max_iter=100000, score=-295040035436952040356446208.000, total= 3.7min\n",
      "[CV] alpha=1e-05, max_iter=1000 ......................................\n",
      "[CV]  alpha=1e-05, max_iter=1000, score=-644335319310300370863915008.000, total= 6.0min\n",
      "[CV] alpha=1e-05, max_iter=1000 ......................................\n",
      "[CV]  alpha=1e-05, max_iter=1000, score=-440257046269989644499156992.000, total= 3.1min\n",
      "[CV] alpha=1e-05, max_iter=1000 ......................................\n",
      "[CV]  alpha=1e-05, max_iter=1000, score=-114255908796581055333138432.000, total= 4.2min\n",
      "[CV] alpha=1e-05, max_iter=10000 .....................................\n",
      "[CV]  alpha=1e-05, max_iter=10000, score=-134042655663166666957651968.000, total= 4.4min\n",
      "[CV] alpha=1e-05, max_iter=10000 .....................................\n",
      "[CV]  alpha=1e-05, max_iter=10000, score=-248977905754728500914290688.000, total= 3.1min\n",
      "[CV] alpha=1e-05, max_iter=10000 .....................................\n",
      "[CV]  alpha=1e-05, max_iter=10000, score=-786055961918633295535407104.000, total= 3.9min\n",
      "[CV] alpha=1e-05, max_iter=100000 ....................................\n",
      "[CV]  alpha=1e-05, max_iter=100000, score=-85504695694920330380312576.000, total= 6.6min\n",
      "[CV] alpha=1e-05, max_iter=100000 ....................................\n",
      "[CV]  alpha=1e-05, max_iter=100000, score=-54786913464672264912896000.000, total= 5.3min\n",
      "[CV] alpha=1e-05, max_iter=100000 ....................................\n",
      "[CV]  alpha=1e-05, max_iter=100000, score=-290339662161352399159033856.000, total= 4.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 167.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SGDRegressor(alpha=0.0001, average=False,\n",
       "                                    early_stopping=False, epsilon=0.1,\n",
       "                                    eta0=0.01, fit_intercept=True,\n",
       "                                    l1_ratio=0.15, learning_rate='invscaling',\n",
       "                                    loss='squared_loss', max_iter=1000,\n",
       "                                    n_iter_no_change=5, penalty='l2',\n",
       "                                    power_t=0.25, random_state=None,\n",
       "                                    shuffle=True, tol=0.001,\n",
       "                                    validation_fraction=0.1, verbose=0,\n",
       "                                    warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'alpha': [0.01, 0.001, 0.0001, 1e-05],\n",
       "                         'max_iter': [1000, 10000, 100000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(units=283, activation='relu', input_dim=283))\n",
    "# model.add(Dense(units=1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compile the model\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_categorical = to_categorical(y_train)\n",
    "# y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     X_train_scaled,\n",
    "#     y_train_categorical,\n",
    "#     epochs=283,\n",
    "#     shuffle=True,\n",
    "#     verbose=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -7.152215663193909e+25\n",
      "Best Params: {'alpha': 0.01, 'max_iter': 10000}\n"
     ]
    }
   ],
   "source": [
    "# List the best score\n",
    "print(f'Best Score: {grid.best_score_}')\n",
    "print(f'Best Params: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01, 'max_iter': 10000}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(grid.best_params_)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'average', 'early_stopping', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter_no_change', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.01, average=False, early_stopping=False, epsilon=0.1,\n",
       "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "             learning_rate='invscaling', loss='squared_loss', max_iter=10000,\n",
       "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
       "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_test = linear_model.SGDRegressor(alpha = grid.best_params_['alpha'], \\\n",
    "#                         early_stopping = grid.best_params_['early_stopping'], \\\n",
    "#                         epsilon = grid.best_params_['epsilon'], eta0 = grid.best_params_['eta0'], \\\n",
    "#                         learning_rate = grid.best_params_['learning_rate'], \\\n",
    "#                         tol = grid.best_params_['tol'], \n",
    "                        max_iter = grid.best_params_['max_iter'])\n",
    "clf_test.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double_check = linear_model.SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
    "#              eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
    "#              learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
    "#              n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
    "#              shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
    "#              warm_start=False)\n",
    "# double_check.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaled_predict = clf_test.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double_check_scaled = double_check.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double_check_score = double_check.score(X_train_scaled, y_train)\n",
    "# double_check_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41208914269472907"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = clf_test.score(X_train_scaled, y_train)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4201670892092394"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_test.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df = pd.DataFrame(columns = ['Prediction', 'Actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df['Prediction'] = test_scaled_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df['Actual'] = true_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxwellpatterson/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test_percent_change = []\n",
    "for i in range(len(test_scaled_predict)):\n",
    "    test_percent_change.append(100 *((test_scaled_predict[i] - true_values[i]) / true_values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df['Percent Change'] = test_percent_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [min(test_percent_change), -20, -10, -5, 0, 5, 10, 20, max(test_percent_change)]\n",
    "labels = ['-20% or worse','-20% to -10%','-10% to -5%', '-5% to 0%', '0% to 5%', '5% to 10%', '10% to 20%', '20% or worse']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df['binned'] = pd.cut(test_results_df['Percent Change'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Percent Change</th>\n",
       "      <th>binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.890640</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-45.546800</td>\n",
       "      <td>-20% or worse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.983435</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-10.165655</td>\n",
       "      <td>-20% to -10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.286385</td>\n",
       "      <td>5.0</td>\n",
       "      <td>105.727693</td>\n",
       "      <td>20% or worse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.614706</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-35.901963</td>\n",
       "      <td>-20% or worse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.048097</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.480967</td>\n",
       "      <td>0% to 5%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction  Actual  Percent Change         binned\n",
       "0   10.890640    20.0      -45.546800  -20% or worse\n",
       "1    8.983435    10.0      -10.165655   -20% to -10%\n",
       "2   10.286385     5.0      105.727693   20% or worse\n",
       "3    9.614706    15.0      -35.901963  -20% or worse\n",
       "4   10.048097    10.0        0.480967       0% to 5%"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20% or worse     129325\n",
       "-20% or worse     67241\n",
       "-20% to -10%      28427\n",
       "10% to 20%        24452\n",
       "5% to 10%         13388\n",
       "0% to 5%          12569\n",
       "-10% to -5%       12246\n",
       "-5% to 0%         11749\n",
       "Name: binned, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_df['binned'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test_results_df['Prediction'], test_results_df['Actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(clf, open('initial_model.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
